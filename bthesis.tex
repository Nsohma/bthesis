\documentclass[11pt,oneside,openany,report]{jsbook}

\usepackage[a4paper,truedimen,margin=25truemm]{geometry}
\usepackage{cscover}
\usepackage[dvipdfmx]{graphicx}
\usepackage[nobreak]{cite}
\usepackage[a4paper,dvipdfmx,pdfdisplaydoctitle=true,%
    bookmarks=true,bookmarksnumbered=true,bookmarkstype=toc,bookmarksopen=true,%
    pdftitle={学位論文の体裁に関する研究},%
    pdfauthor={科学大太郎}%
    ]{hyperref}
\usepackage{pxjahyper}

\renewcommand{\bibname}{参考文献}
\setcounter{tocdepth}{2}
\pagestyle{plain}

\newcommand{\TODO}[1]{\textbf{[TODO: #1]}}
%\renewcommand{\TODO}[1]{}

\thesistype{学士特定課題研究論文}
\title{日本のアニメーション制作現場の調査に基づく活用を見据えた修正のタグ付け手法}
\author{新穂 壮真}
\studentid{22B30610}
\affiliation{東京科学大学\\情報理工学院\\情報工学系} 
\date{2026年1月}

\supervisorname{指導教員}
\supervisor{齋藤 豪}
%\dsupervisorname{副指導教員}
%\dsupervisor{工学 次郎}

\begin{document}

\frontmatter
\maketitle

\chapter{概要}
ここに概要を書きます。

\tableofcontents
\listoffigures
\listoftables

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\mainmatter
\chapter{序論}
\section{本論文の背景と目的}

近年、アニメーション制作のデジタル化が進み、作画や撮影、編集
といった各工程においてコンピュータ上での作業が一般的になってきている。
それに伴い制作過程で扱うデジタルデータの量も増加している。
%これに伴い、制作過程で生成されるレイアウト、原画、動画、仕上げ画像など、
%さまざまなデータをどのように蓄積し利活用するかが重要な課題となっている。
とくに日本のアニメーション制作では、セルアニメーション由来の分業制やカット単位の工程管理が
現在も広く採用されており、各工程で多数の中間生成物や指示書類が発生し、
作品制作の過程で複雑に行き交っている。
その一方で、これらのデータが制作後に体系的に整理・蓄積されることは少なく、
制作ノウハウや現場での判断の多くが個人の経験や属人的な管理に依存しているのが現状である。

こうした状況を受けて、これまでにアニメーション制作におけるデータ管理や
中間生成物の蓄積を目的とした研究・システム開発がいくつか行われてきた。
しかし、それらはいずれも修正という行為そのもの、
すなわち演出や作画監督による修正指示や、その結果として更新された原画・動画といった情報を、
データ活用の観点から蓄積することには十分な焦点を当てていない。
新潟大学アニメ中間素材データベース AIMDB\cite{aimdb} はアニメ制作過程におけるデータの蓄積を目的としたデータベースであり、
リテイクをはじめとした様々な素材の蓄積に対応しているが、データ活用を意識した蓄積構造が設計されているとは言い難い。
渕上ら\cite{fucci}の研究では、データ活用を見据えた中間生成物の蓄積を行っているが、
修正に関する蓄積には対応していない。
修正は、作品のクオリティや作業者ごとの傾向を端的に反映する情報でありながら、
多くの場合は各カットの中に埋もれた形で扱われ、体系的に蓄積・分析されてこなかったと言える。

そこで本論文では、実際のアニメーション制作現場で役立つ視点から、
修正のタグ付けとその活用方法を提案することを目的とする。
%その蓄積と利活用を主な対象とする。具体的には、原画や動画に対する演出修正・
%作画監督修正などの作画上の修正情報を、従来のカットや中間生成物の管理とは
%独立した形で収集・構造化し、それらを分析することで制作進行を円滑にするための
%システムを提案することを目的とする。
この目的を達成するため、アニメーション制作現場における修正の運用実態を調査し、
現状の課題について考える。その上で実際の修正素材を見て分析し、
どのような単位・粒度で修正を蓄積すべきかを整理し、修正に対してつけるタグについて設計する。
次に、その結果に基づき、修正のタグ付けを行うシステムを提案し、
そのシステムから得られるタグの活用可能性について議論する。
%最後に、提案システムを用いて修正データの傾向分析や可視化を行い、
%その結果から制作進行の計画立案や人員配置の最適化といった場面における有用性を検証する。





\section{本論文の構成}
本論文は6章から構成されている。各章の内容は以下の通りである。

\vspace{\baselineskip}

\noindent
\textbf{1章 序論}

本章では、本研究の背景と目的について述べる。

\vspace{\baselineskip}

\noindent
\textbf{2章 関連研究}

本章では、関連研究としてアニメーション制作に使用されるツールやアニメーション制作の
現状、及び画像認識技術やVLMについて述べる。

\vspace{\baselineskip}

\noindent
\textbf{3章 アニメ会社への調査}

本章では、アニメーション会社に対して行った調査と結果について述べる。

\vspace{\baselineskip}

\noindent
\textbf{4章 調査に基づく修正のタグ付け手法}

本章では、アニメーション会社への調査結果を踏まえて、
本研究で提案するシステムの設計と実装について述べる。

\vspace{\baselineskip}

\noindent
\textbf{5章 評価}

本章では、本研究で提案するシステムの実際の使用事例とフィードバック、
アニメーション会社の方からの意見によりシステムの有用性について述べる。


\vspace{\baselineskip}

\noindent
\textbf{6章 結論}

本章では、本論文のまとめ及び今後の課題について述べる。


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\chapter{関連研究}
\section{はじめに}
本章では、本研究に関連する従来研究として、日本のアニメーション制作においてデータ管理を目的とした
ツールや中間生成物の蓄積に関する研究について述べる。最後に、本研究を実現するための
既存技術である画像認識技術やLLMについて述べる。

\section{アニメーション制作のデータ蓄積と活用方法の現状}
本節では、日本のアニメーション制作のデータ蓄積の現状と検討されている活用方法について述べる。

\subsection{アニメーションアーカイブの現状2017\cite{yamakawa}}
山川氏は、株式会社プロダクション・アイジーにおいてアーカイブグループのリーダを務め、
業務中に発生したアニメーション制作資料の収集・整理・選別・保管と、その利活用への対応を主な業務としている。
記事では、2017 年時点のアニメーションアーカイブの現状として、
社内スタッフからの問い合わせが月最大 200 件にも達し、
その内容が新作や続編制作のための設定画・色指定データの取り出し、
アニメータや演出家に仕事を発注する際の作風確認、新人教育用の原画貸出、商品化や映像配信、展示企画のための資料提供など多岐にわたることが紹介されている。
このような事例から、過去の原画や設定資料などの中間生成物 が、
制作・教育・商品開発などさまざまな用途において日常的に参照されており、
その活用意義が非常に大きいことがわかる。

中間生成物は、映像を作成する過程で発生した素材のことを指す。
その種類としては、企画書、脚本、絵コンテ、設定、カット袋 (レイアウト・原画・動画・修正・タイムシート・
3D用素材etc) 、カラーモデル、3Dモデル、3Dシーン、色指定・仕上げ、背景、撮影、編集、
音響、アフレコ台本、納品前映像、ロケハン資料、版権画、セル画、宣伝資料、
納品映像(HD-CAM、フィルム) など多様なものが挙げられる。

このように、
多様な種類の資料が大量に発生するため、その全体像を把握できる人材は限られており、
評価選別や保管には大きなコストを要する。
その結果、多くの制作会社では、
資料の大部分が十分な整理を経ずに失われている現状がある。
山川氏は、中間生成物をアーカイブや利活用時に困らない方法で管理することの重要性を述べている。

\subsection{アイデアソンによるアニメーション中間生成物の活用可能性の検討\cite{matsushita}}
松下らは、日本のアニメーション制作が限られた人員で多数の作品を制作しているため、
制作過程で生まれる中間生成物の整理が十分に行われておらず、多くが廃棄されてしまう現状を指摘している。
一方で、こうした中間生成物はアニメーションの文化資本としての価値を持つにもかかわらず、
具体的な利用用途が見えにくいがゆえに、「コストをかけてでもアーカイブする」という動機づけ
が生じにくいことを問題としている。そこで松下らは、中間生成物の利用用途と活用可能性を検討するため、
2022 年にアイデアソンを実施している。

このアイデアソンでは、国立情報学研究所が公開しているリトルウィッチアカデミアの制作素材
（トリガーデータセット\cite{trigger}）を対象とし、計 27 名の学生が 7 チームに分かれて議論を行った。複数日
にわたるグループディスカッションと成果発表を通じて、モブキャラ作成システム、新人アニメータの
自主練習支援システム、原画データベースシステムなど、さまざまな活用案が提案されている。
これらの案は最終的に、中間生成物の横断的検索の必要性、機械学習用リソースとしての活用、
新たな表現メディア創出の手がかり、という三つの観点に整理され、中間生成物が制作・教育・研究・
ビジネスの各側面から広い応用可能性を持つことが示されている。

しかし、これらのアイデアが全ての解ではなく、特にユーザ視点での活用についてはまだまだ不足していると言える。
一方で松下らは、中間生成物の関係性が整理されて容易に利用可能になることで、
ボトムアップな活用案の創出が期待できることを示唆している。
現在、中間生成物の修正の整理は行われていないため、そうした研究が求められている。

\section{アニメーション制作におけるデータ管理用ツール}
この節では、日本のアニメーション制作で用いられているデータ管理用ツールについて
述べる。

\subsection{flow production tracking(旧shot grid)\cite{shotgrid}}
flow production tracking は、Autodesk 社が提供するクラウド型のプロダクション管理ツールであり、
映像・CG・アニメーション制作やゲーム開発などの分野で用いられている。
プロジェクト内の作業単位をタスクとして管理し、ショットやアセット
（キャラクタ、プロップ、背景環境などの制作要素）と関連付けることで、
制作工程全体の進捗を可視化することができる。スケジュール管理の面では、図\ref{shotGridSchedule} のように
ガントチャートによるタスクの開始日・終了日・期間の表示や、担当者・ステータスを含めたタスク一覧
ビューが提供されており、プロジェクト全体の進行状況を把握しやすい設計となっている。

\begin{figure}[h]
    \centering
    \includegraphics[width=\linewidth]{fig/shotGridSchedule.png}
    \caption{flow production tracking のスケジュール管理機能}\label{shotGridSchedule}
\end{figure}

また、図\ref{shotGridReview}のようにアップロードされた動画や静止画に対してコメントや描き込みを行うレビュー機能や、
バージョン違いのメディアを切り替えながら確認できるインタフェースも備えており、
オンライン上でのレビュー・承認ワークフローを支援している。

\begin{figure}[h]
    \centering
    \includegraphics[width=\linewidth]{fig/shotGridReview.png}
    \caption{flow production tracking のレビュー機能}\label{shotGridReview}
\end{figure}


さらに、図\ref{shotGridAsset}のようにアセット管理の機能として、
キャラクタや背景などのアセットに対して
任意のフィールドやステータスを追加し、担当者や進捗状態といった情報を一元的に管理できる。
ユーザごとにアクセス権限を設定する仕組みも用意されており、権限に応じて閲覧・編集可能な情報
を制御しながら、スタジオ内で共通の制作基盤として利用できるようになっている。
このように、flow production tracking は ショット・アセット・タスク を中心とした汎用的な
パイプライン管理ツールとして設計されており、スケジュール管理・レビュー・アセット追跡を統合的
に扱える点に特徴がある。


\begin{figure}[h]
    \centering
    \includegraphics[width=\linewidth]{fig/shotGridAsset.png}
    \caption{flow production tracking のアセット追跡機能}\label{shotGridAsset}
\end{figure}


一方で、多機能であるがゆえに初心者には扱いづらく、
直感的でない複雑なツールになっているという指摘もなされている。
また、導入コストが高いことや、日本のアニメーション制作で使用されるタイムシートなどへの対応ができないこと、
リテイク処理に対応できずリテイク用の別名カットを新たに作成する必要があるため、本来の意図と異なる使い方を
強いられる場合があることなど、日本のアニメーション制作現場での利用においてはいくつかの課題が残るとされている。
そのため、flow production tracking はタスクやアセット単位の進捗管理やレビューの基盤としては有用である一方で、
アニメ制作で発生する修正をデータ活用の観点から蓄積するための仕組みとしては十分とはいえない。


\subsection{save point\cite{savepoint}}
save point は株式会社 MUGENUP のプロジェクト管理ツールであり、イラストや 3DCG、映像、
広告アセット、アニメーションなど様々なクリエイティブ制作に対応している。制作スケジュール
や進捗、コミュニケーション、レビューをツール内で管理することで、情報共有を簡単に行える自由度
の高いツールとなっている。図\ref{savePointSchedule} のように、制作スケジュールや各工程の進捗を
ガントチャート形式で一覧できるスケジュール管理機能を備えており、プロジェクト全体の工程と期間
を俯瞰して把握することができる。

\begin{figure}[h]
    \centering
    \includegraphics[width=\linewidth]{fig/savePointSchedule.png}
    \caption{savepoint のスケジュール管理機能}\label{savePointSchedule}
\end{figure}


また、図\ref{savePointThread} に示すようなスレッド機能やレビュー
機能を通じて、各カットや素材ごとにファイルのアップロードや修正指示、コメントのやり取りを行える
ため、中間生成物の確認や指示を行う際に活用されている。ツール紹介では「コストを save」
「データを save」「ディレクターを save」の三つの save を掲げており、制作進行担当者や
ディレクターの業務負担の軽減と、データの一元管理による人的ミスの防止を主な目的としている。


\begin{figure}[h]
    \centering
    \includegraphics[width=\linewidth]{fig/savePointThread.png}
    \caption{savepoint のスレッド機能}\label{savePointThread}
\end{figure}


さらに save point を基盤として、アニメの制作進行に特化した「Save Point for アニメ」
も開発されている。Save Point for アニメ は、カット袋が担ってきた素材の受け渡しと作業指示書、
進行管理の機能をクラウド上で統合的に扱うことを目指したツールであり、絵コンテや原画、動画などの
素材の納品から、監修や修正指示に関するやり取り、スケジュールや進捗状況の管理までをブラウザ上
で一元化できるとされている。アニメ特有の進行表やカット表をツール内で再現したインタフェースや、
図\ref{savepointFinger}のように
紙のタイムシートをめくる「指パラ」に相当するフレーム単位の動きの確認機能、ガントチャートによる
工程スケジュールの可視化などを備え、アニメ制作の現場で使い慣れたワークフローとの親和性を意識した
設計になっている。

\begin{figure}
    \centering
    \includegraphics[scale=0.5]{fig/savepointFinger.jpg}
    \caption{save point for アニメの指パラ機能}\label{savepointFinger}
\end{figure}

しかし save point は、プロジェクト管理に重点を置いたツールであり、蓄積した中間生成物を将来的
に分析・再利用するデータ基盤として設計されているわけではない。実際に、
save point 内の検索機能も欲しい中間生成物があらかじめ明確になっていることを前提としたファイル
や制作物の検索が中心であり、中間生成物の属性や内容からの
高度な検索や分析には応用しづらい。save point および Save Point for アニメ は進行管理や
コミュニケーションの効率化には有効である一方で、中間生成物を後の運用の観点から
整理し蓄積する仕組みは備えていないと言える。

\subsection{Hiero\cite{hiero}}
Hiero は Foundry 社が提供する Nuke ファミリーのツールであり、マルチショット編集やコンフォーム、
レビューをタイムラインベースで扱うことを目的としたソフトウェアである。
複数ショットをまたいだバージョン管理や再生確認、簡易的な編集作業を
一つのプロジェクト内で行うことができる。

レビュー機能としては、タイムライン上のフレームに対して描き込み付きの
アノテーションやコメントを付与でき、
後工程の担当者に修正内容を伝えるワークフローが想定されている。
一方で、こうしたアノテーションはあくまで各プロジェクト内のレビュー情報として扱われており、
修正指示そのものを、作品をまたいで横断的に検索・分析するための
データとして管理する枠組みは提供していない。したがって Hiero はアニメ制作進行の
効率化には有効であるが、修正素材を整理し蓄積するには不十分であると言える。

\subsection{アニクロ\cite{anikuro}}
アニクロは、メモリーテック株式会社が提供するクラウド型アニメ制作管理システムであり、
「カット袋をデジタル化しませんか？」というコンセプトのもと、カット袋やタイムシートを
オンライン上に再現して制作工程を管理することを目指している。工程ごとに素材ファイルをアップロード
して紐付ける工程管理・素材管理機能や、ブラウザ上で作画ファイルをプレビューし、コメントや手書きの修正指示
を書き込めるチェック機能を備えており、従来紙ベースで行われてきた受け渡しや指示をクラウド上で完結できる点が特徴である。

また、Web 上で共有可能なデジタルタイムシートや、自動更新されるカット表・日報表、複数カットに対する一括リテイク
出しやリテイク一覧表示などの機能により、作品単位での進行管理とリテイク管理を一元的に行うことができる。
このようにアニクロは、日本のセルアニメーション制作で用いられてきたカット袋やタイムシートの運用に対応した
制作管理ツールとして有用である一方で、アップロードされた中間生成物を属性や内容から整理する仕組みまでは提供していない。
したがって、アニクロは修正素材を整理し蓄積するという目的では運用できない。



\subsection{OLM FM tool\cite{olmfmtool}}
OLM FM Tool は、株式会社 OLM がデジタル作画パイプライン構築の一環として社内開発したファイル管理
ツールであり、リモートワーク環境における素材配布や成果物回収を円滑に行うことを目的としている。
制作データを Google ドライブ上に保存したうえで、作品・話数・カット・工程といった日本のアニメ制作
の単位に沿ってブラウズできる専用インタフェースを提供し、図\ref{OLMFMTool}のように、
ファイルやフォルダの個別・一括ダウンロード
やアップロード、フォルダの作成や削除などの操作を一画面から行うことができる。
これにより、従来のフォルダ構成では把握しづらいディレクトリ階層を現場向けに分かりやすく整理するとともに、
データ紛失を起こすことなく、低速なネット環境でも比較的快適に素材を扱うことができる点が特徴的であり、
リモートワークへの対応力の高さが強みである。

\begin{figure}[h]
    \centering
    \includegraphics[width=\linewidth]{fig/OLMFMTool.png}
    \caption{OLM FM toolの自由度の高いディレクトリ操作機能}\label{OLMFMTool}
\end{figure}

一方で、OLM FM Tool はあくまでフォルダ階層とファイルパスに基づく素材管理を主眼としたツールであり、
データベース上に中間生成物を蓄積するわけではなく、オンラインストレージ上にファイル
を保存しているにとどまるという限界がある。


\subsection{Redmine\cite{redmine}}
Redmine はオープンソースの Web ベースプロジェクト管理ツールであり、チケットによる課題管理や
ガントチャート・カレンダーによるスケジュール管理、Wiki・フォーラムによる情報共有機能などを備えている。
プロジェクトごとにチケット種別やワークフロー、カスタムフィールドを定義できる汎用的な設計となっており、
ソフトウェア開発以外の業務管理やコンテンツ制作にも広く用いられている。

アニメーション制作においても、図\ref{redmineChiket}のように各カットや工程をチケットとして登録し、
担当者・期限・ステータスを設定することで、進行状況の把握やタスク割り当てに利用することができる。
しかし Redmine はあくまで汎用的な課題管理ツールであり、
日本のアニメーション制作に特有のカット袋やタイムシートの運用を前提としておらず、原画・動画に対する個々の修正指示や
修正後素材を作品やアニメータをまたいで横断的蓄積するデータ構造は備えていない。

\begin{figure}[h]
    \centering
    \includegraphics[scale=0.5]{fig/redmineChiket.png}
    \caption{Redmine のチケット機能}\label{redmineChiket}
\end{figure}

\subsection{株式会社サンジゲンの制作管理ツール\cite{sannjigenn}}
株式会社サンジゲンは 3DCG アニメーション制作を主業務とするスタジオであり、
日本のアニメ制作に適した市販パッケージが少ないことから、自社内で制作管理システム
とデータベースを構築している。従来 Excel で管理していた工程表ではタイトル数
やカット数の増加に対応しきれなくなったことを受け、発注情報やスタッフの作業状況、日報、チェック結果、
収支などを一元管理できる仕組みを整備している。
制作の進行状況やステータスはもちろん、チャット機能やアップロード通知の機能など、
制作支援のための機能を幅広く備えている。
アップロードされた中間生成物を参照しながらレビューを行うことも可能であり、
日本のアニメーション制作の工程に幅広く対応している

また、アップロードされた映像データは自動エンコードされて Hiero に蓄積され、
社内ツール SanzigenCutManager と連携して最新テイクと過去テイクの比較チェックを行えるなど、
大規模 3DCG 制作におけるレビューと進行管理を効率化する基盤として機能している。一方で、
修正素材を、整理し蓄積しているわけではなく、修正は主としてスケジュール・品質管理上のイベント
として扱われていると考えられる。


\section{アニメーションの中間生成物の蓄積に関する研究}
この節では、日本のアニメーション制作における中間生成物の蓄積に関する研究について述べる。

\subsection{新潟大学アニメ中間素材データベースAIMDB\cite{aimdb}}
新潟大学アニメ中間素材データベース AIMDB は、
アニメーション制作における中間生成物を体系的にアーカイブすることを目的として構築されたデータベースである。
扱っている中間生成物は原画、動画、修正原画、脚本、リテイクなど多岐にわたり、
制作過程で生じるさまざまな資料を対象としている。

AIMDB の研究目的は、中間生成物のアーカイブ化とデータ処理・分析、
セル画の保存システムの開発であり、特に制作時に散逸しがちな中間生成物を蓄積することに焦点を当てている。
蓄積された中間生成物の一部は公開されており、
アーカイブされたデータはそれぞれの属性をもとに検索ができる。
図\ref{AIMDB}に示すように、作品名や制作会社、中間生成物の種類といった項目によって絞り込みを行うことが可能である。

\begin{figure}[h]
    \centering
    \includegraphics[width=\linewidth]{fig/AIMDB_mid.png}
    \caption{AIMDB}\label{AIMDB}
\end{figure}

一方で、このデータベースにはアニメータが制作業務の中で直接利用できるような入力インタフェースは提案されておらず、
中間生成物を蓄積するためには、過去の制作で用いられた資料をスキャンしてデータ化し、
技術者が手作業でデータベースに登録する必要がある。
また、タイムシートの取り扱いは紙媒体のみを対象としており、
デジタル形式（XDTS\cite{xdts}など）には対応していない。
さらに、検索も主として作品名や会社名など既知の属性を前提としており、
修正の内容や中間生成物同士の関係性といった観点から自由度の高い検索を行うには、
十分なデータベースであるとは言い難い。

\subsection{実務家に聞くアニメアーカイブデータベースの可能性と課題
新潟大学アニメ中間素材データベース(AIMDB)へのフィードバックから\cite{matsumoto}}
新潟大学アニメ・アーカイブ研究センターでは、過去のアニメーション作品の中間生成物の
アーカイブを進めており、先述した AIMDB\cite{aimdb} として閲覧者を限定して公開している。
松本は、この AIMDB を用いた科研費プロジェクトの一環として、
Production I.G でアニメアーカイブを推進する山川道子氏と、
東映アニメーションでシニアプロデューサーを務める野口光一氏に
AIMDB を試用してもらい、アニメ制作の実務家としての所感をヒアリングしている。

山川氏と野口氏からは、例えば、
ニーズに応じて解像度の異なるデータを用意してはどうかという指摘や、
タグ付けや香盤表の情報だけでは十分ではなく、
目的に応じて資料を読み解き適切に案内できる
リファレンス能力を持ったアーキビストの育成が不可欠であることなどが挙げられている。
また、現場に共有されないまま早い段階で破棄されてしまう資料の存在を前提に、
絵コンテからのキーワード抽出によって香盤表的な情報を補完するなど、
失われがちな文脈情報を補う仕組みの必要性も指摘されている。

これらの意見からは、単に中間生成物そのものを1保存するだけでなく、
検索や利活用の起点となるメタデータや文脈情報をあわせて蓄積する重要性が示唆されている。

\subsection{長尾らのデータベース\cite{nagao}}
セルアニメーション由来の手描きを含む制作手法を用いる日本のアニメーション制作では分業制が採用されており、
1 カットに対して携わる人数が多い。さらに、制作現場ごとに制作プロセスが異なるため、
業界内での画一的な中間生成物の管理は困難であり、スタジオごとにそれぞれ独自の手法で中間生成物を管理している。
しかし、共通の形式でデータを蓄積できなければ、中間生成物の活用を見込むことは難しく、貴重とされる中間生成物
が十分に生かされないまま終わってしまう。

これらの事実を受けて、長尾らはアニメーション制作完了後に残された中間生成物を調査し、
画一的な管理手法としてリレーショナルデータベースを提案した。具体的には、2014 年に株式会社スタジオ
コロリドと株式会社ロボットが共同制作を行ったマルコメ株式会社の「料亭の味」の CM アニメーション
\cite{marukome} のうち、「単身赴任編」と「夜食編」の 2 つのエピソードを対象に調査を行っている。
中間生成物を含むディレクトリ構造を分析した結果、以下の 5 点の課題を挙げている。

\begin{enumerate}
    \item ディレクトリの構成や命名規則がはっきりしておらず、必要となるファイルの在処を把握するのが困難
    \item 同一内容のファイルが複数のディレクトリに点在
    \item 工程の進捗状況を知るためには、複雑なデータ構造の確認が必要
    \item チェックの意図がファイル構造やファイル名からは判別しづらい
    \item 一部のファイルについてはデータ自体が残されていない
\end{enumerate}

これら 5 点に対して、長尾らは課題に適した設計指針を示している。設計指針としては、カット単位でデータ
を扱うこと、データの種類をタイムシートに関わるものとそうでない場合を分別できること、 
タイムシートの情報ではフレームとレイヤの情報を持てること、修正前後を含む全てのデータが確認できること
が挙げられている。カット単位で中間生成物を管理することは、カット袋での管理が基本である日本のアニメーション
業界において標準的であり、同一ファイルが複数箇所に点在するようことを防ぐメリットがある。また、
工程ごとにデータを管理することによって、必要となるファイルの在処を明確にし、進捗状況を把握しやすくすることができる。

これらの設計指針を基準に作成したデータベースが以下の図 \ref{Nagao} の 22 のテーブルからなる
リレーショナル・データベースである。カット、ファイル、作業の 3 つのテーブル群をフレームやレイヤなど
のテーブルで結びつけ、カットやファイル、作業を関連付けている。また、登録日時と更新日時を蓄積することで、
作業履歴を追跡可能な構造となっている。

\begin{figure}[h]
    \centering
    \includegraphics[width=\linewidth]{fig/NagaoDatabase.jpg}
    \caption{長尾らのデータベース}\label{Nagao}
\end{figure}

長尾らのデータベースは日本のアニメーション特有の制作手法に特化した構造となっており、
従来では管理が難しかった日本のアニメーション中間生成物を統一的な形式で扱うことを可能にした点に特徴がある。

\subsection{夏らのシステム\cite{yiyi}}
夏らは先述した長尾らのデータベース \cite{nagao} に対して、
原画と動画の中間生成物を蓄積できる WEB システムを提案している。
このシステムはアニメータ自身がアニメーション制作中に中間生成物を蓄積できる設計になっており、
制作後にまとめてアップロードするという手間を省くことができる。

中間生成物を蓄積する具体的な方法は、WEB インタフェース上の作業ページからのアップロードである。
アップロードの形式はレイヤ別の絵とタイムシートを含めたディレクトリ構造を zip 形式に圧縮
したものであり、作画ツールとして主流である CLIP Studio Paint \cite{clipstudio} で
描いた絵やタイムシートを容易にその形式にできることから、ツールとの連携も容易である。アップロード
により蓄積した中間生成物は図 \ref{XiaWorkpage} に示す作業画面にて確認をすることができる。

\begin{figure}[h]
    \centering
    \includegraphics[width=\linewidth]{fig/XiaWorkpage.png}
    \caption{夏らのシステム : 作業画面}\label{XiaWorkpage}
\end{figure}

作業ページのインタフェースはカット袋やタイムシートなど、
日本のアニメーション制作で使用される管理手法と似た表形式を意識して設計されており、
アニメータが違和感なく利用できるように配慮されている。
また、単に中間生成物をアップロードするだけでなく、下記のような制作支援機能を提供することで、ア
ニメータが制作途中に中間生成物を蓄積するモチベーションを高めている。

\begin{enumerate}
    \item タイムシートの編集 \\
    アップロードされたタイムシートはインタフェース上で編集を行うことができる。
    タイムシートのセル値の入力や削除、セル値の移動、undo、redo、コピー、ペーストなどができ、ユーザが容易に編集可能である。
    タイムシートの編集ができるツールは東映デジタルタイムシート \cite{toei} など限られていることから、本機能は貴重である。
    \item 映像作成 \\
    インタフェース上のタイムシートとアップロードされた原画や動画を使用して、
    現状の映像を作成することができる仕組みとなっている。
    映像作成は線画に対応しており、レイヤの重ね合わせはもちろん、
    特定のレイヤのみを用いた映像を作成することも可能である。
    \item 版による履歴管理 \\
    アニメータは自身の作業の中で、絵を描き換えやタイムシートを編集などの変更を加える。
    夏らのシステムではこの変更の際に、素材を上書きせず、過去の版の内容を復元可能な形で蓄積する。
    具体的には、映像作成時や再アップロード時に自動で過去の版を登録する。
    この蓄積方法により、過去の版の中間生成物を復元することが可能となり、
    インタフェース上で確認できる。版の保存は映像確認を行った際に、ユーザ自身の要望に応じて行うことができる。
    \item 版を用いた映像比較 \\
    過去の素材を版として蓄積しているため、各版時点での映像をインタフェース上で作成できる。
    また、過去の版を複数選択すれば、図 \ref{XiaVideopage} に示すインタフェースで、
    最大 4 つの版の映像を同時再生により比較できる。この映像比較機能によって、
    アニメータがより良い素材を選択できるだけでなく、
    試行錯誤の過程とその結果をデータベースに蓄積することができる。
    正解例のみならず失敗例も蓄積することで、試行錯誤の意図の理解に資する可能性がある。
\end{enumerate}


\begin{figure}[htbp]
    \begin{center}
        \includegraphics[scale=0.5]{fig/XiaVideopage.png}
    \end{center}
    \caption{夏らのシステム : 映像比較}\label{XiaVideopage}
\end{figure}

このような制作支援を通して、多忙なアニメーション業界での使用可能性を高めている。
蓄積するタイミングが制作途中であるために、最終版の中間生成物のみでなく、途中経過の中間生成物を蓄積
できることも大きな強みである。また、本システムは WEB システムであるので、アニメータが使用する環境
を構築するのが容易であり、導入難易度が比較的低い点も利点として挙げられる。

\newpage
\subsection{渕上らのシステム\cite{fucci}}
渕上らは、先述した夏らのシステムに対して、
カット間の関係接続を導入した中間生成物蓄積システムを提案した。
関係接続の手がかりとなる中間生成物とそれに関連するアニメータの行動、
および中間生成物の活用方法を明らかにするため、アニメーション制作会社
に対する調査を実施した。調査対象は株式会社スタジオエイトカラーズ、株式会社 OLM、
有限会社神風動画、Kaikai Kiki Animation Studio PONCOTAN であり、
制作現場での定点観察、対面インタビュー、意見交換、アンケートなどの手法を用いて
情報収集を行った。
調査の結果、中間生成物の主な活用方法として、以下の 4 点が挙げられている。

\begin{enumerate}
    \item 教育のための検索 \\ベテランアニメータがアニメーション制作を学んできた過程を調査したところ、原画本や修正指示の様子、類似カットなどの素材を閲覧することで学んできたという回答が多かった。そのため、新人アニメータが参照すべき中間生成物を手元から検索・閲覧できるようにすることは、教育の促進に有効であると考えられる。特に、修正指示や修正過程を併せて閲覧でき、新人の視点を補うような情報が付随していることが望ましい。
    \item 修正指示のための検索\\アニメ制作における修正指示の出し方には、原画シートへの書き込みや補助資料の送付など複数の方法が存在する。動きの説明などのために補助資料を用いる場合も多いが、中間生成物が十分に整理されていない現状では、適切な資料を探すのに多くの時間を要する。修正指示に用いる素材を検索によって素早く取得できれば、指示内容の簡潔化やリテイク数の減少に寄与すると考えられる。この用途の検索は動きなどに特化したものである必要があり、アニメーション制作向けのアノテーションやタグ付けが求められる。
    \item 作画の参考資料としての検索\\アニメータは、慣れないカットを描く場合や再現しにくい動きを捉える場合に、似た素材を検索して作画の参考にする。こうした素材を中間生成物から検索・参照できれば、作画作業を直接支援する機能として有用である。
    \item 素材の使い回し\\3DCG 素材や背景素材などは、作品内で再利用されることがある。しかし、中間生成物が十分に整理されていないと、再利用可能な素材を即座に取り出すことは難しい。使い回し可能な素材を検索によって取得できれば、作業効率を大きく向上させることができる。
\end{enumerate}

また、関係接続の手がかりとなる、中間生成物と関連するアニメータの行動として、
設定資料の閲覧、演出からの指示、タイムシートの更新履歴などが挙げられている。
渕上らは、これらの中から特にアニメータの行動履歴に着目し、カットごとの関係接続
を行うことで、活用を意識した中間生成物の構造的な蓄積を可能にしている。

さらに渕上らは、夏らのシステムと同様に、アニメ会社が本システムを利用するモチベーションを高めるため、アニメーションのクオリティ向上や作業時間短縮につながる付加価値機能を実装している。主な機能としては、以下の点が挙げられる。

\begin{enumerate}
\item デジタルタイムシートへの対応とインタフェース改善\\
デジタルタイムシート形式である TDTS の読み込みに対応し、工程に応じて原画欄と動画欄を切り替えて利用できるようにしている。また、セル幅を削減することで十分なセル数を画面上に表示可能とし、紙のタイムシートに近いレイアウトを実現している。さらに、タイムシート上のセルにマウスオーバーした際に対応する絵を表示する機能を設けることで、映像を生成せずともカットの完成度を簡易的に確認できるようにしている。
\item 色付き素材を考慮した映像作成\\
仕上げ工程を想定し、レイヤ合成時にアルファ値を考慮した映像作成機能を実装している。これにより、線画のみを対象とした夏らのシステムと異なり、色付きのセルを用いた映像確認が可能となっている。
\item 各工程ツールとの連携と作業ファイルのダウンロード\\
原画・動画・ペイントといった各工程で主に用いられる CLIP STUDIO PAINT との連携を考慮し、XDTS や TDTS 形式のデジタルタイムシートと各セルの絵を含むディレクトリ構造を zip 形式でダウンロードできるようにしている。過去の版や最新の版を選択して中間生成物一式を取得できるため、現場の作業フローに組み込みやすい構成となっている。
\end{enumerate}

これらの機能に加え、図 \ref{fucciInforFlow} に示すように、
アニメータが Web システム上で情報伝達を行う中で各工程の中間生成物が自動的に蓄積されるよう設計
されている。システム上で情報伝達と制作管理を一体的に行えるようにすることで、制作進行担当者の業務
負担を軽減するとともに、アニメータがシステムを利用するだけで中間生成物とその版の履歴が蓄積
されていく点が、渕上らのシステムの特徴である。

\begin{figure}[htbp]
    \begin{center}
        \includegraphics[scale = 0.7]{fig/fucciInfoflow.png}
    \end{center}
    \caption{渕上らのシステム : 全体設計}\label{fucciInforFlow}
\end{figure}


\section{既存アニメ関連ツールの比較}

\subsection{比較指標}

\subsection{比較結果}



\section{タグ付けのための物体検出}
本研究では、アニメーション制作過程の修正を活用しやすい形で蓄積するため、
修正が入ったカット、特に彩色後のフレーム画像から自動的にタグを付与することを目的とする。
その基盤技術として、画像中の対象（人物、顔、手、衣装、小物など）を領域（バウンディングボックス）
とともに抽出できる物体検出は有用である。一方で、アニメ画像に対して十分な教師データを用意することは困難であるため
、本研究が物体検出器に求める要件は次の通りとする。

\begin{enumerate}
    \item 学習データを用意せずに適用できるゼロショット検出が可能であること
    \item 速度をあまり重視せず、精度を重視すること
\end{enumerate}

以上を踏まえ、クローズドセット検出器（YOLO, DETR, DINO）と、
言語条件により語彙を拡張できるオープンボキャブラリ検出器（GLIP, Grounding DINO）を取り上げ、
以上の要件を満たす候補として後者を中心に整理する。



\subsection{YOLO\cite{yolo}}
YOLO （You Only Look Once） は  Redmon らにより提案された物体検出を代表する手法の一つであり、
特に画像を一度だけネットワークに通して検出を完結させる
単段（one-stage）検出器の流れを決定づけたモデルとして位置付けられる。
アーキテクチャとしては、入力画像から特徴を抽出するバックボーン CNN と検出ヘッドを一体化して持つ CNN ベースのモデルである。
図\ref{fig:yolo_arch} に示すように、
畳み込み層とプーリング層を中心に段階的に特徴マップを得たのち、最終段でバウンディングボックスの位置・
サイズとクラス確率を同時に推定する。二段方式（候補領域生成して分類する方式）と比べて処理が単純であるため、
推論が高速になりやすく、リアルタイム物体検出の文脈で広く普及した。

\begin{figure}[h]
  \centering
  \includegraphics[width=\linewidth]{fig/yoloArchitecture.png}
  \caption{YOLOv1 のネットワーク構造の例}
  \label{fig:yolo_arch}
\end{figure}


YOLO 系の利点は「多数フレームに対して候補領域を一括抽出する処理を比較的軽量に実行できる」という点にある。
アニメ制作現場の素材はフレーム数が膨大になり得るため、処理時間を抑えやすいこと自体は魅力である。
ただし、本研究では夜間などの一括処理も想定でき、リアルタイム性は重要ではない。
一方で、YOLO 系を自動タグ付けの中核として用いる際には、構造上の制約が生じる。多くの YOLO 系モデルは COCO 
など自然画像データセットに基づくクローズドセット検出器として設計され、検出クラスはあらかじめ定義されたカテゴリ集合に限定される。
このため、アニメ制作で検索や分析に有用な「上半身」「顔」「目」といった部位概念や、
柔軟に増やしたいタグに用いたい語彙を、学習データなしでそのまま検出に用いることは不可能である。
また、後述する Transformer ベースの検出器と比べて検出の精度は劣る。そのため、速度よりも精度を重視したい本研究には
不適当なモデルと言える。

したがって本章では、YOLO を物体検出の基礎的枠組みを示す参照（ベースライン）として位置付けつつ、
後続で扱うオープンボキャブラリ検出器、また Transformer ベースの検出器へと議論を接続する。

\subsection{DETR\cite{detr}}
DETR（DEtection TRansformer）は Carion らによって 2020 年に提案された物体検出モデルであり、
従来主流であった「候補領域の生成→分類・回帰」という段階的パイプラインを、
Transformer を中核とする単一のネットワークに統合した点に特徴がある。物体検出の研究史の中では、
CNN を中心に発展してきた検出器に対して、Transformer を用いた 集合予測（set prediction） 
の枠組みを導入し、後続の多くの Transformer ベースの検出器
につながる重要な転換点となったモデルとして位置付けられる。図\ref{fig:detr_arch} に DETR の全体構成を示す。


\begin{figure}[h]
    \centering
    \includegraphics[width=\linewidth]{fig/Detr_arch.png}
    \caption{DETR の全体構成}\label{fig:detr_arch}
\end{figure}


DETR の処理は大きくバックボーン、Transformer エンコーダ、Transformer デコーダ
の三段に整理できる。まず入力画像は CNN バックボーンにより特徴マップへ変換され、
空間方向に並べ替えられたうえで位置エンコーディング (positional encoding) が付与される。
これが Transformer エンコーダへ入力され、
自己アテンションによって画像全体の文脈を踏まえた特徴量が得られる。次に Transformer デコーダには固定個数の 
オブジェクトクエリ が入力される。オブジェクトクエリ (object queries) は学習可能なベクトル集合であり、
画像中の各物体を「どのスロットが担当するか」を決めるための枠組みとして機能する
。デコーダはクエリとエンコーダ出力の間でクロスアテンションを行うことで、画像中の重要領域をクエリごとに参照し、
最終的に各クエリに対応する出力を FFN に入力してクラスラベルとバウンディングボックスを推定する。
従来の Anchor Base や非最大抑制 (NMS) に依存せず、ネットワーク全体を end-to-end に学習できる点が利点として挙げられる。
また、エンコーダの自己アテンションにより画像全体の関係性を扱えることから、
物体同士の重なりや離れた領域間の関係が重要になる場面で有利に働く可能性がある。

一方で、元の DETR には実用面での課題も報告されている。代表的には、学習の収束が遅く、
COCO のような一般的データセットでも十分な精度に到達するまでに多くの学習エポックを要する点が挙げられる。%???
また、高解像度画像における小物体の検出性能が十分でないことが指摘されている。%???
さらに Transformer を中核とする性質上、軽量な CNN ベースの検出器と比べて推論時間やメモリ使用量
が大きくなりやすい。

本研究との関係で整理すると、DETR は物体検出を Transformer による end-to-end な枠組みとして定式化した点で重要であり、
後続の改良手法を理解するための基礎的なモデルである。
ただし、DETR 自体は基本的にクローズドセット検出であり、アニメ画像に対する教師データが十分に用意できない状況で
学習なしにタグ語彙を柔軟に増やしながら検出するという本研究の要件であるゼロショット性を満たしていない。

したがって本章では、DETR を Transformer ベース検出器の代表例として位置付けつつ、
収束性や小物体検出といった課題がどのように改善され、さらにゼロショット検出へ発展していくかという流れの中
で次の小節以降の手法を紹介する。

\subsection{DINO\cite{dino}}
DINO は Zhang らによって提案された Transformer ベースの物体検出モデルであり、
DETR の課題であった学習収束の遅さと小物体検出性能の不足を改善することを目的としている。
図\ref{fig:dino_arch} に DINO の全体構成を示す。

\begin{figure}[h]
  \centering
  \includegraphics[width=\linewidth]{fig/DINO_arch.png}
  \caption{DINO の全体構成図}
  \label{fig:dino_arch}
\end{figure}


まず、入力画像からは CNN バックボーンによりマルチスケールの特徴マップが抽出され、
それぞれに位置エンコーディングを加えた上でフラット化し、
Transformer エンコーダに入力する。
エンコーダは複数スケールの特徴を統合しつつ自己アテンションにより文脈情報を取り込んだ
画像特徴を生成する。

DETR ではオブジェクトクエリがランダム初期化された学習パラメータとして与えられていたのに対して、
DINO ではエンコーダ出力から「クエリ選択（Query Selection）」を行い、
物体らしさの高い位置を初期アンカーとして抽出する。
これらのアンカー情報をもとに内容ベクトル（Content Query）を生成し、
Transformer デコーダに入力することで、
各クエリが画像中の有望な領域に対応しやすいように設計されている。
デコーダの出力は DETR 同様にクラスラベルとバウンディングボックスを予測する
ネットワークに入力され、最終的な検出結果として解釈される。

また DINO では、学習の安定化と性能向上のために
「Contrastive DeNoising（CDN）」と呼ばれる学習戦略を導入している。
これは、正解ボックスにノイズを加えた擬似ターゲットと、
全く関係のないネガティブなボックスを同時にデコーダへ入力し、
どの出力が真の物体に対応するかを学習させる手法である。
このノイズ付きターゲット学習により、
モデルはローカライゼーション誤差や外れ値に対して頑健になり、
少ないエポックでも高い性能に到達しやすくなると報告されている。

このように DINO は、DETR のエンコーダ・デコーダ構造を継承しつつ、
クエリ選択による初期アンカー生成とノイズ付き学習戦略を組み合わせることで、
収束の高速化と小物体を含む高精度な検出を実現したモデルである。
一方で、Transformer を中核とする点は DETR と同様であり、
YOLO 系の軽量な CNN ベース検出器と比較すると推論時の計算コストは依然として大きい。
またゼロショット性を備えていないため、アニメ制作で欲しい「顔」「手」「上半身」といった部位概念や、
作品・工程依存で増やしたいタグ語彙を学習なしで柔軟に扱う主手法としては限界がある。



\subsection{GLIP\cite{glip}}

GLIP は Li らによって 2022 年に提案された物体検出モデルであり、画像と言語を統合的に扱う点に特徴がある。
従来の物体検出では、画像と、それに対応するバウンディングボックスとクラスラベルの組からなる検出データのみ
を用いて学習するのが一般的であったのに対して、GLIP ではこれに加えて、文章中のフレーズと画像内の領域を対応
付けたグラウンディング用データや、画像とキャプションのペアからなる画像テキストデータを併用して事前学習を行う。
具体的には、物体検出データセット上では従来と同様に「ボックス＋クラス名」の組を学習しつつ、
グラウンディングデータセット上では「文章中のフレーズ」と「それに対応する画像領域」の対応関係を学習し、
さらに画像全体とキャプション文のペアからは、画像特徴とテキスト特徴が意味的に対応するように事前学習を行っている。
このように複数形式の画像テキストデータを統合的に用いることで、GLIP は言語に敏感な物体表現を獲得し、
ゼロショット設定においても高い検出性能を示すことが報告されている。

図\ref{fig:glip_arch}に GLIP の全体構成を示す。上段では
「person」「bicycle」「hairdryer」などのカテゴリ名や
簡単なフレーズからなるプロンプトをテキストエンコーダで処理し、
単語ごとの特徴量を得ている。下段では画像から領域ごとの特徴量を
抽出し、テキスト側の特徴と融合させることで、各領域がどの単語に
対応するかのスコア行列を計算している。このように、単語と画像領域の
対応関係を直接学習する構成になっていることが、GLIP の特徴である。

\begin{figure}[h]
  \centering
  \includegraphics[width=\linewidth]{fig/glip.png}
  \caption{GLIP の全体アーキテクチャ\cite{glip}}
  \label{fig:glip_arch}
\end{figure}


GLIP の大きな利点は、オープンボキャブラリ検出が可能である点にある。
検出時には、従来のようにあらかじめ固定されたクラス集合をモデル内部に持たせるのではなく、
「girl」「smiling woman」のようなカテゴリ名や簡潔なフレーズをテキストとして入力し、
そのテキストと画像中の領域の対応に基づいてバウンディングボックスとスコアを出力する枠組みとなっている。
このため、クラス集合を事前に厳密に固定しておく必要がなく、タグ集合を後から追加したり、
「女の子」「赤い服」など比較的柔軟な概念をタグとして扱える点は、タグ設計の自由度という観点から有用である。
また、学習には物体検出データだけでなくキャプション付き画像も用いられているため、
従来の検出器では学習データ数が少なく性能が出にくいカテゴリに対しても、ゼロショットもしくは少数ショット
で一定の性能が得られやすいとされている。

一方で、GLIP を実際のシステムに組み込む際の課題も存在する。GLIP は大規模な Transformer を中核とするモデルであり、
YOLO 系の軽量な検出器と比較すると、推論時間やメモリ使用量は大きい。
また、GLIP は主として実写画像を用いたデータセットで事前学習されているため、
線画や彩色済みセル画といったアニメーション画像とは分布が異なる。デフォルメされたキャラクタやアニメ特有の表現に対しては
検出精度の低下が避けられないと考えられるが、アニメ領域ではバウンディングボックス付きの大規模教師データを新たに構築
することは現実的ではない。そのため、本研究のような設定では、GLIP をアニメ画像に完全に適応させるための追加学習
を前提とするのではなく、ゼロショットを前提としたある程度の誤差を許容した候補領域抽出
として位置付ける必要がある。加えて、検出対象はテキストで指定するため、プロンプトとして与える語彙や表現の仕方
によって検出結果が変動しやすく、アニメ制作におけるタグ設計に合わせて、どのような表現
を用いるかといったプロンプト設計も重要な検討事項となる。

以上より、GLIP は、事前に固定されたクラス集合に依存しないオープンボキャブラリ物体検出を可能にする点で
、アニメーションの修正カットに対して柔軟なタグ付けを行うための有力な候補である一方で、
実写ベースの事前学習による精度低下やプロンプト依存性といった課題を抱えている。
本研究においては、YOLO のようなクローズドセット検出器と比べてタグ語彙の自由度が高いことを重視しつつも、
アニメ画像に対する検出精度や計算コストとのバランスを踏まえた上で、修正カットのタグ付けにおける適用可能性を検討する。






\subsection{Grounding Dino\cite{groundingdino}}
Grounding DINO は Liu らによって提案されたオープンボキャブラリ物体検出モデルであり、
DINO 系の高性能な Transformer ベース検出器と、GLIP のようなテキスト条件付きグラウンディング
の枠組みを統合している\cite{groundingdino}。すなわち、DINO が示した高精度な Transformer 
検出アーキテクチャを土台としつつ、GLIP のようにテキストと画像の対応関係を明示的に学習することで、
任意のテキストフレーズに対するゼロショット検出を実現したモデルと言える。図\ref{fig:grounding_dino_arch}に 
Grounding DINO の全体構成を示す。

\begin{figure}[h]
\centering
\includegraphics[width=\linewidth]{fig/GroundingDino.png}
\caption{Grounding DINO の全体アーキテクチャ\cite{groundingdino}}
\label{fig:grounding_dino_arch}
\end{figure}

図の左下に示すように、入力テキストはテキストバックボーンを通して「cat」「person」「mouse」
などのトークン列として埋め込みベクトルに変換される。一方で、入力画像は DINO と同様の画像バックボーンと 
FPN によってマルチスケールな画像特徴として表現される。これらの「素の」テキスト特徴と画像特徴は 
Feature Enhancer で統合され、テキストから画像へ、画像からテキストへという双方向のクロスアテンションを通じて、
互いの情報を参照しながら更新された特徴表現へと変換される。

その上で、Language-guide Query Selection によってテキスト特徴から言語ガイド付きのクエリが生成される。
これは DINO における学習済みオブジェクトクエリに相当するが、Grounding DINO ではテキスト側の情報を利用して
「どのクエリがどのテキストトークンに対応するか」を明示的に制御する点が異なる。生成されたクエリは 
Cross-Modality Decoder に入力され、画像特徴に対するクロスアテンションとテキスト特徴に対するクロスアテンション
を通して更新される。最終的なデコーダの出力に対しては、テキストと画像領域の整合性を測るコントラスト損失と、
バウンディングボックスの位置精度を評価するローカライゼーション損失が同時に適用され、
テキストフレーズと画像中の領域が一貫した形で対応付けられるように学習される。

GLIP との比較という観点では、両者とも「テキストを入力として任意の語彙の物体検出を行う」という点で共通しているものの、
GLIP が比較的シンプルな検出ヘッドの上にテキストとのクロスアテンションを載せた構成であるのに対し、
Grounding DINO は DINO 系の強力な Transformer 検出アーキテクチャをそのまま活かしつつ、Feature Enhancer 
と Cross-Modality Decoder という二段構成で画像特徴とテキスト特徴を深く融合している点が大きな違いである。
また、DINO と比較すると、DINO はあくまでクラス数が固定されたクローズドセット検出器であり、クラス埋め込みは
モデル内部に固定されているのに対し、Grounding DINO はクラス名やフレーズをテキストとして与えることで、
クラス集合を外から自由に指定できるオープンボキャブラリ検出器となっている。

利点としては、DINO 由来の高い検出精度と学習安定性を維持したまま、GLIP のように自然言語でカテゴリを指定できる
柔軟なゼロショット検出を実現している点が挙げられる。特に高解像度画像に対する検出性能や、長いテキストプロンプト
を扱うスケーラビリティに配慮した設計となっており、公開実装や事前学習済みモデルも整備されていることから、
テキスト条件付き物体検出の実用的な選択肢として広く利用されている。

一方で、Grounding DINO は大規模な Transformer モデルを中核とするため、YOLO 系のような軽量な CNN ベース検出器
に比べると推論時間やメモリ使用量が大きい。
また、事前学習に用いられているデータセットの多くは実写画像であり、線画や彩色済みセル画といったアニメーション画像
とは分布が異なる。そのため、本研究のようにアニメの修正カットに適用する場合には、デフォルメされたキャラクタやアニメ特有
の背景表現に対する検出精度の低下をある程度許容した上で、ゼロショットな候補領域抽出やタグ候補生成のためのツール
として位置付ける必要がある。さらに、GLIP と同様に、検出対象はテキストプロンプトで指定するため、
「どの表現でタグを与えるか」によって検出結果が変動しやすく、アニメ制作で用いるタグ語彙や修正指示の書き方
に合わせたプロンプト設計も重要な検討事項となる。

このように Grounding DINO は、DINO の高精度 Transformer 検出器と GLIP 系の言語条件付きグラウンディング
を統合したモデルとして位置付けられ、クラス集合を固定しない柔軟なタグ付けを可能にする一方で、
計算コストやドメインギャップ、プロンプト依存性といった課題を抱えている。本研究では、YOLO や DINO のような
クローズドセット検出器と比較してタグ設計の自由度が高いという点を重視しつつ、アニメ画像に対する精度や処理コスト
とのバランスを踏まえて、修正カットのタグ付けにおける適用可能性を検討する。

\subsection{各物体検出技術の比較}
\begin{table}[h]
    \centering
    \caption{各物体検出の性能比較}\label{table_objectdetection}
    \begin{tabular}{|l|l|l|}\hline
        物体検出技術 & ベース & ゼロショット性 \\ \hline
        YOLO & CNN & $\times$\\
        DETR & Transformer & $\times$ \\
        DINO & Transformer & $\times$ \\
        GLIP &  & $\bigcirc$\\
        Grounding Dino & Transformer & $\bigcirc$\\ \hline
    \end{tabular}
\end{table}

以上より、各物体検出の性能をまとめたものが
図\ref{table_objectdetection}である。
これまでの議論を踏まえて、本研究ではゼロショット性と高性能なTransformerベースの
物体検出モデルであるGrounding Dinoを採用することにする。

\section{タグ付けのためのポーズ推定}

\subsection{mmpose}

\section{タグ付けのためのVLM}

\subsection{Qwen2.5}

\section{既存画像認識技術の比較}

\subsection{比較指標}

\subsection{比較結果}



\section{おわりに}

結論は、網羅的にかつ簡潔に。

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{アニメ会社への調査}
\section{はじめに}
本章では、日本のアニメーション制作会社様への調査の内容とその結果について述べる。

\section{調査目的/調査方法}
本調査の目的は、日本のアニメーション制作現場において発生した修正やリテイク
がどのように活用されているかを調査し、実際の素材の分析から今後の活用の
観点においてどのように修正、リテイクへのタグを設計するか考察することである。

調査の方法としては、株式会社 ufotable にインターンという形で
受け入れていただき、制作進行の方への聞き込みと実際の素材の分析の2通りによって実施した。


\section{アニメーション制作工程でのワークフロー}
\subsection{全体的な流れ}
まず、日本のアニメーション制作工程でのワークフローの全体像を図\ref{AnimationFlowchart}に示す。
アニメーション制作はまず、脚本・設定・デザインといった工程を済ませた後、
絵コンテ、第一原画、第二原画、動画、色指定・彩色、撮影といった流れで進行する。
以降の小節では、これらの各工程について詳しく触れていく。

\begin{figure}[h]
    \centering
    \includegraphics[width=\linewidth]{fig/AnimationFlowchart.png}
    \caption{日本のアニメーション制作におけるワークフロー}\label{AnimationFlowchart}
\end{figure}


\subsection{脚本・デザイン・設定}\label{kyakuhonsetteidezain}
本格的なアニメの作画の前に行われるのが、脚本・デザイン・設定の工程である。
脚本とは、映像の構成と映像に必要な要素を書き出した物で、登場人物のセリフはもちろん、
キャラクタの行動や感情を示すト書き、シーンの背景や状況などの物語を構成する様々な要素が記述されている物である。

設定・デザインでは、主にストーリー設定、キャラクターデザイン、メカニックデザイン、美術設定、色彩設計などを決定する。
これらは作品のビジュアルイメージや世界観、登場キャラクタなどの仕様書のような物である。後のアニメ制作工程では、
これらの設定・デザインを参照しながら進めることになる。


\subsection{絵コンテ}
絵コンテは監督・演出家が作るべき映像や演出意図、作業指示などを後の工程に伝えるための、
映像の設計図のような物である。具体例を図\ref{ekonnte}に示す。


\begin{figure}[h]
    \centering
    \includegraphics[scale=0.5]{fig/ekonnte.png}
    \caption{絵コンテ [\cite{trigger}より]}\label{ekonnte}
\end{figure}

絵コンテは脚本・設定・デザインをもとにして作成され、主に以下の要素を含んでいる。

\begin{itemize}
    \item カット番号
    \item キャラクタのセリフ
    \item SE 
    \item 大まかに描かれた画面設計図
    \item ト書き
    \item 尺
    \item 細くメモ
\end{itemize}

演出意図や作業の指示を後の工程に正確に伝えることが、この工程で重要なことである。

\subsection{第一原画 (レイアウト・ラフ原画)}
第一原画 (通称1原) と呼ばれる工程は、絵コンテから読み取れた情報や監督、演出から指示された
内容から、画面の設計と動きの設計を行う工程である。

この工程ではレイアウト、ラフ原画 (通称ラフ原) 、タイムシートの作成を行う。
1原に求められる要件は、次のとおりである。

\begin{enumerate}
    \item 1枚は影付きの作画があること
    \item タイムシートがあること
    \item レイアウトがあること
\end{enumerate}

1原で作られるものは全て後の工程の基盤となってくる重要な資料である。
レイアウトとは、カットの背景とキャラクタの位置関係、サイズ感、構図、どのセルに何を描くか
などについての設計図である。レイアウトにおいては、キャラクタなどは丁寧に描いてあることがほとんどである。
タイムシートは何秒何コマ目に何番の絵がくるか、
中割りは何枚か、セルの重ねはどうなっているかといったことを指示するための表である。

ラフ原は後の完成系の原画 (第二原画\ref{dainigenga}) の初期案のようなものであり、動きの設計をするための物である。
ラフ原では、各カットの代表的なキーとなる絵の動きを描く。
ラフ原をどこまでラフに描くかはそのアニメータ次第である。
基本的には丁寧に描かれている場合が多いが、
この段階では動きの設計がメインなので、
衣服の柄など細かい部分は省略して描かれる場合もある。
ラフ原がラフに書かれる理由としては、服の柄など丁寧に書き込んだとしても、
後の修正で動きや構図などの修正が入り、元のラフ原から大きな変更が入る可能性があることが挙げられる。
もしも丁寧に描いたとしても、後の修正で大きく絵が変更になると、その部分の細かな作画が無駄になる。
そのため、最初はラフに動きの設計を行い、修正を踏まえて第二原画\ref{dainigenga}において清書をするというイメージである。
一般にベテランのアニメータほどラフな傾向がある。
動きを描くのが上手いアニメータなどは、ラフ原で丁寧に描いてスピードが落ちてしまうよりも、
ラフな代わりにスピード早く枚数を多くたくさんのカットを描くことでよりアニメ制作に貢献することができるからである。
ただし、新人の場合はラフ原の押さえるべきところを押さえていない場合があるため、なるべく丁寧に描くことが推奨される。


\subsection{第二原画}\label{dainigenga}
第二原画 (2原) は、1原で提出された原画に対して入った様々な修正を踏まえながら、
すべてのフレームを清書する工程である。
基本的に、2原に作業が回ってきた段階で、カット内に1枚は、その修正を上からトレスするだけで
完成する絵が与えられている。2原の人の主な仕事は、
修正の入っていないフレームに対して、修正の入ったフレームを参考にしながら、合わせた絵を描き清書することである。
2原の人は基本的に全てのフレームに対して、影や服の柄など描かなければならない。

2原は、1原で入った修正を見ながら作業でき、自分の絵と修正の絵を見比べて勉強することができるため、
1原と2原の担当者は同一人物であることが好ましい。
しかし、制作スケジュールなどの都合で別々の者が担当するケースも多い。
1原の人が自分の描いた原画に対して、どのような修正が入ったか確認できず、修正から学ぶことができない場合があるのは、
現在の課題となっている。

\subsection{動画}
動画は原画と原画の動きの間を補完する中割りと呼ばれる絵を描く工程である。
原画において指定されたセルを分けるのはこの工程で行われる。
次の工程が彩色工程であるため、塗りあふれなどを防ぐために線を確実に繋ぐことなど、
線の品質についても考慮する必要がある。
原画が紙の媒体で行われていた場合、この動画工程が完了した後、
スキャンを行うことになる。

\subsection{色指定・彩色}
色彩設定によって設定・デザインの工程\ref{kyakuhonsetteidezain}で決められた色のデータをもらい、
動画からもらった線画のどの部分にどの色を塗るのかを決めていくのが色指定の仕事である。
色指定によって決められた色を実際に塗っていくのが彩色の仕事である。
彩色工程は仕上げ工程とも呼ばれる。


\subsection{撮影}
アニメ制作の撮影工程は、コンピュータ上で背景や彩色済みセルなどから完成した映像データを
作り出すことが仕事である。


\newpage
\section{各工程のチェック工程で発生する修正・リテイク}
\subsection{リテイクと修正の違い}
原則として、リテイクは工程が戻り、修正は工程が進むという違いがある。
修正工程は


\subsection{第一原画への修正・リテイク}
演出修正、監督修正、作監修正、総作監修正
\subsection{第二原画への修正・リテイク}
演出修正、作監修正、総作監修正


\subsection{動画への修正・リテイク}



\subsection{彩色への修正・リテイク}



\subsection{ラッシュでの修正・リテイク}



\section{価値の高い修正・リテイク工程とその活用可能性}
作監修正、総作監修正などの修正は、制作のスピードを予測すること、
アニメータの作画の参考になることなどから価値が高いと考えられる。
ADCF ?

\section{第一原画に対する修正の分析}
\subsection{定量的分析}
\subsection{定性的分析}

\section{分析結果から考える修正のタグ設計}


\section{おわりに}




\chapter{調査に基づく修正のタグ付け手法}
\section{はじめに}
\section{修正のタグ付けの流れ}
\section{VLMによる彩色画像のタグ付け}
\section{物体検出による彩色画像のタグ検出}
\section{姿勢推定による彩色画像の推定}
\section{修正部位のタグ付け}
\section{おわりに}


\chapter{評価}
\section{はじめに}
\section{タグ付け精度の評価と考察}
\subsection{実験内容}
\subsection{実験結果}
\subsection{制作進行からの意見}
\subsection{アニメータからの意見}
\section{おわりに}

\chapter{結論}
\section{本論文のまとめ}
\section{今後の課題}


\appendix
\chapter{リテイクに関与しない部分のアニメ会社調査結果}
必要に応じて、付録を載せる。

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%





\backmatter
\chapter{謝辞}
本論文の執筆にあたり、議論して頂いた関係者に感謝する。

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\bibliographystyle{jplain}
\bibliography{references}
%\begin{thebibliography}{99}
%  \bibitem{tokodai-xyz2015} 科学大太郎. 良い論文の書き方. \textit{Journal of XYZ}, Vol.~3, No.~4, pp. 15--34, 2015.
%\end{thebibliography}

\end{document}
