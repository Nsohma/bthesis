\PassOptionsToPackage{dvipdfmx}{graphicx,xcolor}
\documentclass[11pt,oneside,openany,report]{jsbook}

\usepackage[a4paper,truedimen,margin=25truemm]{geometry}
\usepackage{cscover}
\usepackage[dvipdfmx]{graphicx}
\usepackage[dvipdfmx]{xcolor} % ★明示しておくと安全
\usepackage[nobreak]{cite}
\usepackage{amsmath}
\usepackage{bm}
\usepackage{tabularx}
\usepackage{array}
\usepackage{booktabs}
\usepackage[most]{tcolorbox}  % ★ここで tcolorbox
\usepackage[a4paper,dvipdfmx,pdfdisplaydoctitle=true,%
    bookmarks=true,bookmarksnumbered=true,bookmarkstype=toc,bookmarksopen=true,%
    pdftitle={日本のアニメーション制作現場での調査に基く修正素材のタグ付け蓄積},%
    pdfauthor={新穂壮真}%
    ]{hyperref}
\usepackage{pxjahyper}

\renewcommand{\bibname}{参考文献}
\setcounter{tocdepth}{2}
\pagestyle{plain}

\newcommand{\TODO}[1]{\textbf{[TODO: #1]}}
%\renewcommand{\TODO}[1]{}

\thesistype{学士特定課題研究論文}
\title{日本のアニメーション制作現場での調査に基く修正素材のタグ付け蓄積}
\author{新穂 壮真}
\studentid{22B30610}
\affiliation{東京科学大学\\情報理工学院\\情報工学系} 
\date{2026年1月}

\supervisorname{指導教員}
\supervisor{齋藤 豪}
%\dsupervisorname{副指導教員}
%\dsupervisor{工学 次郎}

\begin{document}

\frontmatter
\maketitle

\chapter{概要}
ここに概要を書きます。

\tableofcontents
\listoffigures
\listoftables

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\mainmatter
\chapter{序論}
\section{本論文の背景と目的}

近年、アニメーション制作のデジタル化が進み、作画や撮影、編集
といった各工程においてコンピュータ上での作業が一般的になってきている。
それに伴い制作過程で扱うデジタルデータの量も増加している。
%これに伴い、制作過程で生成されるレイアウト、原画、動画、仕上げ画像など、
%さまざまなデータをどのように蓄積し利活用するかが重要な課題となっている。
とくに日本のアニメーション制作では、セルアニメーション由来の分業制やカット単位の工程管理が
現在も広く採用されており、各工程で多数の中間生成物や指示書類が発生し、
作品制作の過程で複雑に行き交っている。
その一方で、これらのデータが制作後に体系的に整理・蓄積されることは少なく、
制作ノウハウや現場での判断の多くが個人の経験や属人的な管理に依存しているのが現状である。

こうした状況を受けて、これまでにアニメーション制作におけるデータ管理や
中間生成物の蓄積を目的とした研究・システム開発がいくつか行われてきた。\cite{aimdb}\cite{fucci}
しかし、それらはいずれも修正という行為そのもの、
すなわち演出や作画監督による修正指示や、その結果として更新された原画・動画といった情報を、
データ活用の観点から蓄積することには十分な焦点を当てていない。
新潟大学アニメ中間素材データベース AIMDB\cite{aimdb} はアニメ制作過程におけるデータの蓄積を目的としたデータベースであり、
リテイクをはじめとした様々な素材の蓄積に対応しているが、データ活用を意識した蓄積構造が設計されているとは言い難い。
渕上ら\cite{fucci}の研究では、データ活用を見据えた中間生成物の蓄積を行っているが、
修正に関する蓄積には対応していない。
修正は、作品のクオリティや作業者ごとの傾向を端的に反映する情報でありながら、
多くの場合は各カットの中に埋もれた形で扱われ、体系的に蓄積・分析されてこなかったと言える。

そこで本論文では、実際のアニメーション制作現場で役立てる視点から、
修正の活用方法の提案と、それを見据えた修正の整理・蓄積を考える。
%その蓄積と利活用を主な対象とする。具体的には、原画や動画に対する演出修正・
%作画監督修正などの作画上の修正情報を、従来のカットや中間生成物の管理とは
%独立した形で収集・構造化し、それらを分析することで制作進行を円滑にするための
%システムを提案することを目的とする。
この目的を達成するため、まず制作現場における修正の活用事例を調査し、現状の課題を抽出する。
その上で実際の修正素材を見て分析し、
どのような単位・粒度で修正を蓄積すべきかを整理し、修正に対してつけるタグについて設計する。
次に、その結果に基づき、修正の自動タグ付けを行うシステムを提案し、
同システムから得られるタグが実運用に耐えうる精度であるかについて議論・検証を行う。
%最後に、提案システムを用いて修正データの傾向分析や可視化を行い、
%その結果から制作進行の計画立案や人員配置の最適化といった場面における有用性を検証する。





\section{本論文の構成}
本論文は6章から構成されている。各章の内容は以下の通りである。

\vspace{\baselineskip}

\noindent
\textbf{1章 序論}

本章では、本研究の背景と目的について述べる。

\vspace{\baselineskip}

\noindent
\textbf{2章 関連研究}

本章では、関連研究としてアニメーション制作に使用されるツールやアニメーション制作の
現状、及び画像認識技術やVLMについて述べる。

\vspace{\baselineskip}

\noindent
\textbf{3章 アニメ会社への調査}

本章では、アニメーション会社に対して行った調査と結果について述べる。

\vspace{\baselineskip}

\noindent
\textbf{4章 調査に基づく修正のタグ付け手法}

本章では、アニメーション会社への調査結果を踏まえて、
本研究で提案するシステムの設計と実装について述べる。

\vspace{\baselineskip}

\noindent
\textbf{5章 評価}

本章では、本研究で提案する自動タグ付けシステムの精度について評価・考察する。

\vspace{\baselineskip}

\noindent
\textbf{6章 結論}

本章では、本論文のまとめ及び今後の課題について述べる。


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\chapter{関連研究}
\section{はじめに}
本章では、本研究に関連する従来研究として、日本のアニメーション制作においてデータ管理を目的とした
ツールや中間生成物の蓄積に関する研究について述べる。最後に、本研究を実現するための
既存技術である画像認識技術やLLMについて述べる。

\section{アニメーション制作のデータ蓄積と活用方法の現状}
本節では、日本のアニメーション制作のデータ蓄積の現状と検討されている活用方法について述べる。

\subsection{アニメーションアーカイブの現状2017\cite{yamakawa}}
山川氏は、株式会社プロダクション・アイジーにおいてアーカイブグループのリーダを務め、
業務中に発生したアニメーション制作資料の収集・整理・選別・保管と、その利活用への対応を主な業務としている。
記事では、2017 年時点のアニメーションアーカイブの現状として、
社内スタッフからの問い合わせが月最大 200 件にも達し、
その内容が新作や続編制作のための設定画・色指定データの取り出し、
アニメータや演出家に仕事を発注する際の作風確認、新人教育用の原画貸出、商品化や映像配信、展示企画のための資料提供など多岐にわたることが紹介されている。
このような事例から、過去の原画や設定資料などの中間生成物 が、
制作・教育・商品開発などさまざまな用途において日常的に参照されており、
その活用意義が非常に大きいことがわかる。

中間生成物は、映像を作成する過程で発生した素材のことを指す。
その種類としては、企画書、脚本、絵コンテ、設定、カット袋 (レイアウト・原画・動画・修正・タイムシート・
3D用素材etc) 、カラーモデル、3Dモデル、3Dシーン、色指定・仕上げ、背景、撮影、編集、
音響、アフレコ台本、納品前映像、ロケハン資料、版権画、セル画、宣伝資料、
納品映像(HD-CAM、フィルム) など多様なものが挙げられる。

このように、
多様な種類の資料が大量に発生するため、その全体像を把握できる人材は限られており、
評価選別や保管には大きなコストを要する。
その結果、多くの制作会社では、
資料の大部分が十分な整理を経ずに失われている現状がある。
山川氏は、中間生成物をアーカイブや利活用時に困らない方法で管理することの重要性を述べている。

\subsection{アイデアソンによるアニメーション中間生成物の活用可能性の検討\cite{matsushita}}
松下らは、日本のアニメーション制作が限られた人員で多数の作品を制作しているため、
制作過程で生まれる中間生成物の整理が十分に行われておらず、多くが廃棄されてしまう現状を指摘している。
一方で、こうした中間生成物はアニメーションの文化資本としての価値を持つにもかかわらず、
具体的な利用用途が見えにくいがゆえに、「コストをかけてでもアーカイブする」という動機づけ
が生じにくいことを問題としている。そこで松下らは、中間生成物の利用用途と活用可能性を検討するため、
2022 年にアイデアソンを実施している。

このアイデアソンでは、国立情報学研究所が公開しているリトルウィッチアカデミアの制作素材
（トリガーデータセット\cite{trigger}）を対象とし、計 27 名の学生が 7 チームに分かれて議論を行った。複数日
にわたるグループディスカッションと成果発表を通じて、モブキャラ作成システム、新人アニメータの
自主練習支援システム、原画データベースシステムなど、さまざまな活用案が提案されている。
これらの案は最終的に、中間生成物の横断的検索の必要性、機械学習用リソースとしての活用、
新たな表現メディア創出の手がかり、という三つの観点に整理され、中間生成物が制作・教育・研究・
ビジネスの各側面から広い応用可能性を持つことが示されている。

しかし、これらのアイデアが全ての解ではなく、特にユーザ視点での活用についてはまだまだ不足していると言える。
一方で松下らは、中間生成物の関係性が整理されて容易に利用可能になることで、
ボトムアップな活用案の創出が期待できることを示唆している。
現在、中間生成物の修正の整理は行われていないため、そうした研究が求められている。

\subsection{渕上らのアニメ会社の調査\cite{fucci}}\label{fucci_investigate}
渕上らは、中間生成物とそれに関連するアニメータの行動、
および中間生成物の活用方法を明らかにするため、アニメーション制作会社
に対する調査を実施した。調査対象は株式会社スタジオエイトカラーズ、株式会社 OLM、
有限会社神風動画、Kaikai Kiki Animation Studio PONCOTAN であり、
制作現場での定点観察、対面インタビュー、意見交換、アンケートなどの手法を用いて
情報収集を行った。
調査の結果、中間生成物の主な活用方法として、以下の 4 点が挙げられている。

\begin{enumerate}
    \item 教育のための検索 \\ベテランアニメータがアニメーション制作を学んできた過程を調査したところ、原画本や修正指示の様子、類似カットなどの素材を閲覧することで学んできたという回答が多かった。そのため、新人アニメータが参照すべき中間生成物を手元から検索・閲覧できるようにすることは、教育の促進に有効であると考えられる。特に、修正指示や修正過程を併せて閲覧でき、新人の視点を補うような情報が付随していることが望ましい。
    \item 修正指示のための検索\\アニメ制作における修正指示の出し方には、原画シートへの書き込みや補助資料の送付など複数の方法が存在する。動きの説明などのために補助資料を用いる場合も多いが、中間生成物が十分に整理されていない現状では、適切な資料を探すのに多くの時間を要する。修正指示に用いる素材を検索によって素早く取得できれば、指示内容の簡潔化やリテイク数の減少に寄与すると考えられる。この用途の検索は動きなどに特化したものである必要があり、アニメーション制作向けのアノテーションやタグ付けが求められる。
    \item 作画の参考資料としての検索\\アニメータは、慣れないカットを描く場合や再現しにくい動きを捉える場合に、似た素材を検索して作画の参考にする。こうした素材を中間生成物から検索・参照できれば、作画作業を直接支援する機能として有用である。
    \item 素材の使い回し\\3DCG 素材や背景素材などは、作品内で再利用されることがある。しかし、中間生成物が十分に整理されていないと、再利用可能な素材を即座に取り出すことは難しい。使い回し可能な素材を検索によって取得できれば、作業効率を大きく向上させることができる。
\end{enumerate}

また、中間生成物と関連するアニメータの行動として、
設定資料の閲覧、演出からの指示、タイムシートの更新履歴などが挙げられている。
渕上らは、これらの中から特に設定資料の閲覧履歴に着目し、
中間生成物の構造的な蓄積を達成した。

\section{アニメーション制作におけるデータ管理用ツール}\label{relative_tool}
この節では、日本のアニメーション制作で用いられているデータ管理用ツールについて
述べる。

\subsection{flow production tracking(旧shot grid)\cite{shotgrid}}
flow production tracking は、Autodesk 社が提供するクラウド型のプロダクション管理ツールであり、
映像・CG・アニメーション制作やゲーム開発などの分野で用いられている。
プロジェクト内の作業単位をタスクとして管理し、ショットやアセット
（キャラクタ、プロップ、背景環境などの制作要素）と関連付けることで、
制作工程全体の進捗を可視化することができる。スケジュール管理の面では、図\ref{shotGridSchedule} のように
ガントチャートによるタスクの開始日・終了日・期間の表示や、担当者・ステータスを含めたタスク一覧
ビューが提供されており、プロジェクト全体の進行状況を把握しやすい設計となっている。

\begin{figure}[h]
    \centering
    \includegraphics[width=\linewidth]{fig/shotGridSchedule.png}
    \caption{flow production tracking のスケジュール管理機能}\label{shotGridSchedule}
\end{figure}

また、図\ref{shotGridReview}のようにアップロードされた動画や静止画に対してコメントや描き込みを行うレビュー機能や、
バージョン違いのメディアを切り替えながら確認できるインタフェースも備えており、
オンライン上でのレビュー・承認ワークフローを支援している。

\begin{figure}[h]
    \centering
    \includegraphics[width=\linewidth]{fig/shotGridReview.png}
    \caption{flow production tracking のレビュー機能}\label{shotGridReview}
\end{figure}


さらに、図\ref{shotGridAsset}のようにアセット管理の機能として、
キャラクタや背景などのアセットに対して
任意のフィールドやステータスを追加し、担当者や進捗状態といった情報を一元的に管理できる。
ユーザごとにアクセス権限を設定する仕組みも用意されており、権限に応じて閲覧・編集可能な情報
を制御しながら、スタジオ内で共通の制作基盤として利用できるようになっている。
このように、flow production tracking は ショット・アセット・タスク を中心とした汎用的な
パイプライン管理ツールとして設計されており、スケジュール管理・レビュー・アセット追跡を統合的
に扱える点に特徴がある。


\begin{figure}[h]
    \centering
    \includegraphics[width=\linewidth]{fig/shotGridAsset.png}
    \caption{flow production tracking のアセット追跡機能}\label{shotGridAsset}
\end{figure}


一方で、多機能であるがゆえに初心者には扱いづらく、
直感的でない複雑なツールになっているという指摘もなされている。
また、導入コストが高いことや、日本のアニメーション制作で使用されるタイムシートなどへの対応ができないこと、
リテイク処理に対応できずリテイク用の別名カットを新たに作成する必要があるため、本来の意図と異なる使い方を
強いられる場合があることなど、日本のアニメーション制作現場での利用においてはいくつかの課題が残るとされている。
そのため、flow production tracking はタスクやアセット単位の進捗管理やレビューの基盤としては有用である一方で、
アニメ制作で発生する修正をデータ活用の観点から蓄積するための仕組みとしては十分とはいえない。


\subsection{save point\cite{savepoint}}
save point は株式会社 MUGENUP のプロジェクト管理ツールであり、イラストや 3DCG、映像、
広告アセット、アニメーションなど様々なクリエイティブ制作に対応している。制作スケジュール
や進捗、コミュニケーション、レビューをツール内で管理することで、情報共有を簡単に行える自由度
の高いツールとなっている。図\ref{savePointSchedule} のように、制作スケジュールや各工程の進捗を
ガントチャート形式で一覧できるスケジュール管理機能を備えており、プロジェクト全体の工程と期間
を俯瞰して把握することができる。

\begin{figure}[h]
    \centering
    \includegraphics[width=\linewidth]{fig/savePointSchedule.png}
    \caption{savepoint のスケジュール管理機能}\label{savePointSchedule}
\end{figure}


また、図\ref{savePointThread} に示すようなスレッド機能やレビュー
機能を通じて、各カットや素材ごとにファイルのアップロードや修正指示、コメントのやり取りを行える
ため、中間生成物の確認や指示を行う際に活用されている。ツール紹介では「コストを save」
「データを save」「ディレクターを save」の三つの save を掲げており、制作進行担当者や
ディレクターの業務負担の軽減と、データの一元管理による人的ミスの防止を主な目的としている。


\begin{figure}[h]
    \centering
    \includegraphics[width=\linewidth]{fig/savePointThread.png}
    \caption{savepoint のスレッド機能}\label{savePointThread}
\end{figure}


さらに save point を基盤として、アニメの制作進行に特化した「Save Point for アニメ」
も開発されている。Save Point for アニメ は、カット袋が担ってきた素材の受け渡しと作業指示書、
進行管理の機能をクラウド上で統合的に扱うことを目指したツールであり、絵コンテや原画、動画などの
素材の納品から、監修や修正指示に関するやり取り、スケジュールや進捗状況の管理までをブラウザ上
で一元化できるとされている。アニメ特有の進行表やカット表をツール内で再現したインタフェースや、
図\ref{savepointFinger}のように
紙のタイムシートをめくる「指パラ」に相当するフレーム単位の動きの確認機能、ガントチャートによる
工程スケジュールの可視化などを備え、アニメ制作の現場で使い慣れたワークフローとの親和性を意識した
設計になっている。

\begin{figure}
    \centering
    \includegraphics[scale=0.5]{fig/savepointFinger.jpg}
    \caption{save point for アニメの指パラ機能}\label{savepointFinger}
\end{figure}

しかし save point は、プロジェクト管理に重点を置いたツールであり、蓄積した中間生成物を将来的
に分析・再利用するデータ基盤として設計されているわけではない。実際に、
save point 内の検索機能も欲しい中間生成物があらかじめ明確になっていることを前提としたファイル
や制作物の検索が中心であり、中間生成物の属性や内容からの
高度な検索や分析には応用しづらい。save point および Save Point for アニメ は進行管理や
コミュニケーションの効率化には有効である一方で、中間生成物を後の運用の観点から
整理し蓄積する仕組みは備えていないと言える。

\subsection{Hiero\cite{hiero}}
Hiero は Foundry 社が提供する Nuke ファミリーのツールであり、マルチショット編集やコンフォーム、
レビューをタイムラインベースで扱うことを目的としたソフトウェアである。
複数ショットをまたいだバージョン管理や再生確認、簡易的な編集作業を
一つのプロジェクト内で行うことができる。

レビュー機能としては、タイムライン上のフレームに対して描き込み付きの
アノテーションやコメントを付与でき、
後工程の担当者に修正内容を伝えるワークフローが想定されている。
一方で、こうしたアノテーションはあくまで各プロジェクト内のレビュー情報として扱われており、
修正指示そのものを、作品をまたいで横断的に検索・分析するための
データとして管理する枠組みは提供していない。したがって Hiero はアニメ制作進行の
効率化には有効であるが、修正素材を整理し蓄積するには不十分であると言える。

\subsection{アニクロ\cite{anikuro}}
アニクロは、メモリーテック株式会社が提供するクラウド型アニメ制作管理システムであり、
「カット袋をデジタル化しませんか？」というコンセプトのもと、カット袋やタイムシートを
オンライン上に再現して制作工程を管理することを目指している。工程ごとに素材ファイルをアップロード
して紐付ける工程管理・素材管理機能や、ブラウザ上で作画ファイルをプレビューし、コメントや手書きの修正指示
を書き込めるチェック機能を備えており、従来紙ベースで行われてきた受け渡しや指示をクラウド上で完結できる点が特徴である。

また、Web 上で共有可能なデジタルタイムシートや、自動更新されるカット表・日報表、複数カットに対する一括リテイク
出しやリテイク一覧表示などの機能により、作品単位での進行管理とリテイク管理を一元的に行うことができる。
このようにアニクロは、日本のセルアニメーション制作で用いられてきたカット袋やタイムシートの運用に対応した
制作管理ツールとして有用である一方で、アップロードされた中間生成物を属性や内容から整理する仕組みまでは提供していない。
したがって、アニクロは修正素材を整理し蓄積するという目的では運用できない。



\subsection{OLM FM tool\cite{olmfmtool}}
OLM FM Tool は、株式会社 OLM がデジタル作画パイプライン構築の一環として社内開発したファイル管理
ツールであり、リモートワーク環境における素材配布や成果物回収を円滑に行うことを目的としている。
制作データを Google ドライブ上に保存したうえで、作品・話数・カット・工程といった日本のアニメ制作
の単位に沿ってブラウズできる専用インタフェースを提供し、図\ref{OLMFMTool}のように、
ファイルやフォルダの個別・一括ダウンロード
やアップロード、フォルダの作成や削除などの操作を一画面から行うことができる。
これにより、従来のフォルダ構成では把握しづらいディレクトリ階層を現場向けに分かりやすく整理するとともに、
データ紛失を起こすことなく、低速なネット環境でも比較的快適に素材を扱うことができる点が特徴的であり、
リモートワークへの対応力の高さが強みである。

\begin{figure}[h]
    \centering
    \includegraphics[width=\linewidth]{fig/OLMFMTool.png}
    \caption{OLM FM toolの自由度の高いディレクトリ操作機能}\label{OLMFMTool}
\end{figure}

一方で、OLM FM Tool はあくまでフォルダ階層とファイルパスに基づく素材管理を主眼としたツールであり、
データベース上に中間生成物を蓄積するわけではなく、オンラインストレージ上にファイル
を保存しているにとどまるという限界がある。


\subsection{Redmine\cite{redmine}}
Redmine はオープンソースの Web ベースプロジェクト管理ツールであり、チケットによる課題管理や
ガントチャート・カレンダーによるスケジュール管理、Wiki・フォーラムによる情報共有機能などを備えている。
プロジェクトごとにチケット種別やワークフロー、カスタムフィールドを定義できる汎用的な設計となっており、
ソフトウェア開発以外の業務管理やコンテンツ制作にも広く用いられている。

アニメーション制作においても、図\ref{redmineChiket}のように各カットや工程をチケットとして登録し、
担当者・期限・ステータスを設定することで、進行状況の把握やタスク割り当てに利用することができる。
しかし Redmine はあくまで汎用的な課題管理ツールであり、
日本のアニメーション制作に特有のカット袋やタイムシートの運用を前提としておらず、原画・動画に対する個々の修正指示や
修正後素材を作品やアニメータをまたいで横断的蓄積するデータ構造は備えていない。

\begin{figure}[h]
    \centering
    \includegraphics[scale=0.5]{fig/redmineChiket.png}
    \caption{Redmine のチケット機能}\label{redmineChiket}
\end{figure}

\subsection{株式会社サンジゲンの制作管理ツール\cite{sannjigenn}}
株式会社サンジゲンは 3DCG アニメーション制作を主業務とするスタジオであり、
日本のアニメ制作に適した市販パッケージが少ないことから、自社内で制作管理システム
とデータベースを構築している。従来 Excel で管理していた工程表ではタイトル数
やカット数の増加に対応しきれなくなったことを受け、発注情報やスタッフの作業状況、日報、チェック結果、
収支などを一元管理できる仕組みを整備している。
制作の進行状況やステータスはもちろん、チャット機能やアップロード通知の機能など、
制作支援のための機能を幅広く備えている。
アップロードされた中間生成物を参照しながらレビューを行うことも可能であり、
日本のアニメーション制作の工程に幅広く対応している

また、アップロードされた映像データは自動エンコードされて Hiero に蓄積され、
社内ツール SanzigenCutManager と連携して最新テイクと過去テイクの比較チェックを行えるなど、
大規模 3DCG 制作におけるレビューと進行管理を効率化する基盤として機能している。一方で、
修正素材を、整理し蓄積しているわけではなく、修正は主としてスケジュール・品質管理上のイベント
として扱われていると考えられる。


\section{アニメーションの中間生成物の蓄積に関する研究}\label{relative_database}
この節では、日本のアニメーション制作における中間生成物の蓄積に関する研究について述べる。

\subsection{新潟大学アニメ中間素材データベースAIMDB\cite{aimdb}}
新潟大学アニメ中間素材データベース AIMDB は、
アニメーション制作における中間生成物を体系的にアーカイブすることを目的として構築されたデータベースである。
扱っている中間生成物は原画、動画、修正原画、脚本、リテイクなど多岐にわたり、
制作過程で生じるさまざまな資料を対象としている。

AIMDB の研究目的は、中間生成物のアーカイブ化とデータ処理・分析、
セル画の保存システムの開発であり、特に制作時に散逸しがちな中間生成物を蓄積することに焦点を当てている。
蓄積された中間生成物の一部は公開されており、
アーカイブされたデータはそれぞれの属性をもとに検索ができる。
図\ref{AIMDB}に示すように、作品名や制作会社、中間生成物の種類といった項目によって絞り込みを行うことが可能である。

\begin{figure}[h]
    \centering
    \includegraphics[width=\linewidth]{fig/AIMDB_mid.png}
    \caption{AIMDB}\label{AIMDB}
\end{figure}

一方で、このデータベースにはアニメータが制作業務の中で直接利用できるような入力インタフェースは提案されておらず、
中間生成物を蓄積するためには、過去の制作で用いられた資料をスキャンしてデータ化し、
技術者が手作業でデータベースに登録する必要がある。
また、タイムシートの取り扱いは紙媒体のみを対象としており、
デジタル形式（XDTS\cite{xdts}など）には対応していない。
さらに、検索も主として作品名や会社名など既知の属性を前提としており、
修正の内容や中間生成物同士の関係性といった観点から自由度の高い検索を行うには、
十分なデータベースであるとは言い難い。

\subsection{実務家に聞くアニメアーカイブデータベースの可能性と課題
新潟大学アニメ中間素材データベース(AIMDB)へのフィードバックから\cite{matsumoto}}
新潟大学アニメ・アーカイブ研究センターでは、過去のアニメーション作品の中間生成物の
アーカイブを進めており、先述した AIMDB\cite{aimdb} として閲覧者を限定して公開している。
松本は、この AIMDB を用いた科研費プロジェクトの一環として、
Production I.G でアニメアーカイブを推進する山川道子氏と、
東映アニメーションでシニアプロデューサーを務める野口光一氏に
AIMDB を試用してもらい、アニメ制作の実務家としての所感をヒアリングしている。

山川氏と野口氏からは、例えば、
ニーズに応じて解像度の異なるデータを用意してはどうかという指摘や、
タグ付けや香盤表の情報だけでは十分ではなく、
目的に応じて資料を読み解き適切に案内できる
リファレンス能力を持ったアーキビストの育成が不可欠であることなどが挙げられている。
また、現場に共有されないまま早い段階で破棄されてしまう資料の存在を前提に、
絵コンテからのキーワード抽出によって香盤表的な情報を補完するなど、
失われがちな文脈情報を補う仕組みの必要性も指摘されている。

これらの意見からは、単に中間生成物そのものを保存するだけでなく、
検索や利活用の起点となるメタデータや文脈情報をあわせて蓄積する重要性が示唆されている。

\subsection{長尾らのデータベース\cite{nagao}}
セルアニメーション由来の手描きを含む制作手法を用いる日本のアニメーション制作では分業制が採用されており、
1 カットに対して携わる人数が多い。さらに、制作現場ごとに制作プロセスが異なるため、
業界内での画一的な中間生成物の管理は困難であり、スタジオごとにそれぞれ独自の手法で中間生成物を管理している。
しかし、共通の形式でデータを蓄積できなければ、中間生成物の活用を見込むことは難しく、貴重とされる中間生成物
が十分に生かされないまま終わってしまう。

これらの事実を受けて、長尾らはアニメーション制作完了後に残された中間生成物を調査し、
画一的な管理手法としてリレーショナルデータベースを提案した。具体的には、2014 年に株式会社スタジオ
コロリドと株式会社ロボットが共同制作を行ったマルコメ株式会社の「料亭の味」の CM アニメーション
\cite{marukome}「単身赴任編」と「夜食編」 の 2 つのエピソードを対象に調査を行っている。
中間生成物を含むディレクトリ構造を分析した結果、以下の 5 点の課題を挙げている。

\begin{enumerate}
    \item ディレクトリの構成や命名規則がはっきりしておらず、必要となるファイルの在処を把握するのが困難
    \item 同一内容のファイルが複数のディレクトリに点在
    \item 工程の進捗状況を知るためには、複雑なデータ構造の確認が必要
    \item チェックの意図がファイル構造やファイル名からは判別しづらい
    \item 一部のファイルについてはデータ自体が残されていない
\end{enumerate}

これら 5 点に対して、長尾らは課題に適した設計指針を示している。設計指針としては、カット単位でデータ
を扱うこと、データの種類をタイムシートに関わるものとそうでない場合を分別できること、 
タイムシートの情報ではフレームとレイヤの情報を持てること、修正前後を含む全てのデータが確認できること
が挙げられている。カット単位で中間生成物を管理することは、カット袋での管理が基本である日本のアニメーション
業界において標準的であり、同一ファイルが複数箇所に点在するようことを防ぐメリットがある。また、
工程ごとにデータを管理することによって、必要となるファイルの在処を明確にし、進捗状況を把握しやすくすることができる。

これらの設計指針を基準に作成したデータベースが以下の図 \ref{Nagao} の 22 のテーブルからなる
リレーショナル・データベースである。カット、ファイル、作業の 3 つのテーブル群をフレームやレイヤなど
のテーブルで結びつけ、カットやファイル、作業を関連付けている。また、登録日時と更新日時を蓄積することで、
作業履歴を追跡可能な構造となっている。

\begin{figure}[h]
    \centering
    \includegraphics[width=\linewidth]{fig/NagaoDatabase.jpg}
    \caption{長尾らのデータベース}\label{Nagao}
\end{figure}

長尾らのデータベースは日本のアニメーション特有の制作手法に特化した構造となっており、
従来では管理が難しかった日本のアニメーション中間生成物を統一的な形式で扱うことを可能にした点に特徴がある。

\subsection{夏らのシステム\cite{yiyi}}
夏らは先述した長尾らのデータベース \cite{nagao} に対して、
原画と動画の中間生成物を蓄積できる WEB システムを提案している。
このシステムはアニメータ自身がアニメーション制作中に中間生成物を蓄積できる設計になっており、
制作後にまとめてアップロードするという手間を省くことができる。

中間生成物を蓄積する具体的な方法は、WEB インタフェース上の作業ページからのアップロードである。
アップロードの形式はレイヤ別の絵とタイムシートを含めたディレクトリ構造を zip 形式に圧縮
したものであり、作画ツールとして主流である CLIP Studio Paint \cite{clipstudio} で
描いた絵やタイムシートを容易にその形式にできることから、ツールとの連携も容易である。アップロード
により蓄積した中間生成物は図 \ref{XiaWorkpage} に示す作業画面にて確認をすることができる。

\begin{figure}[h]
    \centering
    \includegraphics[width=\linewidth]{fig/XiaWorkpage.png}
    \caption{夏らのシステム : 作業画面}\label{XiaWorkpage}
\end{figure}

作業ページのインタフェースはカット袋やタイムシートなど、
日本のアニメーション制作で使用される管理手法と似た表形式を意識して設計されており、
アニメータが違和感なく利用できるように配慮されている。
また、単に中間生成物をアップロードするだけでなく、下記のような制作支援機能を提供することで、ア
ニメータが制作途中に中間生成物を蓄積するモチベーションを高めている。

\begin{enumerate}
    \item タイムシートの編集 \\
    アップロードされたタイムシートはインタフェース上で編集を行うことができる。
    タイムシートのセル値の入力や削除、セル値の移動、undo、redo、コピー、ペーストなどができ、ユーザが容易に編集可能である。
    タイムシートの編集ができるツールは東映デジタルタイムシート \cite{toei} など限られていることから、本機能は貴重である。
    \item 映像作成 \\
    インタフェース上のタイムシートとアップロードされた原画や動画を使用して、
    現状の映像を作成することができる仕組みとなっている。
    映像作成は線画に対応しており、レイヤの重ね合わせはもちろん、
    特定のレイヤのみを用いた映像を作成することも可能である。
    \item 版による履歴管理 \\
    アニメータは自身の作業の中で、絵を描き換えやタイムシートを編集などの変更を加える。
    夏らのシステムではこの変更の際に、素材を上書きせず、過去の版の内容を復元可能な形で蓄積する。
    具体的には、映像作成時や再アップロード時に自動で過去の版を登録する。
    この蓄積方法により、過去の版の中間生成物を復元することが可能となり、
    インタフェース上で確認できる。版の保存は映像確認を行った際に、ユーザ自身の要望に応じて行うことができる。
    \item 版を用いた映像比較 \\
    過去の素材を版として蓄積しているため、各版時点での映像をインタフェース上で作成できる。
    また、過去の版を複数選択すれば、図 \ref{XiaVideopage} に示すインタフェースで、
    最大 4 つの版の映像を同時再生により比較できる。この映像比較機能によって、
    アニメータがより良い版を選択できるだけでなく、
    試行錯誤の過程とその結果をデータベースに蓄積することができる。
    正解例のみならず失敗例も蓄積することで、試行錯誤の意図の理解に資する可能性がある。
\end{enumerate}


\begin{figure}[htbp]
    \begin{center}
        \includegraphics[scale=0.5]{fig/XiaVideopage.png}
    \end{center}
    \caption{夏らのシステム : 映像比較}\label{XiaVideopage}
\end{figure}

このような制作支援を通して、多忙なアニメーション業界での使用可能性を高めている。
蓄積するタイミングが制作途中であるために、最終版の中間生成物のみでなく、途中経過の中間生成物を蓄積
できることも大きな強みである。また、本システムは WEB システムであるので、アニメータが使用する環境
を構築するのが容易であり、導入難易度が比較的低い点も利点として挙げられる。

\subsection{渕上らのシステム\cite{fucci}}
渕上らは、\ref{fucci_investigate}節の調査結果に基づき、夏らのシステムを拡張した新しいシステムを提案した。本システムは、アニメータの行動履歴と中間生成物を関連付けて蓄積することで、中間生成物の構造的な保存を可能にしている。 さらに、夏らのシステムが原画・動画工程のみを対象としていたのに対し、
本システムではレイアウト工程や仕上げ工程、および各工程間のチェック工程まで対応範囲を拡大した。 夏らのシステムと同様、Webシステム上での情報伝達の過程で、各工程の中間生成物が自動的に蓄積される設計となっている（図\ref{fucciInforFlow}）。

また、渕上らは、アニメ制作会社における導入の動機付けを強化するため、制作クオリティの向上や作業時間の短縮に寄与する付加価値機能を実装した。主な機能は以下の通りである。

\begin{enumerate}
\item TDTSへの対応とインタフェース改善\\
デジタルタイムシート形式である TDTS の読み込みに対応させ、工程に応じて原画欄と動画欄を切り替えて利用できるようにしている。
また、セル幅を削減することで十分なセル数を画面上に表示可能とし、紙のタイムシートに近いレイアウトを実現している。
さらに、タイムシート上のセルにマウスオーバーした際に対応する絵を表示する機能を設けることで、
映像を生成せずともカットの完成度を簡易的に確認できるようにしている。
\item 色付き素材を考慮した映像作成\\
仕上げ工程を想定し、レイヤ合成時にアルファ値を考慮した映像作成機能を実装している。
これにより、線画のみを対象とした夏らのシステムと異なり、色付きのセルを用いた映像確認が可能となっている。
\item 各工程ツールとの連携と作業ファイルのダウンロード\\
原画・動画・ペイントといった各工程で主に用いられる CLIP STUDIO PAINT との連携を考慮し、
XDTS や TDTS 形式のデジタルタイムシートと各セルの絵を含むディレクトリ構造を zip 形式でダウンロードできるようにしている。
過去の版や最新の版を選択して中間生成物一式を取得できるため、現場の作業フローに組み込みやすい構成となっている。
\end{enumerate}

以上のように、制作現場の本システムを利用するモチベーション向上に繋がる付加価値の実装と、
中間生成物の構造的な蓄積を実現した点が、
本研究におけるアニメ制作支援への大きな貢献である。

\section{データ管理に関する既存アニメ関連ツールの比較}
\ref{relative_tool}節と\ref{relative_database}節で
述べたデータ管理に関する各手法やツールを目的、制作現場での使用、制作中の保存、構造的な蓄積、修正の整理蓄積という
4 つの観点より比較する。

まず、各指標の選定理由について述べる。
目的の項目では、手法やツールごとに何を目指しているか明らかにし、蓄積への注目度を示す。
制作中の保存の指標は、アニメータ自身が制作中に中間生成物を蓄積できるかを示すものであり、
制作と別途コストを割かずに蓄積するためには、アニメータ自身が制作中に蓄積できることは必要不可欠である。
構造的な蓄積の指標は、蓄積したデータを将来的に活用するために、中間生成物同士の関係性が構築されているかを示す。
修正の整理蓄積においては、修正を対象とした適切な整理蓄積が行えているかについて示す。

\begin{table}[h]
    \centering
    \caption{データ管理に関するツールと手法の比較}\label{relativereserach}
    \scalebox{0.8}{
        \begin{tabular}{|c|c|c|c|c|c|}\hline
        手法・ツール & 目的 & 制作中の保存 & 構造的な蓄積 & 修正の整理蓄積 \\ \hline
        flow production tracking\cite{shotgrid} &  制作管理 & $\bigcirc$ &$\times$ & $\times$\\
        save point\cite{savepoint} &  制作管理 & $\bigcirc$ & $\times$ & $\times$\\
        Hiero\cite{hiero} &  制作管理 & $\bigcirc$ & $\times$ & $\times$\\
        アニクロ\cite{anikuro} &  制作管理 & $\bigcirc$ & $\times$ & $\times$\\
        OLM FM Tool\cite{olmfmtool}  & 制作管理 & $\bigcirc$ & $\times$ & $\times$\\
        Redmine\cite{redmine} & 制作管理 & $\bigcirc$ & $\times$ & $\times$\\
        サンジゲン社のツール\cite{sannjigenn} & 制作管理 & $\bigcirc$ & $\times$ & $\times$\\
        新潟大学の AIMDB\cite{aimdb} & 蓄積 & $\times$ & $\times$ & $\times$\\
        渕上らのシステム\cite{fucci} & 蓄積 & $\bigcirc$ & $\bigcirc$ & $\times$\\ \hline
        \end{tabular}
    }
\end{table}

比較結果を表\ref{relativereserach}にまとめた。
まず、目的の観点から比較すると、各手法の目的は大きく「蓄積」と「制作管理」の2つに分けられる。
蓄積を目的とする手法はAIMDBと渕上らのシステムの2つであり、いずれもデータベースが用意されている点から、
活用を一定程度意識しているといえる。一方、制作管理を目的とする手法は、ディレクトリに沿った保存など
ユーザインタフェースを重視しており、中間生成物の保存にとどまっている。本研究はデータ活用を見据えるため、
蓄積を目的とした手法に注目する必要がある。

次に、アニメータが制作中に保存できるかという観点から比較する。新潟大学のAIMDBでは、
アニメータが入力できるインタフェースが用意されておらず、制作後にデータを保存する必要がある。
多忙なアニメータが別途時間を割いて作業を行うことは現実的に難しいため、今後多くの中間生成物を継続的に蓄積
することは困難であると考える。その他のツールについては、対応する工程範囲に差はあるものの、
制作中にアニメータ自身が中間生成物を保存できるため、多くの中間生成物の蓄積が可能である。

さらに、構造的な蓄積の観点から比較を行う。渕上らのシステムでは、中間生成物に付帯情報としてアニメータの行動履歴
を蓄積することで、中間生成物間の関係性を明示的に構築でき、構造的な蓄積が可能となっている。一方、
その他のツールでは中間生成物の構造的な蓄積が十分に行われておらず、活用に足る形で蓄積できているとは言い難い。

ただし、渕上らのシステムにおいても、修正に関する情報の整理・蓄積は十分に行えていない。修正は、作品のクオリティ
や作業者ごとの傾向を端的に反映する情報であり、アニメータの参考資料など多様な活用が見込める重要な情報である。

以上を踏まえ、本研究では修正の整理・蓄積を可能にするため、修正のタグ付けについて検討し、アニメータがWebシステム
を通じて修正情報を蓄積できる仕組みを実現する。
具体的には、蓄積を目的としたデータベースを扱い、かつ中間生成物の構造的な蓄積に対応
している渕上らのシステムを基盤とし、後述する物体検出や視覚言語モデル(VLM)の活用により上記目標の達成を目指す。

\section{タグ付けのための物体検出}
\subsection{物体検出の重要項目}\label{bounding_important}
本研究では、アニメーション制作過程の修正を活用しやすい形で蓄積するため、
修正が入ったカット、特に彩色後のフレーム画像から自動的にタグを付与することを考える。
その基盤技術として、画像中の対象（人物、顔、手、衣装、小物など）を領域（バウンディングボックス）
とともに抽出できる物体検出は有用である。

本研究が物体検出モデルに対して重視する項目は次の通りである。

\begin{enumerate}
    \item 学習データを用意せずに適用できるゼロショット検出が可能であること
    \item 速度よりも精度を重視すること
\end{enumerate}

理由としては、本研究の段階ではアニメ画像に対して十分な教師データを用意できていないこと、
蓄積においてリアルタイム性は必須ではないことが挙げられる。

次節以降、代表的な物体検出モデルとして
クローズドセット検出器（YOLO, DETR, DINO）と、
ゼロショット検出が可能なオープンボキャブラリ検出器（GLIP, Grounding DINO）を取り上げ、
以上の要件を満たす候補として後者を中心に整理する。

\subsection{YOLO\cite{yolo}}
YOLO（You Only Look Once）は Redmon らにより提案された物体検出器であり、
画像を一度ネットワークに通すだけで検出を完結させる単段（one-stage）方式の流れを決定づけたモデルである。
初期のモデルは純粋なCNNベースのアーキテクチャであったが、近年のモデルでは、
TransformerブロックやAttention機構をバックボーンやネックに組み込んだハイブリッドな構造も登場しており、
現在も進化を続けている。

本手法は、二段方式（領域候補を生成した後に分類する方式）と比較して処理が単純であるため推論が高速であり、
リアルタイム物体検出の文脈で広く普及してきた。 YOLO系の利点は、
多数のフレームに対して一括で物体検出を行う処理を比較的軽量に実行できる点にある。 
ただし、\ref{bounding_important}節で述べる通り、本研究においては実行速度よりも精度の担保を優先する立場を取る。
一般に、標準的なCNNベースのYOLOは、後述するTransformerベースの検出器（DETR等）と比較すると、
特に複雑なシーンにおける検出精度で劣る傾向がある。

また、従来のYOLO系モデルの多くは、学習時に定義した特定のカテゴリのみを検出対象とするクローズドセット（Closed-set）
の枠組みに従っており、未知の語彙に対応するゼロショット検出には対応していない。 したがって本章では、
YOLOの初期モデルを「単段方式の基礎的枠組み」および「CNNベース検出器の発展形」としての参照（ベースライン）と位置づける。
その上で、後続の節ではTransformerベースの検出器、
およびオープンボキャブラリ検出器へと議論を展開し、本研究の提案手法へと接続する。

\subsection{DETR\cite{detr}}
DETR（DEtection TRansformer）は Carion らによって 2020 年に提案された物体検出モデルであり、
従来主流であった「候補領域の生成→分類・回帰」という段階的パイプラインを、
Transformer を中核とする単一のネットワークに統合した点に特徴がある。物体検出の研究史の中では、
CNN を中心に発展してきた検出器に対して、Transformer を用いた 集合予測（set prediction） 
の枠組みを導入し、後続の多くの Transformer ベースの検出器
につながる重要な転換点となったモデルとして位置付けられる。図\ref{fig:detr_arch} に DETR の全体構成を示す。

\begin{figure}[h]
    \centering
    \includegraphics[width=\linewidth]{fig/Detr_arch.png}
    \caption{DETR の全体構成}\label{fig:detr_arch}
\end{figure}


DETR の処理は大きくバックボーン、Transformer エンコーダ、Transformer デコーダ
の三段に整理できる。まず入力画像は CNN バックボーンにより特徴マップへ変換され、
空間方向に並べ替えられたうえで位置エンコーディング (positional encoding) が付与される。
これが Transformer エンコーダへ入力され、
セルフアテンション (self-attention) によって画像全体の文脈を踏まえた特徴量が得られる。次に Transformer デコーダには固定個数の 
オブジェクトクエリ (object queries) が入力される。オブジェクトクエリは学習可能なベクトル集合であり、
画像中の各物体を「どのスロットが担当するか」を決めるための枠組みとして機能する。
デコーダはクエリとエンコーダ出力の間でクロスアテンション (cross-attention) を行うことで、
画像中の重要領域をクエリごとに参照し、
最終的に各クエリに対応する出力を FFN に入力してクラスラベルとバウンディングボックスを推定する。
従来の Anchor Base や非最大抑制 (NMS) に依存せず、ネットワーク全体を end-to-end に学習できる点が利点として挙げられる。
また、エンコーダのセルフアテンションにより画像全体の関係性を扱えることから、
物体同士の重なりや離れた領域間の関係が重要になる場面で高い精度が期待できる。

一方で、元の DETR には学習の収束が遅いこと、小物体の検出性能が低いことが指摘されている。
さらに Transformer を中核とする性質上、軽量な CNN ベースの検出器と比べて推論時間やメモリ使用量
が大きくなりやすい。

本研究との関係で整理すると、DETR は物体検出を Transformer による end-to-end な枠組みとして定式化した点で重要であり、
後続の改良手法を理解するための基礎的なモデルである。
ただし、DETR 自体は基本的にクローズドセット検出であり、アニメ画像に対する教師データが十分に用意できない状況で
学習なしにタグ語彙を柔軟に増やしながら検出するという本研究の要件であるゼロショット性を満たしていない。

したがって本章では、DETR を Transformer ベース検出器の代表例として位置付けつつ、
収束性や小物体検出といった課題がどのように改善され、さらにゼロショット検出へ発展していくかという流れの中
で次の小節以降の手法を紹介する。

\subsection{DINO\cite{dino}}
DINO は Zhang らによって提案された Transformer ベースの物体検出モデルであり、
DETR の課題であった学習収束の遅さと小物体検出性能の不足を改善することを目的としている。
図\ref{fig:dino_arch} に DINO の全体構成を示す。

\begin{figure}[h]
  \centering
  \includegraphics[width=\linewidth]{fig/DINO_arch.png}
  \caption{DINO の全体構成図}
  \label{fig:dino_arch}
\end{figure}

DINOとDETRの主な違いは2点ある。
一つ目は、クエリ選択 (Query Selection) である。
DETR ではオブジェクトクエリがランダム初期化された学習パラメータとして与えられていたのに対して、
DINO では物体らしさの高い位置を初期アンカーとして抽出する。
これらのアンカー情報をもとに内容ベクトル (Content Query) を生成し、
Transformer デコーダに入力することで、
各クエリが画像中の有望な領域に対応しやすいように設計されている。

二つ目に、 DINO では、学習の安定化と性能向上のために
Contrastive DeNoising (CDN) と呼ばれるノイズ付き学習戦略を導入している。
これは、正解ボックスにノイズを加えた擬似ターゲットと、
全く関係のないネガティブなボックスを同時にデコーダへ入力し、
どの出力が真の物体に対応するかを学習させる手法である。
この学習手法により、モデルは誤差や外れ値に対して頑健になると報告されている。

このように DINO は、DETR のTransformerエンコーダ・デコーダ構造を継承しつつ、
クエリ選択による初期アンカー生成とノイズ付き学習戦略を組み合わせることで、
収束の高速化と小物体を含む高精度な検出を実現したモデルである。
DETRより高精度なモデルではあるものの、
ゼロショット性を備えていないため、タグ語彙を柔軟に設計することはできていない。

\subsection{GLIP\cite{glip}}
GLIP は Li らによって 2022 年に提案された物体検出モデルであり、画像と言語を統合的に扱う点に特徴がある。
従来の物体検出では、バウンディングボックスとクラスラベルの組からなる検出データのみ
を用いて学習するのが一般的であったのに対して、GLIP はこれに加えて、
画像キャプションペアからボックスを自動生成して作った擬似グラウンディングデータも用いて事前学習する。
% "グラウンディング用データや、画像とキャプションのペアからなる画像テキストデータ" -> "や"というかグラウンディング用データと画像テキストデータは一緒では?
具体的には、物体検出データセット上では従来と同様に「ボックス＋クラス名」の組を学習しつつ、
グラウンディングデータセット上では「文章中のフレーズ」と「それに対応する画像領域」の対応関係を学習する。
複数形式の画像テキストデータを統合的に用いることで、GLIP は言語に敏感な物体表現を獲得し、
ゼロショット設定においても高い検出性能を示すことが報告されている。

図\ref{fig:glip_arch}に GLIP の全体構成を示す。上段では
「person」「bicycle」「hairdryer」などのカテゴリ名や
簡単なフレーズからなるプロンプトをテキストエンコーダで処理し、
単語ごとの特徴量を得ている。下段では画像から領域ごとの特徴量を
抽出し、テキスト側の特徴と融合させることで、各領域がどの単語に
対応するかのスコア行列を計算している。このように、単語と画像領域の
対応関係を直接学習する構成になっていることが、GLIP の特徴である。

\begin{figure}[h]
  \centering
  \includegraphics[width=\linewidth]{fig/glip.png}
  \caption{GLIP の全体アーキテクチャ\cite{glip}}
  \label{fig:glip_arch}
\end{figure}

GLIP の大きな利点は、ゼロショット検出が可能である点にある。
検出時には、従来のようにあらかじめ固定されたクラス集合をモデル内部に持たせるのではなく、
「girl」「smiling woman」のようなカテゴリ名や簡潔なフレーズをテキストとして入力し、
そのテキストと画像中の領域の対応に基づいてバウンディングボックスとスコアを出力する枠組みとなっている。
そのため、GLIPは本研究での要件を満たしている。

\subsection{Grounding Dino\cite{groundingdino}}
Grounding DINO は Liu らによって2022年に提案された物体検出モデルであり、
DINO 系が示した高精度な Transformer ベースのアーキテクチャを土台としつつ、
GLIP のようにテキストと画像の対応関係を明示的に学習することで、
ゼロショット検出を実現したモデルである。
図\ref{fig:grounding_dino_arch}に 
Grounding DINO の全体構成を示す。

\begin{figure}[h]
\centering
\includegraphics[width=\linewidth]{fig/GroundingDino.png}
\caption{Grounding DINO の全体アーキテクチャ\cite{groundingdino}}
\label{fig:grounding_dino_arch}
\end{figure}

Grounding Dinoを用いる利点としては、DINO 由来の高い検出精度と学習安定性を維持したまま、
GLIP のように自然言語でカテゴリを指定できる柔軟なゼロショット検出を実現している点が挙げられる。
特に高解像度画像に対する検出性能や、長いテキストプロンプト
を扱うスケーラビリティに配慮した設計となっており、テキスト条件付き物体検出の実用的な選択肢として広く利用されている。

このように Grounding DINO は、DINO の高精度 Transformer 検出器と GLIP 系の言語条件付きグラウンディング
を統合したモデルとして位置付けられ、クラス集合を固定しない柔軟なタグ付けを可能にする。


\subsection{MM Grounding DINO\cite{mmgroundingdino}}
MM Grounding DINO は、OpenMMLab の物体検出フレームワーク MMDetection 上で
Grounding DINO 系を再現・拡張したオープンソース実装である。
Grounding DINO は 物体検出のタスクで高い性能を示す一方、元実装では学習コード等の技術詳細が十分に公開されていない点
が指摘されてきた。
これに対して Zhao らは、MMDetection\cite{mmdetection} 上で学習・評価まで含めた再現可能な基盤として MM Grounding DINO を提示し、
多様な事前学習データと検出／グラウンディング系データでの学習レシピを含む包括的なパイプラインを公開している。


\subsection{各物体検出技術の比較}
以上より、要件\ref{bounding_important}の一つであるゼロショット性を備えたモデルは、
GLIP、Grounding Dino、MM Grounding Dinoの3つである。

図\ref{zeroshot}に、GLIP、Grounding DINO、およびMM Grounding DINOの性能比較を示す\cite{mmgroundingdino}。
本図の放射軸は、標準的な物体検出ベンチマークであるCOCOやLVISに加え、多様な実ドメインへの汎化性能を測るODinW
（Object Detection in the Wild）、自然言語による指示から特定の物体を同定する参照表現理解（RefCOCO/+/g、gRefCOCO）、
および自由記述に基づく検出能力を評価するD3（Description Detection Dataset）から構成される。これにより、モデルが持つ
「広範な語彙への対応力」と「複雑な言語理解に基づく空間特定能力」を多角的かつ定量的に検証することが可能となっている。

比較の結果、MM Grounding DINOが全指標において他の検出器を凌駕する高い性能を示した。
また、本モデルはGrounding DINOと比較してファインチューニングが容易であるため、将来的にアニメ特化型の学習データセットが整備された際、
さらなる精度向上が見込める。以上の検討に基づき、本研究におけるタグ付け用の物体検出モデルとしてMM Grounding DINOを採用する。


\begin{figure}[h]
  \centering
  \includegraphics[width=\linewidth]{fig/mmdetection.png}
  \caption{各ゼロショット物体検出器の比較\cite{mmgroundingdino}}\label{zeroshot}
\end{figure}



\section{タグ付けのためのVLM}
本節では、近年登場した最新の視覚言語モデル(VLM)について紹介する。
本研究は、アニメ制作現場で扱う中間生成物を対象にタグ付けを行う。
これらの素材は制作途中の機密情報を含みうるため、クラウドAPI前提ではなく、
スタジオ内の計算機で完結できる「ローカル運用可能なVLM」を優先する。

\paragraph{Qwen3-VL}
Alibaba Cloud（Qwen チーム）により公開されたオープンウェイトの VLM であり、
多様な視覚タスク（VQA、文書理解、数式・図表理解など）を広く扱えることを特徴とする。
モデルカード上では多くのベンチマークが報告されており、高い総合性能が示されている\cite{qwen3vl_card}。

\paragraph{InternVL3.5}
OpenGVLab により公開されたオープンウェイトの VLM であり、
汎用的な視覚理解に加えて OCR・文書理解・図表理解などの実用タスクを強化している。
モデルカード上で複数の代表ベンチマーク結果が示されている\cite{internvl35_card}。

\paragraph{Phi-4-multimodal}
Microsoft によるマルチモーダルモデルであり、
小型・実用志向の設計思想を持つ系列（Phi）のマルチモーダル拡張として位置付けられる。
公開ページで代表的な視覚ベンチマーク（MMMU、MathVista、DocVQA、ChartQA 等）の結果が報告されている\cite{phi4mm_card}。

\paragraph{Gemma 3}
Google により公開されたオープンウェイトのモデル系列であり、
（構成によって）マルチモーダル入力を扱えるモデルが提供されている。
第三者の比較表においても MMMU / MathVista / DocVQA / ChartQA 等の結果が示されている\cite{gemma3_vision_table}。


\subsection{採択理由：Qwen3-VLを主モデルとする根拠}
Qwen3-VLはモデルカードにおいて、事前学習データの拡張と品質向上により視覚認識能力が強化され、
著名人、アニメ、製品、ランドマーク、動植物など、幅広い対象を認識できる
旨が述べられている。このような多ドメイン・高品質な事前学習を前提とする設計は、自然画像とは画風が異なるアニメ画像に対しても、
一定の認識精度が見込める。

また、本研究はローカル運用を前提とし、研究室GPU（96GB）上での実行可能性が採択条件となる。
推論時にはモデル重みに加えてKVキャッシュがVRAMを占有するため、精度を最大化しつつ単一GPUで運用可能な範囲として、
30B前後のモデル規模が現実的である。
以上を踏まえ、複数ベンチで高水準の性能が報告され、かつ30B級のチェックポイントが利用可能なQwen3-VLを
本研究の主モデルとして採択する。


\section{おわりに}
本章では、日本のアニメーション制作におけるデータ蓄積の現状と、既存の管理ツールおよび蓄積手法について概観した。
山川氏や松下らの議論により、中間生成物のアーカイブと利活用は、教育や制作支援において極めて高い価値を持つことが確認された。
しかし、flow production trackingやSave Pointなどの既存ツールは主に「進行管理」を目的としており、
中間生成物を将来的な分析や再利用に供するための構造的な蓄積という観点では不十分であることが明らかになった 。

また、蓄積を主眼とした先行研究である新潟大学のAIMDBや渕上らのシステムについても検討した。
渕上らのシステムは、アニメーターの行動履歴と中間生成物を紐付けることで構造的な蓄積を実現しているが、
作品のクオリティや作業者の傾向を色濃く反映する修正に関する情報の詳細な整理・蓄積には至っていない 。

これらを踏まえ、本研究では修正情報の蓄積と活用を目的とし、渕上らのシステムを基盤とした新しい仕組みを提案する。
タグ付けの自動化においては、ゼロショット性能と精度、およびスタジオ内でのローカル運用を考慮し、
物体検出モデルとしてMM Grounding DINO、視覚言語モデルとしてQwen3-VLを採用することとした 。

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{アニメ会社への調査}
\section{はじめに}
本章では、日本のアニメーション制作会社様への調査の内容とその結果について述べる。
まず始めに、アニメーションのワークフロー上の主要な工程について説明し、
その上で各工程間においてどのような観点でチェックされ、どのような修正が入るかについて述べる。
さらに、現場での修正の利用について触れた上で実際の修正素材の分析に移る。

\section{調査目的}
本調査の目的は、日本のアニメーション制作現場において発生した修正やリテイク
がどのように活用されているかを調査し、実際の素材の分析から今後の活用の
観点においてどのように修正、リテイクへのタグを設計するか考察することである。

調査の方法としては、ユーフォーテーブル有限会社(以下、ufotable)にインターンという形で
受け入れていただき、制作進行の方への聞き込みや実際の素材の分析によって行った。


\section{アニメーション制作工程でのワークフロー}
\subsection{全体的な流れ}
まず、日本のアニメーション制作工程でのワークフローの全体像を図\ref{AnimationFlowchart}に示す。
アニメーション制作はまず、脚本・デザイン・設定といった工程を済ませた後、
絵コンテ、第一原画、第二原画、動画、色指定・彩色、撮影といった流れで進行する。
以降の小節では、これらの各工程について述べる。

\begin{figure}[h]
    \centering
    \includegraphics[width=\linewidth]{fig/AnimationFlowchart.png}
    \caption{日本のアニメーション制作におけるワークフロー}\label{AnimationFlowchart}
\end{figure}


\subsection{脚本・デザイン・設定}\label{kyakuhonsetteidezain}
本格的なアニメの作画の前に行われるのが、脚本・デザイン・設定の工程である。
脚本とは、映像の構成と必要要素を文章として整理した資料であり、
セリフに加えて、行動・感情を示すト書き、背景や状況などが含まれる。
設定・デザインでは、ストーリー設定、キャラクタデザイン、美術設定、色彩設計などを決定する。
これらは作品の世界観や各要素の仕様を定める設計資料であり、以降の工程はこれらを参照して進められる。

色彩設計は、作品全体の色の方向性を定めるために必要であり、作品の世界観を視覚的に成立させるための基準を用意する。
具体的には、キャラクタや小物の基本色を整えたうえで、夕景や夜景など状況に応じて変化する色も含め、
後工程が参照できる形で資料として整理する。
これにより、以降の色指定・彩色工程では、ここで定めた色の基準を参照しながら、
各カットの素材に対して一貫した色づくりを行えるようになる。


\subsection{絵コンテ}
絵コンテは監督・演出家が作るべき映像や演出意図、作業指示などを後の工程に伝えるための、
映像の設計図のような物である。具体例を図\ref{ekonnte}に示す。


\begin{figure}[h]
    \centering
    \includegraphics[scale=0.5]{fig/ekonnte.png}
    \caption{絵コンテ [\cite{trigger}より]}\label{ekonnte}
\end{figure}

絵コンテは脚本・設定・デザインをもとにして作成され、主に以下の要素を含んでいる。

\begin{itemize}
    \item カット番号
    \item キャラクタのセリフ
    \item SE 
    \item 画面構成（構図・カメラ）
    \item ト書き
    \item 尺
    \item 補足メモ
\end{itemize}

演出意図や作業の指示を後の工程に正確に伝えることが、この工程で重要なことである。

\subsection{第一原画 (レイアウト・ラフ原画)}
第一原画は、絵コンテから読み取れる情報や監督・演出の指示をもとに、
画面の設計と動きの設計を行う工程である。
具体的には、レイアウト、ラフ原画（通称ラフ原）、タイムシートを作成する。
第一原画に求められる要件は、次のとおりである。

\begin{enumerate}
    \item 1枚は影付きの作画があること
    \item タイムシートがあること
    \item 背景原図 (背景スタッフに渡す用のレイアウト) があること
\end{enumerate}

第一原画で作られるものは全て後の工程の基盤となってくる重要な資料である。
レイアウトとは、カットの背景とキャラクタの位置関係、サイズ感、構図、どのセルに何を描くか
などについての設計図である。レイアウトにおいては、キャラクタなどは丁寧に描いてあることがほとんどである。

タイムシートは、フレームごとのセル配置や打ち（コマ）を指示する表であり、どのセルがいつ表示されるか、
どのタイミングで切り替わるかといった情報を後工程に伝達する。

ラフ原は後の完成系の原画 (第二原画\ref{dainigenga}) の初期案のようなものであり、
主としてキャラクタの動きやポーズ、タイミングの設計を担う。
ラフ原では必要な輪郭や主要な形状は示しつつも，衣服の柄や細部の描き込みは省略される場合がある。
細部が省略される理由の一つは、第一原画の後段で複数回のチェックが入り、
構図や芝居の調整が生じうるためである。もし早い段階で細部まで作り込んでしまうと、
後から修正が入った際に、描き込んだ部分を最初からやり直す必要が生じ、結果として無駄になる作業量が大きくなる。
特に、演出・監督修正などで大きめの修正が入る場合、細部の描き込みがそのまま活かせず、描いた分だけ作業が失われやすい。
このため、ラフ原では「後から変わり得る部分」を見越して、必要十分な情報に留めることが多い。
一般に経験のあるアニメータほど、動きの設計に重点を置き、ラフ原を簡略にすることが多い傾向にある。
これは、丁寧さと引き換えに作業速度を早め多くの枚数を描くことで、よりアニメ制作に貢献できるからである。
ただし、新人の場合はラフ原の押さえるべきところを押さえていない場合があるため、なるべく丁寧に描くことが推奨される。

\subsection{第二原画}\label{dainigenga}
第二原画は、第一原画で提出された原画に対して入った様々な修正を踏まえながら、
すべてのフレームを清書する工程である。
多くの場合、第二原画に作業が回ってきた段階で、カット内には修正を反映させるだけで
完成となるフレームが与えられている。第二原画の人の主な仕事は、
修正の入っていないフレームに対して、修正の入ったフレームを参考にしながら、合わせた絵を描き清書することである。
第二原画の人は基本的に全てのフレームに対して、影や服の柄など描かなければならない。

第二原画は、第一原画で入った修正を見ながら作業でき、自分の絵と修正の絵を見比べて勉強することができるため、
第一原画と第二原画の担当者は同一人物であることが好ましい。
しかし、制作スケジュールなどの都合で別々の者が担当するケースも多い。
第一原画の人が自分の描いた原画に対して、どのような修正が入ったか確認できず、修正から学ぶことができない場合があるのは、
現在の課題となっている。

\subsection{動画}
動画は、第一原画と第二原画で設計された動きにもとづき、
原画間を補完する中間の絵（中割り）を作成し、後工程で扱える線画素材として整える工程である。
動画工程では、中割りの作成に加えて、原画線の清書や線の整理といった作業が含まれる場合があり、
制作体制や作品の運用によって担当範囲は多少変動する。

また、動画工程は、原画段階で指定されたセル構成を実際の素材として成立させる工程でもある。
アニメーション制作では、キャラクタの一部や小物、エフェクトなどを後で彩色や合成で扱いやすい単位に分けて管理するために、
セル（レイヤ）を分離して扱う。第一原画でどのセルに分けるか指示され、動画ではそれらを受け取って、
後工程の作業に必要な単位で線画素材を整える。こうしたセル分離は、後段での素材管理や合成上の取り回しに関係するため、
単に中割りを描くだけではなく、工程全体の流れを踏まえた整理作業としての側面も持つ。

原画や動画が紙媒体で運用される場合、動画工程が完了した後にスキャンを行い、
デジタルデータとして取り込む工程が発生する。スキャン後は、線画を後工程で扱える形式へ整える処理が伴うことがあり、
最終的に彩色工程へ渡る線画素材が準備される。一方で、近年は作画工程自体がデジタル化され、
紙のスキャン工程を介さない運用も増えているが、いずれの場合でも、動画工程は動きの補完と後工程に渡す線画素材の成立
を担う工程として位置付けられる。

\subsection{色指定・彩色}
色指定・彩色は、線画素材に対して色を与え、作品としての画面を成立させる工程である。
色指定は、色彩設計で決められた方針にもとづき、各カットに対してどの部分にどの色を置くかを具体的な指示として整理する役割を担う。
彩色は、色指定で定義された指示にもとづいて、実際に線画へ着彩していく作業である。
彩色工程は仕上げ工程と呼ばれることもあり、線画と色の情報を統合して、撮影工程で合成可能なセル素材を生成する工程
として機能する。したがって、色指定・彩色は単に色を塗るだけではなく、作品の色の一貫性を維持しつつ、
多数カットにわたって安定した画面を成立させるための工程である。


\subsection{撮影}
撮影工程は、背景、美術素材、彩色済みセル、エフェクト素材など複数の素材をコンピュータ上で統合し、
完成した映像カットを生成する工程である。アニメーション制作における撮影は、
実写映像のように物理的なカメラで撮影する作業を指すのではなく、素材を重ね合わせ、
必要な加工を施しながら最終的な画面を組み上げる合成としての意味合いが強い。

撮影工程では、セルと背景の重ね合わせに加え、カメラワークに相当する画面効果（パンやズームなど）や、
画面全体の印象を整えるための調整処理が行われることがある。また、煙、炎、光などのエフェクト素材や、
3DCG素材が投入される場合もあり、複数セクションの成果物を一つのカットとして成立させる役割を担う。
最終的に、撮影で生成されたカットが編集工程へ渡り、作品全体の映像として統合されていく。

\section{各工程のチェック工程で発生する修正・リテイク}
この節では、前節で整理した工程のうち、第一原画、第二原画、動画、彩色、そして
撮影後のチェックであるラッシュについてどのような修正・リテイクが出されているのかについて述べる。

\subsection{リテイクと修正の違い}
主要な各工程が終わったとき、次の工程に受け渡しされる前にチェック工程が入る。
修正は、提出物をベースにしつつ、チェック工程の担当者が
画面上の修正点を指し示し、その次の工程に受け渡しされる。
その修正点は次の工程の担当者か、修正担当者自身が素材に反映させる。

一方でリテイクは、元の作業者へ差し戻し、作業者側で描き直しや作り直しを行う対応である。
本調査では、リテイクは「要件を満たしていない」「後の工程への指示が書かれていない」「前の工程からの指示内容に準拠していない」
といった状況で発生しうること、また次工程が困る状態を解消する目的でも出されることが整理できた。
修正が上位者が変更点を入れて完成形へ寄せる対応であるのに対し、リテイクは作業を返して作り直す対応であり、
過激なチェックが起きた場合に起こるのがリテイクである。
リテイクは本調査の範囲では頻度が相対的に小さく、まず修正の蓄積を優先する。


\subsection{第一原画への修正}
第一原画は、レイアウトやラフ原画としてカット内の画面設計や動きの設計を担うため、
ここでの判断や修正は後工程に大きく影響しやすい。そのため、第一原画のチェックは、工程としては
「原画上がり → 演出修正 → 監督修正 → 作監修正 → 総作監修正 → これらを踏まえた清書」という段階的な流れで行われ、
修正が積み重なることを前提に運用されている。

まず、第一原画に対する修正は、上がってきた原画を前提に、チェック工程の担当者がより望ましい状態
に寄せるための追記や調整として行われる。
演出修正と監督修正は、絵コンテや作打ちで共有された演出意図を第一原画として
正しく落とし込めているか
といった比較的抽象度の高い観点が中心になる。一方で、作監修正と総作監修正は、ラフ原が作品の原画として成立するように
整える工程として位置付けられ、より具体的で作画上の注意点に踏み込んだ修正が多くなる。作監は絵を整える役割に加えて、
ラフ原で省略されていた部分の書き込みも担当する場合がある。

修正の出し方にはいくつかの特徴がある。
修正は、修正指示用紙というものに絵や文字の書き込みをすることで出す。
修正指示用紙はどの修正工程かによって色が異なり、ufotableの場合は、演出修正があさぎ色、監督修正がわかくさ色、
作監修正がさくら色、総作監修正がレモン色というように区別できるようになっていた。

修正絵は差分だけを示すものに限らず、原画と重なる線を保持した形で描かれる場合もあり、
どの程度トレースして示すかは作業者によって差がある。また、修正用紙に書き込まれる文字としては、
フレーム番号やセルの特定（例として「A12修」）、修正の細かなニュアンスの指示、
簡単な申し送り（よろしくお願いします等）が書き込まれる。実際の指示文としては「体はD④修合わせでお願いします」
「他前後合わせて修正お願いします」のように、
特定フレームの修正を基準に前後フレームへ整合を取ることを求める表現が多い。これは、
カット内で一フレームでも修正が入った場合、後続フレームも連動して調整が必要になるという実務上の性質と対応している。

運用面では、修正絵の枚数や指示の細かさが一定ではない点も重要である。あるカットで一枚だけ修正絵を描き
「他前後合わせてお願いします」で済ませる場合もあれば、連続フレームに対して複数枚の修正絵を描く場合もある。
これは作監側のスケジュール余裕、カット内フレーム枚数、次工程の作業者への信頼度、納期間際に一発で通したい事情などで変動する。
また、作監のタイプとして、第一原画修正を多めに描いて第二原画修正を抑えるタイプと、
第一原画修正は抑えめで第二原画側の修正を多めに出すタイプがあり、人によって配分が異なる。
原則として同一カットの第一原画と第二原画は同じ作監が見るが、作監が過負荷になった場合などには担当が変わることもある。
作監と総作監が同一になる、あるいは総作監が工程を飛ばすように見えるケースについても、人手不足で総作監に仕事が回らない場合や、
総作監が修正を出しすぎてしまう場合、作監クラスの人が原画を担当して実質的に作監修正相当が内包される場合など、
制作体制上の事情で起こり得る。

以上を踏まえると、第一原画の修正は演出意図のチェック（演出、監督）と作画としての成立（作監、総作監）
が段階的に重なっていく形で発生し、修正絵とコメントを通じてカット内の前後フレームへ波及させながら整合を取る性質を持つ。
第一原画への修正の反映は第二原画が担当する。

\subsection{第二原画への修正}
第二原画に対するチェックでは、第一原画で設計された意図や修正指示を前提としつつ、第二原画として清書が成立しているか、
及び次工程が参照しやすい形で情報が整理されているかという観点が強くなる。そのため、芝居や構図を再設計するというよりも、
第一原画に対して修正が発生したフレームに他のフレームを正確に合わせるための修正が行われる。

第二原画の修正は、演出、作監、総作監の順で発生する。演出によるチェックは、
検品の性格が強く、次工程が困らない素材になっているかに重点が置かれやすい。
例えば、必要な要素が欠けていないか、指示の書き方が不十分で誤解を生まないか、
素材同士の整合が取れているかといった点が対象になりやすい。

作監、総作監による修正は、作画としての成立性や統一感を高める方向のものが多い。
具体的には線の清書、動きの微調整、絵柄寄せ、細部の整合など、作画品質を底上げする調整が中心となる。
このとき重要なのは 
ラフ原画や修正指示の意図が適切に清書へ落ちているか、及び動画工程が拾うべき形や情報が整理されているかという点である。
例えば、迷い線が残り形状が確定していない、パーツの優先順位が線の強弱や情報量として整理されていない、
前後フレームで形が不安定で追従の基準が取りにくいといった状態は第二原画段階で問題になりうる。

以上より、演出は検品を中心に確認し、作監・総作監は清書品質と作画の成立性を中心に確認する。修正の反映は動画が担う。

\subsection{動画への修正}
動画工程は、第一原画・第二原画で定められたタイミングと動きに基づいて、
中割りを作成し、線画として次工程に渡せる状態に整える工程である。
動画工程のチェックは動画検査が行う。
動画検査は、動画素材が後工程（仕上げ、撮影）で支障なく扱える状態になっているかを確認し、
不備があれば修正またはリテイク対応を行う。確認対象は作画内容だけでなく、線の抜けや途切れ、
のつながり不足、二重線や線のガタつきなどの線品質、さらにタイムシートや合成伝票の記載、
セル名やデータ名、フォルダ運用といった管理情報も含む。

動検における修正は、色トレス線や塗り分けの抜け、口紅トレスの欠落、エフェクト線の部分的な抜けなど、
局所的で原因が明確な不備を補う対応として現れる。
特に、動画番号末尾へのENDの付与（合成伝票も同様）、動画番号や記号の記載位置、合成子の補足表記、クミ関連ファイルの命名整合、
タイムシート上に存在しないセルが出る場合の欄の振り直しなどは、後工程の混乱を防ぐために重要である。
また、T.U.やT.B.のように解像度が変わる場面での線幅調整、汚れブラシ等の別紙素材のセル名運用、
クミセルの本セル画像のレイヤ設定（下描き、かつ不透明度50\%）といった設定面の不備も、指摘対象となる。
動画検査での修正の反映は次工程ではなく動画検査本人が行う。


\subsection{彩色への修正}
彩色工程のチェックは、セル検と呼ばれ、色指定が行う。
セル検では背景とセルを合わせてチェックし、
最終画面に現れる色の正しさはもちろん、素材としての不備がないかという観点でもチェックされる。
例えば、塗り残しや塗りはみ出し、領域の誤認による誤配色、透過の扱い（抜き・マスクの破綻）、
線画由来の隙間から発生する色漏れなどは、静止画での確認だけでなく、パラパラや実際の合成を想定した確認で問題化しやすい。
また、セル素材は撮影工程で多数レイヤとして扱われるため、命名規則やファイルの整合性など、管理面の不備も後工程の混乱につながる。
このため、仕上げ工程の検査は「色が合っているか」に加えて「素材として破綻がないか」を確認する位置付けになりやすい。
彩色工程への修正の反映は、セル検の担当である色指定本人が行う。


\subsection{ラッシュでのリテイク}
ラッシュは、撮影工程で合成された各カットを納品前に動画として確認し、映像としての最終的な品質と演出意図の整合を点検する工程である。
撮影は画としての制作工程の出口に位置付けられるため、ここでの確認は、仕上がった映像を前提にした不備の発見と修正判断に直結する。 

ラッシュチェックでは、放送用の基準に合わせて調整された業務用モニターと、
一般的な民生用モニターの双方で見え方を確認し、色味やレベルなどの品質を点検する。
これにより、作業中には見落としやすいテクニカルな撮影ミスや、エフェクトの微調整が発見され、必要に応じて差し替えや再出力が発生する。 

ラッシュで指摘された事項は、制作進行が取りまとめ、演出や監督の判断のもとで、どの部署にどの内容を戻すかが決められる。
撮影内で完結する調整で済むものは撮影側で修正し、素材自体の差し替えが必要な場合は、該当する工程へ戻してリテイクとして
対応する運用になる。 

指摘内容としては、素材差し替え漏れ、セルやエフェクトの処理抜け、位置ずれ、色の塗り間違いや塗り漏れ、
連続フレーム間での色パカやパカつき、パーツや模様の線の太さの不揃い、影の落ち方と動きの不整合など、
静止画では見逃しやすい時間的な破綻が中心になる。現場運用としては、事前にラッシュ素材を関係者へ共有して個別に確認し、
初回は対面でアウトとセーフの基準感を揃える、といった形で確認精度を上げる工夫も行われていた。


\section{価値の高い修正・リテイク工程とその活用可能性}
本節では、制作現場における修正素材の実際の活用事例を整理し、どの工程の修正が特に価値が高いかを論じる。結論として、後工程で参照されやすく、
かつ制作全体への影響が大きいという観点から、第一原画に対する修正が価値の高い蓄積対象であると位置付ける。

\subsection{スケジュール見積もりのための判断材料}
修正を含む成果物の集計は、単に枚数を数えるためではなく、制作進行の判断材料として活用される。
作品ごとに、１カットあたりの原画枚数や修正枚数の傾向を把握することで、進捗を「残りカット数」ではなく「残りフレーム枚数」
で評価する必要がある状況を検出できる。例えば、１カットあたりの枚数が少なすぎる作品や多すぎる作品では、
カット数だけを見た進捗把握が実態と乖離しやすく、フレーム枚数を基準にした作業の見積もりが有効になる。

また、集計表に記録された完了日付と枚数は、作監やアニメータの作業スピードの把握にも用いられる。
１日あたりの平均処理枚数を推定できれば、今後依頼すべきチェック量に対して必要日数を概算できる。
例えば、１０日で３０枚の作監修正を上げる作監であれば、１日平均約３枚とみなせる。仮に３００枚のチェックを依頼し、
修正発生率を１／３と見積もるなら、作監修正は約１００枚となり、必要日数は約３３．３日といった形で試算できる。
さらに、作画コストの高いカットが含まれる場合には、係数を掛けて工数を上振れさせる判断が行われる。
つまり、修正枚数と日付の記録は、スケジュール調整の根拠として実務上の価値を持つ。

\subsection{作画時の参考資料としての活用}
定性的な活用としては、修正素材を参照資料として用い、アニメータの作業品質を上げる目的が大きい。
具体的には、作監修正や総作監修正を参照することで、キャラデザ寄せの基準となる顔の形、パーツ配置、表情の作り方
などをアニメータが確認できる。原画担当者や動画担当者が、過去の修正を見て作品内での正解の形を理解し、
描き直しや迷いを減らすことができる。
修正素材は作監や総作監がどこに着目しているかを学ぶ重要な教材になっている。

また、原画マンや動画マンだけでなく、作監自体も他の作監の仕事の確認をするために閲覧することができる。
作監同士がお互いの成果物を見ることで、修正の基準を統一することにも役立っている。


\subsection{修正素材検索システムによる運用例}
修正素材の活用を支える仕組みとして、過去の修正を検索できるシステムが運用されている例がある。
ここでは、作品名、作監名、キャラクタ名、キャラクタの顔の向きの４要素をキーとして、作監修正、
総作監補佐修正、総作監修正の修正絵を登録し、検索できるようにすることが目的とされている。修正絵は、
図\ref{adcf}のUIから制作進行やアルバイトの方が手動でシステムに登録する形で運用されていた。
登録時には、作品名などのキー情報に加え、顔の向きは専用の顔のＵＩをドラッグしてｘ、ｙ、ｚ座標として入力する運用になっている。

\begin{figure}[h]
    \centering
    \includegraphics[width =\linewidth]{fig/ADCF登録用UI.png}
    \caption{登録用UI}\label{adcf}
\end{figure}


この運用は、修正素材を見つけられる形で蓄積することが、現場での参照利用を成立させる条件であることを示している。
一方で、このシステムは顔の向きのみに対応しており手のアップなどの対応や、人間が手動でタグ付け
する必要があり蓄積の自動化などが求められる。
つまり、参照価値の高い修正素材ほど、蓄積と検索のためのメタデータ付与が重要であり、
幅広い修正に対応できるタグ設計と、そのタグ付けの効率化が課題になる。

\subsection{第一原画の修正が価値の高い蓄積対象である理由}
以上の活用事例を踏まえると、第一原画に対する修正は、定量面と定性面の両方で価値が高い蓄積対象である。

第一に、第一原画の修正は制作全体への影響が大きい。第一原画は以降の第二原画、動画、彩色、撮影へと連鎖する入力であり、
この段階での修正は後工程の作業内容そのものを規定する。また、各工程の中で最も修正の枚数が多くなりがちなのは第一原画である。
したがって、第一原画での修正枚数や修正発生率は、
進捗把握や工数見積もりに直結し、制作進行にとって実務的価値が高い。

第二に、第一原画の修正は参照資料としての価値が高い。
実際に、特定のキーに基づいて検索できる仕組みが運用されていることからも、
第一原画の修正が制作現場で活用されていることが分かる。

以上より、本研究では、蓄積対象を第一原画に付随する修正情報に定め、後工程で参照しやすい形で整理するためのタグ付けと
蓄積手法を検討する。次節以降では、第一原画に対する修正の実態をより細かく分析し、その結果をタグ設計へ反映する。


\section{第一原画に対する修正の分析}
\subsection{分析対象}
ufotableより第一原画修正50カット分（計306枚）の提供を受け、その分析を行った。
分析にあたっては、修正前の原画と各修正を比較し、修正担当者がどのような視点で指示を出し、
どのような修正箇所に指示を施したかに着目した。
全ての分析結果は付録に掲載し、本節ではそれらを総括した傾向と考察について述べる。

\subsection{担当別の修正枚数}
修正枚数の集計結果を表\ref{bunsekigaikyou}に示す。
修正枚数306枚のうち、演出修正は51枚、監督修正は17枚、作監修正は151枚、総作監修正は87枚であった。
構成比を見ると、作監修正が全体の約半数（151/306）を占め、次いで総作監修正が約3割（87/306）となっており、
演出修正と監督修正は相対的に少ない（それぞれ約17\%、約6\%）。したがって、本データにおいては
作監および総作監の修正が修正枚数の大部分を構成していると言える。

また全50カットのうち修正が発生したカット数は、演出が24、監督が7、作監が37、総作監が28であった。
作監修正は7割超のカットで発生しており、総作監修正も半数を超えている。一方で、監督修正は1割台にとどまり、監督が直接修正を行うカットは限定的であることが示唆される。


1カットあたりの平均修正枚数（修正発生カットのみを対象）は、演出2.13枚、監督2.42枚、作監4.08枚、総作監3.11枚であった。作監修正は発生頻度が高いだけでなく、1カットあたりの枚数も多い傾向にある。演出と総作監を比較すると、対象カット数に大きな差はないものの、1カットあたりの平均枚数の差が総修正枚数の乖離に繋がっていることがわかる。

さらに、1カットあたりの最大修正枚数は、演出6枚、監督7枚、作監13枚、総作監9枚であった。
特に作監修正は最大値が突出しており、特定のカットで集中的に修正が行われる可能性
を示している。また、監督修正は発生数こそ少ないものの、最大で7枚の修正が入る事例があることから、
修正対象となる場合には一定規模の作業が発生すると考えられる。

以上のことから、修正枚数の観点では作監・総作監の修正が中心であり、
特に作監修正は「発生範囲の広さ」と「1カットあたりの密度」の両面において、
修正作業の主軸を担っていることが明らかとなった。

\begin{table}[h]
    \centering
    \caption{集計結果の概況}\label{bunsekigaikyou}
    \begin{tabular}{|c|c|c|c|c|}\hline
        担当 & 修正枚数 & 対象カット数 & 平均修正枚数 & 最大の修正枚数 \\ \hline
        演出 & 51 & 24 & 2.13 & 6\\
        監督 & 17 & 7 & 2.42 & 7\\
        作監 & 151 & 37 & 4.08 & 13 \\
        総作監 & 87 & 28 & 3.11 & 9\\ \hline
    \end{tabular}
\end{table}



\subsection{担当者別の修正内容の分析}
続いて、修正担当者がどのような着眼点で修正を行ったかを分析する。
各担当者における修正内容の集計結果を表\ref{tab:retake_by_role}に示す。

本分析では、修正内容を「清書」「絵柄統一」「芝居」「動き・タイミング」「立体・角度」「画面設計」「設定・世界観整合」「光源」「連続性」の9項目に分類した。
各項目の具体的な定義は以下の通りである。

\begin{enumerate}
  \item 清書 : 加筆、タッチや強弱の調整、および前のチェック工程の修正指示の清書
  \item 絵柄統一  : キャラクタデザインへの準拠、顔のサイズ感の調整
  \item 芝居 : 表情のニュアンス、目線などの演技全般 
  \item 動き・タイミング : ポーズや姿勢、動きの軌道・タイミングの調整
  \item 立体・角度 : 全身や各パーツ（顔・四肢・持ち物等）の立体的な整合性や角度の修正
  \item 画面設計 : 構図の変更、キャラクタの立ち位置やカメラワークの調整
  \item 設定・世界観整合 : 設定資料との照合、衣装・小物の細部修正
  \item 光源 : 光源位置の指定および影付けの修正
  \item 連続性 : 前後フレームや前後カットとの整合性の確保
\end{enumerate}

\begin{table}[h]
  \centering
  \small
  \setlength{\tabcolsep}{4pt}
  \renewcommand{\arraystretch}{1.15}
  \resizebox{\linewidth}{!}{%
    \begin{tabular}{ccccccccccc}
      \hline
      修正担当者 & 清書 & 絵柄統一 & 芝居 & 動き・タイミング & 立体・角度 & 画面設計 & 設定・世界観整合 & 光源 & 連続性 & 担当の修正枚数合計 \\
      \hline
      演出   & 2   & 0  & 11 & 10 & 1  & 4 & 28 & 1 & 1 & 51 \\
      監督   & 5   & 0  & 5  & 8  & 0  & 1 & 1  & 1 & 0 & 17 \\
      作監   & 141 & 28 & 5  & 6  & 30 & 1 & 9  & 9 & 0 & 151 \\
      総作監 & 3   & 77 & 20 & 6  & 19 & 0 & 3  & 0 & 1 & 87 \\
      \hline
    \end{tabular}%
  }
  \caption{修正担当者別の分類別件数}
  \label{tab:retake_by_role}
\end{table}

\subsubsection{演出修正の傾向}

演出修正においては、「設定・世界観整合」の件数が他工程と比較して突出して多い。次いで「芝居」や「動き・タイミング」が多く、表情や動作の調整を通じて演出意図を浸透させる修正が中心であることが読み取れる。一方で、「清書」や「絵柄統一」の割合は極めて低く、描線を整える作業よりも、画面内の状況の成立や設定上の整合性を優先する傾向が強い。また、「画面設計」についても一定の修正が見られ、第一原画上がりを最初にチェックするという制作フロー上の役割を反映している。

\subsubsection{監督修正の傾向}

監督修正では「動き・タイミング」が最多であり、「芝居」も同程度に重視されている。演出修正と同様に演技面への介入が主であるが、特に動作の連続性や「間」の成立に重点が置かれている点が特徴である。「設定・世界観整合」や「画面設計」への関与は相対的に少なく、監督工程は作品全体の意図を、キャラクタの動態と感情表現へと具体化する役割を担っていると解釈できる。

\subsubsection{作監修正の傾向}

作監修正では「清書」が全項目の中で圧倒的な割合を占める。次いで「立体・角度」や「絵柄統一」が続き、描画としての完成度を高めつつ、形状の説得力やキャラクタの統一感を確保する修正が主となっている。「芝居」や「動き・タイミング」に関する修正が相対的に少ないことは、作画監督の主目的が演技の調整よりも、作画素材としての物理的な破綻をなくし、品質を底上げすることにあることを示している。

\subsubsection{総作監修正の傾向}

総作監修正では「絵柄統一」が最多となり、次いで「芝居」や「立体・角度」の修正が多く、全体的な統一感の維持に加え、キャラクタの印象や立体的な整合性の最終調整が重視されている。一方で「清書」は少なく、総作監工程は描線のクリーンアップそのものよりも、キャラクタ表現の最終的な方向付けと、作品全体のビジュアルの収束を担う役割であるといえる。

\subsubsection{総括}

以上、修正内容を9つの分類に整理し、工程別の出現傾向を確認した。これにより、演出・監督による「演出意図の具現化」と、作監・総作監による「絵を整える」という役割分担が数値として裏付けられた。次節では、これらの修正が具体的にどの箇所（部位や要素）に対して現れやすいかを把握するため、修正内容ごとに修正箇所の集計を行った。

\subsection{修正内容ごとの修正箇所の分析}
続いて、前述した修正内容ごとに、具体的な修正箇所の傾向を分析した。
表\ref{tab:intent_top5_contents}に、各修正内容における上位5種の修正箇所（修正枚数による集計）を示す。



「清書」においては、描線の整理が主目的となるため、特定の部位に限定されず、
全身や衣装、四肢といった広範囲に及んでいる。これは、作画クオリティの底上げがカット全体に関わる作業
であることを示している。 「絵柄統一」では、目、輪郭、口といった顔の印象を決定づけるパーツが
上位を占めた。キャラクタデザインへの準拠は、主に顔周辺の微細なニュアンスの調整として現れる傾向にある。 
「芝居」に関しても、目、口、眉といった表情を司る部位に修正が集中しており、キャラクタの演技意図
がこれらのパーツの微調整によって具体化されていることが見て取れる。

「動き・タイミング」については、全身の姿勢やポーズの調整が核となっており、
それに伴って衣装や口などの付随的な要素にも修正が波及している。 
「立体・角度」は、顔のみならず足や着物の形状など、パースの整合性が問われる部位において修正が発生しやすい。
特に四肢や衣装の重なりにおいて、空間的な違和感の解消が求められていることがわかる。

「画面設計」では構図やカメラ位置といったレイアウト要素が中心となり、「設定・世界観整合」
では小物や背景の設定準拠が主たる修正対象であった。 「光源」は影の付け方が支配的であり、「連続性」
については特定の部位に偏らず、前後整合が必要な箇所がそのまま修正対象として現れる結果となった。


\begin{table}[h]
    \centering
    \caption{修正内容別の上位5種の修正箇所}
    \label{tab:intent_top5_contents}
    \begin{tabularx}{\linewidth}{l*{5}{>{\raggedright\arraybackslash}X}}
        \hline
        修正内容 & 1位 & 2位 & 3位 & 4位 & 5位 \\
        \hline
        清書 & 全身（48） & 着物（28） & 足（26） & 目（24） & 口（20） \\
        絵柄統一 & 目（44） & 輪郭（37） & 着物（34） & 口（32） & 眉（31） \\
        芝居 & 目（34） & 口（30） & 眉（22） & 輪郭（15） & 髪（10） \\
        動き・タイミング & 全身（13） & 口（8） & 着物（8） & 足（7） & 服（4） \\
        立体・角度 & 足（13） & 着物（12） & 肩（10） & 顔（10） & 目（9） \\
        画面設計 & 構図（3） & 全身（2） & カメラ位置（1） & 口（1） & 小物（1） \\
        設定・世界観整合 & 小物（22） & 着物（9） & 背景（5） & 仮面（3） & 口（3） \\
        光源 & 影（11） & 足（1）& - & - & -\\
        連続性 & 全身（1） & 口（1） & 構図（1） & 目（1） & 眉（1） \\
        \hline
    \end{tabularx}
\end{table}


\subsection{修正箇所の分類}
次に、修正対象を「顔まわり」「手足」「衣装」「画面要素」の4カテゴリに分類し、分析を行った。各カテゴリの定義は以下の通りである。本カテゴリ設計は、工程ごとの特性（担当者間の役割差）が顕著に現れること、および必要に応じて詳細な部位（目・輪郭等）へ再分解が可能であることを意図している。

\begin{itemize}
  \item 顔まわり：目、眉、口、鼻、輪郭、髪、表情、耳など。
  \item 手足：手、指、腕、足など。
  \item 衣装：着物、洋服、模様、マフラーなどの着衣物。
  \item 画面要素：構図、背景、影、光源、小物、文字などのレイアウト要素。
\end{itemize}

\subsubsection{集計方法}
一枚の修正指示が複数の領域にまたがる場合（例：顔の向きと同時に腕の位置を直す等）を考慮し、
本分析ではカテゴリを排他的にせず、重複カウントを許容した。
そのうえで、担当者ごとにカテゴリ別の修正枚数および構成比を算出し、重点的に修正される領域の比較を行った。

\begin{table}[h]
  \centering
  \caption{担当者別：修正対象カテゴリの内訳（構成比）}
  \label{tab:category_share}
  \begin{tabular}{l|rrrr}
    \hline
    担当者 & 顔まわり & 手足 & 衣装 & 画面要素 \\
    \hline
    演出   & 34\% & 21\% & 2\%  & 43\% \\
    監督   & 50\% & 30\% & 5\%  & 15\% \\
    作監   & 33\% & 23\% & 30\% & 14\% \\
    総作監 & 29\% & 29\% & 37\% & 5\%  \\
    \hline
  \end{tabular}
\end{table}

\subsubsection{演出修正} 
演出修正の構成比を図\ref{enshutushuusei}に示す。演出工程では「画面要素」が43\%と最も高く、
次いで「顔まわり」が34\%となっている（表\ref{tab:category_share}）。この傾向は、
演出が「画面としての成立（レイアウトの意図）」と「演技の成立（感情表現）」を最優先することを裏付けている。

具体的な修正事例を以下に挙げる。 

\begin{itemize} 
  \item 画面要素：キャラクタの配置・サイズが演出意図と乖離している際のカメラワークやレイアウトの調整。また、背景の密度が画面の可読性を損なう場合の要素再配置、小物の意匠設定との整合性確保など。特に自然物の多い屋外シーンでは背景要素への修正が顕著となる。 
  \item 顔まわり：視線の方向が演技と不一致な場合の調整、あるいは眉や口元の形状を強調することで、怒りや緊張といった特定の感情を立ち上がらせる修正。 
\end{itemize} 

演出修正は第一原画に対する初期チェックであるため、描線の精緻化よりも、画面構成の骨格や演技の方向性を決定づける部位に指示が集中する。

\begin{figure}[h]
    \centering
    \includegraphics[scale=0.7]{fig/演出.png}
    \caption{演出修正における修正対象カテゴリ内訳}\label{enshutushuusei}
\end{figure}


\subsubsection{監督修正}
監督修正は「顔まわり」が50\%と過半数を占め、次いで「手足」が30\%を占める。

\begin{itemize}
  \item 顔まわり：演技意図を極大化するための表情の微調整が主となる。特筆すべき事例として、睡眠時のキャラクタへの「よだれ」の追加など、キャラクタの個性を強調する生理的表現の付加が見られた。
  \item 手足：キャラクタ固有のシルエットへの近似や、次フレームとの整合性を確保するための四肢のポジション変更などが主である。
\end{itemize}

監督修正は発生頻度こそ限定的だが、介入する際には特定のディテールに対して枚数を割き、
局所的に密度の高い修正を施す傾向にある。これは、作品全体の質感を決定づける重要なニュアンスを監督自らが
担保しているためと解釈できる。

\begin{figure}[h]
    \centering
    \includegraphics[scale=0.7]{fig/監督.png}
    \caption{監督修正における修正対象カテゴリ内訳}\label{kantokushuusei}
\end{figure}

\paragraph{作監修正}
作監修正の構成比を図\ref{sakkannshuusei}に示す。作監工程では各カテゴリに比較的均等に修正が入っており、
対象範囲が極めて広い。他工程と比較して「衣装」の修正（30\%）が多発している点は、本分析対象作品が衣装の模様
やなびきに高い作画コストを割いている実態を反映している。

\begin{itemize}
  \item 顔まわり：表情の変更よりも、デザイン準拠のためのパーツ配置の整理や、ラフ線の清書が主目的となる。
  \item 手足：人体の解剖学的なバランス（長さ、太さ、関節の曲がり具合）の補正。
  \item 衣装：着物の柄の連続性確保、しわの線量の最適化など。衣装は線数が多く形状制約も強いため、清書段階での技術的修正が必然的に増加する。
\end{itemize}

以上より、作画監督は「絵を整える」という役割を、身体から衣装まで網羅的に担っているといえる。

\begin{figure}[h]
    \centering
    \includegraphics[scale=0.7]{fig/作監.png}
    \caption{作監修正における修正対象カテゴリ内訳}\label{sakkannshuusei}
\end{figure}


\subsubsection{総作監修正}
総作監修正の分析結果を図\ref{sousakkannshuu}に示す。
総作監修正では「衣装」が37\%と最多となり、次いで「顔まわり」「手足」が各29\%と続く。
一方で「画面要素」は5\%と極めて小さい。これは総作監が画面レイアウトよりも、
キャラクタのビジュアル的な統一感（キャラクタ・アイデンティティ）の維持に注力していることを示している。

\begin{itemize}
  \item 顔まわり：輪郭線の揺れを抑え、数カット跨いでも同一人物に見えるよう印象を収束させる調整。
  \item 衣装：作監工程で整えられた形状をさらに精査する
  \item 手足：頭身バランスやシルエットの太さを作品規格と合致させる。
\end{itemize}

総作監は、キャラクタが画面に登場した際の印象を全カットで均質化する、最終的なフィルターの役割を果たしている。

\begin{figure}[h]
    \centering
    \includegraphics[scale=0.7]{fig/総作監.png}
    \caption{総作監修正における修正対象カテゴリ内訳}\label{sousakkannshuu}
\end{figure}

\section{おわりに}
本章では、アニメ制作のワークフローに沿って各工程の業務とそのチェック工程について述べたのち、
アニメーション制作スタジオ（ufotable）における現場での修正の活用事例について述べた。

また、ufotableに提供された実データに基づき、第一原画修正に関する多角的な分析を行った。

制作現場において、修正データは単なる作業記録に留まらず、制作スケジュールの精度向上に向けた分析材料や、アニメーターの技術向上を促す参考資料として極めて有効に活用されている実態が明らかとなった。また、本分析を通じて、演出・監督・作画監督・総作画監督の各修正工程が、それぞれ固有の修正意図および対象箇所を有していることが定量的に示された。

次章以降では、これらの分析結果から得られた修正傾向を体系的に管理・把握するための「タグ設計」について述べる。さらに、それらを視覚言語モデル（VLM）や物体検出技術を用いて自動的に付与し、制作管理を効率化するシステムの構築を提案する。


\chapter{調査に基づく修正のタグ付け手法}
\section{はじめに}
本章では、前章での実態調査および分析を踏まえ、アニメーション制作管理の効率化
に寄与するタグの設計指針を定義し、それらを自動付与するための手法を提案する。

\section{調査に基づくタグの設計}
制作現場における修正データの活用可能性を最大化するため、以下の3つの活用例を提示し、それぞれに対応するタグを設計した。

\begin{enumerate} 
  \item 頻出修正の分析による発生抑制 \\
  特定の作品や工程において、担当者を問わず同様の修正（例：シルエットの崩れ等）が多発している
  箇所を特定することで、以降の作業においてアニメーターへ事前に注意喚起を行い、リテイクの削減を図る。 
    \begin{itemize} 
    \item 対応タグ：設定資料の閲覧履歴、被写体の動き・姿勢、修正部位 
    \end{itemize}
  \item 適材適所なタスク割り当ての支援\\
  原画担当者が不得意とする描写（例：群衆、複雑なアクション等）と、修正担当者（作監等）が重視するこだわり（例：表情のニュアンス、特定のポーズ等）を可視化し、仕事の割り振りを支援する。
    \begin{itemize}
    \item 対応タグ：設定資料の閲覧履歴、原画担当者、修正担当者、被写体の数・関係性、被写体の表情、動き・姿勢、修正部位
    \end{itemize}
  \item 修正内容に依拠した精緻な作業速度の計測\\
  例えば「手のアップ」など、難易度や描き込み量の異なるカットごとに修正所要時間を把握することで、類似カットの依頼時に高精度なスケジュール見積もりを可能にする。
  \begin{itemize}
    \item 対応タグ：修正担当者、作業の開始日・終了日、被写体の映り方（ショットサイズ）、カメラアングル、被写体の画面占有率
  \end{itemize}
\end{enumerate}

以上の検討に基づき、本研究では以下の9項目のタグを管理対象として設定した。
\begin{itemize}
    \item 設定資料の閲覧履歴
    \item 原画・修正担当者
    \item 作業の開始日と終了日
    \item 被写体の数と関係
    \item 被写体の映り方・カメラアングル
    \item 被写体の表情
    \item 被写体の動き・姿勢
    \item 修正部位
    \item 画面占有率
\end{itemize}

\section{修正の自動タグ付けフロー}
自動タグ付けの全体フローを図\ref{fuccitagging}に示す。
本手法では、既存の「渕上らのシステム」から得られるメタデータと、本研究で提案する画像解析ベースの自動タグ付けを統合する。

まず、彩色済み画像に対して、VLM（Vision Language Model）および物体検出モデル
を用いた推論を行い、「カット内容に関する属性タグ」と「部位領域（Bounding Box）」を抽出する。
次に、修正素材（修正絵）から抽出した「修正領域（修正マスク）」を彩色済み画像上の部位領域に重ね合わせ、
空間的な重複度を算出する。これにより、各部位ごとの修正の有無を自動判定し、「修正対象部位」および「画面占有率」
のタグを取得する。

\begin{figure}[h]
    \centering
    \includegraphics[width=\linewidth]{fig/fuccitagging.png}
    \caption{渕上らのシステムの情報伝達の流れ}\label{fuccitagging}
\end{figure}

なお、前述した9項目のタグのうち、以下の管理項目については既存のシステムからログデータ
として取得可能であるため、本研究ではそれら以外の画像依存型タグの自動生成手法に焦点を当てる。
\begin{itemize}
    \item 設定資料の閲覧履歴
    \item 原画・修正担当者
    \item 作業の開始日と終了日
\end{itemize}

\section{VLMによる彩色画像のタグ付け}
本節では、画像の内容（コンテキスト）に基づくタグ付け手法について詳述する。

VLMによる推論を通じて取得を目指すタグは、以下の4カテゴリである。
これらは物体検出よりもVLMによる意味的な理解が活きる項目として定義した。

\begin{itemize}
    \item 被写体の数と関係
    \item 被写体の映り方・カメラアングル
    \item 被写体の表情
    \item 被写体の動き・姿勢
\end{itemize}

このためのプロンプトとして、以下の文章を採用する。


\begin{tcolorbox}[
    breakable,
    colback=white,      % 背景色（白）
    colframe=black,     % 枠の色（黒）
    arc=0mm,            % 角の丸み（0なら直角）
    boxrule=0.5pt,      % 枠線の太さ
    left=1em, right=1em, top=1em, bottom=1em % 内側の余白
]
\small
【目的】
入力画像（単体 or 同一カットの複数フレーム）から、以下のカテゴリだけを抽出して
厳密にJSONのみを出力してください。\\
※ 許可していないカテゴリ（outfit/attributes/colors/style/text 等）や説明文・コメントは一切出さない。

【抽出カテゴリ（出力してよいトップレベルキー）】
\begin{itemize}
  \item summary
  \item subjects
  \item interactions（被写体が2人以上のときのみ）
  \item background
  \item props
\end{itemize}

【座標（bbox）のルール：必須】
\begin{itemize}
  \item subjects / props には bbox を含める。
  \item bbox は 4値の配列：\texttt{[x\_min, y\_min, x\_max, y\_max]}
  \item 座標は正規化座標（0.0〜1.0）で表す。
    \begin{itemize}
      \item 原点(0,0)は画像の左上、(1,1)は右下。
    \end{itemize}
  \item 可能な限りタイトに囲う。判断不能なら、その要素自体を出力しない。
\end{itemize}

【被写体（subjects）の抽出カテゴリ（固定語彙の例つき）】
\begin{enumerate}
  \item 被写体の写り方（cropping）\\
    wide（引き/ロング：人物が画面内で小さく、全体の状況・空間を見せるショット）,
    close\_up（顔や手のアップ）,
    bust（胸上/上半身）,
    half（腰上/半身）,
    full（全身）から選択。
  \item カメラ角度・視点（camera\_angle）\\
    front（正面）, back（背面）, profile（側面/横顔）, low（仰角）, high（俯瞰）, three\_quarter（3/4視）から選択。
  \item 姿勢（pose）※複数可、各要素にconfidence
    \begin{itemize}
      \item 立つ/座る/歩く/走る/跳ぶ/しゃがむ/ひざをつく/寝る
      \item 指さす/手を振る/見る（注視する）/振り向く/腕組み/祈る（手を合わせる）
      \item 抱える/持つ/手渡す
      \item 構える（身構える）/攻撃する/防ぐ（ガードする）/逃げる
    \end{itemize}
    ※ 推測で埋めない。判別が弱い場合は pose 自体を省略する。
  \item 表情（expression）※複数可、各要素にconfidence
    \begin{itemize}
      \item 笑顔/怒り/悲しみ/驚き/困惑/無表情/緊張
      \item 泣き/焦り（慌て）/照れ/怯え/得意顔（ドヤ）
      \item 後ろ向きなど、判別不能な場合は \texttt{None} とする。
    \end{itemize}
  \item 相互関係（interactions）※被写体が2人以上のとき必須\\
    以下から選択：
    \begin{itemize}
      \item conversation（会話）, handshake（握手）, gaze\_contact（見つめ合い）, physical\_contact（接触）,
            group\_action（集団動作）, confrontation（対峙）, chase（追跡：追う/追われる）
      \item handover（受け渡し：物を渡す/受け取る）, support（介抱・支える：支援/救助含む）,
            attack（攻撃：一方が他方を攻撃）, defense（防御：一方が他方から守る/かばう）
      \item 根拠が弱い場合は推測で出さず、interactions 自体を省略する。
    \end{itemize}
\end{enumerate}

【背景（background）】
\begin{itemize}
  \item 背景を単語で示す。
  \item 背景が判別不能（白背景など）のときは省略可能。
  \item 判断不能なら background 自体を省略する（空配列は出さない）。
\end{itemize}

【小物（props）】
\begin{itemize}
  \item 人物以外の目立つ小物・道具・乗り物・武器・食べ物・家具、エフェクトなどを列挙する（背景そのものは含めない）。
  \item props は複数可。各要素に \texttt{name / bbox / confidence} を付与する。
  \item 判断不能なら props 自体を省略する（空配列は出さない）。
\end{itemize}

【人数に応じた出力ルール】
\begin{itemize}
  \item 被写体（人物/キャラ/生物など）の \textbf{人数が0}：
    \begin{itemize}
      \item subjects は出さない。
      \item interactions も出さない。
      \item summary は必須。
      \item background / props は分かる範囲で出してよい。
    \end{itemize}
  \item \textbf{1人}：
    \begin{itemize}
      \item subjects を1要素で出力。
      \item interactions はキーごと省略。
    \end{itemize}
  \item \textbf{2人以上}：
    \begin{itemize}
      \item subjects に人数ぶんの要素を作成し、id を 1..N で振る。
      \item id の付け方は \textbf{画面左→右（同程度なら大きい方優先）} を基本として安定させる。
      \item interactions を必ず出力し、participants は subjects[].id を参照する。
    \end{itemize}
\end{itemize}

【信頼度（confidence）】
\begin{itemize}
  \item 0.0〜1.0 の小数（小数第2〜3位程度）で付与。
  \item cropping / camera\_angle はオブジェクト形式で value と confidence を持たせる。
  \item pose / expression は配列（複数候補可、各要素に confidence）。
  \item bbox にも confidence を付与してよい（ただしキーは増やさず、bbox は配列のまま）。
\end{itemize}

【不明時の扱い】
\begin{itemize}
  \item 不明な要素は \textbf{出力しない（キーごと省略）}。空配列は避ける。
  \item 推測しすぎず、判断困難な場合は該当キーを省略する。
\end{itemize}

【最終出力フォーマット（JSONのみ/UTF-8/改行可/キー順任意）】
\begin{verbatim}
{
  "summary": "カット全体の要約（1〜2文）",
  "subjects": [
    {
      "id": 1,
      "bbox": [0.00, 0.00, 0.00, 0.00],
      "cropping": { "value": "bust", "confidence": 0.00 },
      "camera_angle": { "value": "front", "confidence": 0.00 },
      "pose": [ { "description": "手を振る", "confidence": 0.00 } ],
      "expression": [ { "description": "笑顔", "confidence": 0.00 } ]
    }
    //2人以上なら id=1,2,3... を追加
  ],
　//2人以上のときのみ出力
  "interactions": [
    {
      "type": "conversation|handshake|gaze_contact|physical_contact|group_action",
      "participants": [1, 2],
      "description": "簡潔な要約（例：向かい合って会話）",
      "confidence": 0.00
    }
  ],
  "background": [
    {
      "description": "劇場",
      "confidence": 0.00
    }
  ],
  "props": [
    {
      "name": "小物名（例：スマホ、刀、椅子、マグカップ）",
      "bbox": [0.00, 0.00, 0.00, 0.00],
      "confidence": 0.00
    }
  ]
}

（注）
- ここに書かれていないキー（outfit/attributes/colors/objects/styleの別形式/text_in_image/nsfw/uncertainties 等）は **出力しない**。
- 1人のときは interactions を出さない。0人のときは subjects と interactions を出さない。
\end{verbatim}
\end{tcolorbox}



\vspace{\baselineskip}
本研究において、上述のような厳密なプロンプトを設計した理由は、主に以下の4点に集約される。

第一に、出力を機械可読性の高い形式に統一するためである。
本研究ではタグ付け結果を後続の統計分析や検索システムに活用することを目的としているため、
自由記述のテキスト形式ではなく、固定語彙と階層構造を有するJSON形式を採用した。これにより、
データベースへの格納および後処理の安定化を図っている。

第二に、VLMが生成する傾向にある冗長な説明や過度な推測を抑制し、
抽出情報を本研究に必要な範囲に限定するためである。特に、
衣装や背景といった本研究の主目的と直接関係しない要素の混入は、
タグの一貫性を損なうだけでなく、分析におけるノイズとなり得る。

第三に、複数人物が登場するカットにおいても同一のスキーマで管理するためである。
人数に応じた出力ルールを明示し、相互関係（interactions）を被写体ID間の参照として表現する
ことで、カット全体における文脈や関係性の定量的記録を可能にした。

最後に、各抽出項目に信頼度（confidence）を付与させることで、
実運用上の柔軟性を確保することを目指した。これにより、後段の処理において閾値に基づく自動フィルタリングや、
人手による確認の優先度付けを行うことが可能となり、分析データの品質管理が容易となる。



\section{物体検出による彩色画像のタグ検出}
\subsection{目的}
本節では、前章の調査において定義した「修正対象部位」および「画面占有率」
を彩色済み画像から推定するための、物体検出モデルを用いたタグ抽出手法について述べる。

\subsection{検出対象（部位タグ）の設計}
修正対象部位の語彙（ラベル）は、制作現場での分析・共有における有用性と、
モデルによる検出精度の安定性を考慮し、以下の8種類を採用した。

\begin{itemize}
  \item face (顔)
  \item eyes (目)
  \item mouth (口)
  \item arm (腕)
  \item nose (鼻)
  \item head (頭)
  \item leg (脚)
  \item person (人)
\end{itemize}

実装においては、画像に対して上記語彙をゼロショット物体検出器にプロンプトとして与えることで、
各部位のバウンディングボックス（以下、$B_i$）と検出スコアを取得する。
複数人物が存在するカットにおいても、スコア閾値以上の検出結果をすべて保持することで、多人数構成に対応する。

\subsection{画面占有率の算出}
面占有率 $r$ は、被写体が画面内で占める面積の割合を示す指標であり、作画作業量や修正難易度の推定
に寄与する。本研究では、人物領域（person）のバウンディングボックス面積 $A_{\mathrm{person}}$ 
を画像全体の面積 $A_{\mathrm{image}}$ で除した値として定義する。

\begin{equation} 
  r = \frac{A_{\mathrm{person}}}{A_{\mathrm{image}}} 
\end{equation}

複数人物が存在する場合、矩形同士の重なりによる二重計上を防ぐため、
矩形の和集合（Union of Rectangles）の面積を算出する。なお、オクルージョン等により
人物全体の検出が不安定な場合は、face や head 等の安定した部位の外接矩形から人物領域を近似的に推定し、
代替値として用いる。

\section{修正部位の自動特定}
\subsection{基本方針}
彩色済み画像から得られた部位領域 $B_i$ と、
修正素材（修正絵）から抽出した修正情報を空間的に統合し、「どの部位に修正指示が施されたか」
を自動推定する手法を述べる。

\subsection{修正領域（修正マスク）の抽出}\label{mask_theta}
修正素材から、追記された線画成分のみを二値マスク $M$（修正画素を1、背景を0）として抽出する。
本研究が対象とする修正素材は背景が単色であるため、画像全体の画素値の中央値 $\bm{c}_{bg}$ を背景色として推定し、各画素 $\bm{c}(x,y)$ との幾何学的距離 $d(x,y)=\|\bm{c}(x,y)-\bm{c}_{bg}\|$ に基づき判定を行う。
閾値 $\theta$ を用いたマスク生成式を以下に示す。
$$
M(x,y)=
\begin{cases}
1 & (d(x,y)\ge \theta)\\ 
0 & \text{otherwise}
\end{cases}
$$

\subsection{部位ごとの修正判定}
彩色済み画像上の部位バウンディングボックス $B_i$ ごとに、内部に含まれる修正画素の密度 $s_i$ を計算する。
これは、ボックス面積に対する修正画素数の比率として定義される。
\begin{equation}
  s_i = \frac{|M \cap B_i|}{|B_i|}\tag{4.2} \label{ink_ratio}
\end{equation}

ここで $| \cdot |$ は領域内の画素数を表す。この $s_i$ が高いほど、当該部位に集中的な修正指示が
行われたことを示唆する。

\subsection{判定信頼度の算定}
修正部位の判定における信頼度（判定スコア） $c_i$ は、(1) 物体検出自体の確信度 $score(B_i)$ と、
(2) 物理的な修正密度 $s_i$ の積として定義する。

\begin{equation}
  c_i = score(B_i) \cdot s_i\tag{4.3} \label{judge_score}
\end{equation}
算出した $c_i$ が所定の閾値 $\theta_{judge}$ を上回る部位を「修正対象部位」として採択し、自動タグ付けを行う。

\section{本章のまとめ}
本章では、前章での実態調査に基づき設計した9項目のタグ\ref{tagtable}を自動付与するため、
VLMと物体検出を統合したハイブリッド型の自動タグ付け手法を提案した。

本手法の成果と意義
\begin{itemize}
  \item 定性情報の構造化: VLMを用いて、被写体の写り方、表情、動作、および相互関係を抽出するプロンプトを設計した。
  出力を固定スキーマの JSON形式 に統一することで、制作現場での蓄積と統計的分析に適したデータ構造を実現した。
  \item 修正箇所の定量化: 物体検出によって特定した部位領域（Bounding Box）と、修正素材から生成した修正マスクを空間的に統合するロジックを定義した。これにより、従来は定性的な指示に留まっていた「修正の発生箇所」を、画素密度に基づく客観的なデータとして記録できる見通しを示した。
\end{itemize}

今後の課題と展望

提案手法の有効性を確認した一方で、実運用に向けては以下の技術的課題が残されている。

\begin{itemize}
  \item 空間的整合性の向上: 修正素材と彩色済み画像間の微細な位置ずれ（レジストレーションミス）への対応。
  \item 検出のロバスト性: キャラクターが重なり合う（オクルージョン）カットにおける部位検出の安定化。
  \item 微小変化への感度: 瞳のハイライトや繊細な表情の変化など、小規模な修正画素に対する検出感度の最適化。
\end{itemize}

これらの課題に対しては、特徴点マッチングによる位置補正技術の導入や、アニメ制作素材に特化したファインチューニングの実施により、
改善が可能であると考えられる。

次章では、本手法に基づくプロトタイプの実装詳細、および実データを用いた検出精度の評価結果について述べる。


\begin{table}[h]
    \centering
    \caption{タグまとめ}\label{tagtable}
    \begin{tabular}{|c|c|c|}\hline
         & 入手方法 & 目的 \\ \hline
        設定資料の閲覧履歴 & 渕上らのシステム & 修正傾向分析・タスク割り当て支援\\
        原画・修正担当者 & 渕上らのシステム & タスク割り当ての支援 \\
        作業の開始日と終了日 & 渕上らのシステム & 精緻な作業速度の計測\\
        被写体の数と関係 & VLM & タスク割り当ての支援 \\
        被写体の映り方・カメラアングル & VLM & 精緻な作業速度の計測 \\
        被写体の表情 & VLM & タスク割り当ての支援\\ 
        被写体の動き・姿勢 & VLM & 修正傾向分析・タスク割り当ての支援\\ 
        修正部位 & 物体検出 & 修正傾向分析・タスク割り当ての支援 \\ 
        画面占有率 & 物体検出 & 精緻な作業速度の計測 \\ \hline
    \end{tabular}
\end{table}



\chapter{評価}
\section{はじめに}
本章では、前章で提案した手法によるタグ付けの精度を検証し、その結果を考察する。

\section{タグ付け実験と共通評価指標}
\subsection{実験内容}
NIITriggerのデータセット「LWA」\cite{trigger}に含まれる100カットのうち、
第一原画に対する修正指示画像51枚を対象としてタグ付け実験を行った。 
VLMのモデルにはQwen3-VL-30B-A3Bを、物体検出モデルにはMM Grounding Dino (Swin-L)を用いた。
なお、修正指示には類似画像が多く含まれるため、各カットから代表的な修正画像を1枚または2枚選出した。

\subsection{共通評価指標の定義}\label{hyouka_sihyou}
本研究における自動タグ付けの精度を評価するため、以下の指標を定義する。
各サンプルに対して、正解ラベルの集合を $G$、システムによる推定ラベルの集合を $P$ とする。このとき、True Positive (TP)、False Positive (FP)、False Negative (FN) をそれぞれ以下のように定義する。
\begin{equation}
    \mathrm{TP} = |G \cap P|, \quad \mathrm{FP} = |P \setminus G|, \quad \mathrm{FN} = |G \setminus P|
\end{equation}

これらに基づき、適合率 (Precision)、再現率 (Recall)、および F1 スコア (F1-score) を算出する。
\begin{equation}
    \mathrm{Precision} = \frac{\mathrm{TP}}{\mathrm{TP} + \mathrm{FP}}, \quad \mathrm{Recall} = \frac{\mathrm{TP}}{\mathrm{TP} + \mathrm{FN}}, \quad \mathrm{F1} = \frac{2 \cdot \mathrm{Precision} \cdot \mathrm{Recall}}{\mathrm{Precision} + \mathrm{Recall}}
\end{equation}

また、マルチラベル分類における集合の一致度を測る指標として、以下のラベル集合に対する Jaccard 係数（IoU）および完全一致率（Exact Match Ratio）を併せて報告する。
\begin{equation}
    \text{Jaccard Index} = \frac{|G \cap P|}{|G \cup P|}
\end{equation}

さらに、全サンプル・全ラベルを合算して算出するマイクロ平均（Micro-average）と、各ラベルごとに算出した指標の平均をとるマクロ平均（Macro-average）
を評価の目的に応じて適宜活用する。

\section{VLM による彩色画像のタグ付け実験}
\subsection{VLMによる彩色画像のタグ付け例}
Qwen3 VLによるタグ付けの具体例として図\ref{example}を考える。

\begin{figure}[h]
  \centering
  \includegraphics[width=\linewidth]{fig/image_for_vlm.png}\label{example}
  \caption{彩色済み画像の例}
\end{figure}

これに応じたVLMの出力は図\ref{vlm_output.png}のようになった。
\begin{figure}[h]
  \centering
  \includegraphics[scale=0.5]{fig/vlm_output.png}\label{vlm_output.png}
  \caption{VLMの出力例}
\end{figure}

これより、タグとして、「half（半身）」、「profile（横向き）」、「走る」、「驚き」を得る。
このタグは「half」、「profile」は正解しているが、「走る」、「驚き」については誤っている。


\subsection{評価データと手法}
Qwen3 VL を用い、画像全体からの属性抽出精度を検証する。
評価には、 前述の 51 枚の画像を対象とし、人手により作成した正解データ（Ground Truth, 以下 GT）との比較評価を行った。

GT は以下の構成で定義されている。
\begin{itemize}
    \item 人数推定 (\texttt{id\_count}): 画像内に存在する人物の総数
    \item 人物属性: 各人物に対し、画面左からの出現順に基づき \texttt{id} を割り当て、構図 (\texttt{cropping})、カメラアングル (\texttt{camera\_angle})、姿勢 (\texttt{pose})、表情 (\texttt{expression}) の各属性を付与する。なお、パースの解釈が複数分かれる場合は 「\texttt{or}」 表記による複数ラベルを許容し、情報の欠落や判定不能な箇所は 「\texttt{None}」 と定義した。
    \item 小物 (\texttt{props}): 画像内に存在する特定のアイテムを集合形式で列挙する。
    \item 相互関係 (\texttt{interactions}): 人物間のアクション（例：\texttt{group\_action}）を定義する。
\end{itemize}

評価には、前述の指標\ref{hyouka_sihyou}に加え、人数推定の精度を定量化するため、以下の平均絶対誤差 (MAE: Mean Absolute Error) を用いる。
\begin{equation}
    \mathrm{MAE} = \frac{1}{N} \sum_{i=1}^{N} |G_i - P_i|
\end{equation}
ここで、$N$ はサンプル数、$G_i$ および $P_i$ はそれぞれ第 $i$ サンプルにおける人数の正解値および推定値である。

\subsection{実験結果と考察}
Qwen3 VL による全体指標および人数・関係性の推定精度の要約を表 \ref{tab:qwen_overall} 、
人物の属性別の推定精度を表 \ref{tab:qwen_attributes} に示す。

\begin{table}[htbp]
\centering
\caption{全体指標および人数・関係性の推定精度}
\label{tab:qwen_overall}
\begin{tabular}{lc}
\hline
評価項目 & スコア \\ \hline
人数一致率 (Exact Match) & 0.725 \\
人数誤差 $\pm1$ 以内の割合 & 0.863 \\
人数推定平均絶対誤差 (MAE) & 0.922 \\
小物の推定精度 (Micro F1) & 0.348 \\
相互関係の一致率 (Exact Match) & 0.667 \\ \hline
\end{tabular}
\end{table}

\begin{table}[htbp]
\centering
\caption{人物属性別の推定精度}
\label{tab:qwen_attributes}
\begin{tabular}{lcc}
\hline
属性項目 & 精度 (Include None) & 精度 (Exclude GT None) \\ \hline
映り方 (\texttt{cropping}) & 0.695 & 0.695 \\
アングル (\texttt{camera\_angle}) & 0.415 & 0.447 \\
姿勢 (\texttt{pose}) & 0.634 & 0.694 \\
表情 (\texttt{expression}) & 0.317 & 0.377 \\ \hline
\end{tabular}
\end{table}

\subsubsection{失敗例の分析（Worst 10）}
人物の属性別スコアの平均値が低い 10 サンプルについて，誤りの内訳を
調査した。その結果、主に以下の 3 つの傾向が確認された。
\begin{enumerate}
  \item camera\_angle(カメラアングル) の誤りが頻発：正解（GT）が \texttt{three\_quarter}（斜め）や \texttt{low}（煽り）であるカットに対し、推定結果が \texttt{front}（正面）や \texttt{profile}（横顔）となる事例が頻発した
  \item cropping(被写体の写り方)の取り違え：GT が \texttt{wide} であるのに対し、推定が \texttt{full} となる誤認識や、\texttt{bust} と \texttt{half} の混同が見られた。
  \item expression (表情)の識別困難：GT の「得意顔」に対し「無表情」、GT の「怒り」に対し「驚き」と推定される事例があった。アニメーション特有の誇張や省略を伴う表情表現は、既存の語彙体系による分類が極めて困難であるといえる。
\end{enumerate}


\subsection{考察}
実験結果から、VLM は 「人数、構図、人物間の関係性」といったマクロな情報の抽出において高い有用性を示すことが明らかになった。
特に、構図（\texttt{cropping}）と姿勢（\texttt{pose}）は \texttt{Exclude None}（有効値のみ）において約 70\% の精度を記録しており、アニメ制作におけるカット内容の自動把握を支援する実用的な水準に達していると考えられる。 また、相互関係の Jaccard 係数が 0.696 という高い値を示したことは、VLM が画像全体のコンテキスト（文脈）理解に優れていることを裏付けている。
一方で、微細な情報の判別には依然として課題が残る。カメラアングル（0.447）や表情（0.377）の精度が低迷した要因として、失敗例の分析により以下の傾向が浮き彫りとなった。

\begin{enumerate}
    \item 正面バイアス: 被写体が斜め向きや煽りの構図であっても、一貫して \texttt{front}（正面）と出力する傾向がある。これは、VLM の学習データにおける正面画像の多さ、あるいは判断の保守性に起因するものと推測される。
    \item 表情のデフォルメへの対応: 「得意顔」や「怯え」といったアニメ特有の記号的な表情ラベルを、より一般的な「無表情」や「笑顔」と誤認する事例が散見された。
\end{enumerate}

以上の結果から、今後はアニメ画像に特化した Fine-tuning（微調整）や、プロンプトにおける語彙定義のさらなる厳密化が、精度向上のための極めて重要な鍵になると考えられる。

\section{MM Grounding Dino による修正部位の精度評価}
\subsection{MM Grounding Dinoによるタグ付けの具体例}
MM Grounding Dinoによるタグ付けの具体例を以下に示す。
まず、彩色済み画像\ref{example}に対し、物体検出を行う。
その結果が図\ref{output_groundingdino}である。

\begin{figure}[h]
  \centering
  \includegraphics[width=\linewidth]{fig/grounding_dino_output.png}\label{output_groundingdino}
  \caption{MM Grounding Dinoによる物体検出例}
\end{figure}

また、修正の書き込みに対し、マスクを行う。
修正マスクの画像の白い部分が書き込みとして認識された部分である。
\begin{figure}[h]
  \centering
  \includegraphics[width=\linewidth]{fig/raf_image.png}\label{raf_image}
  \caption{修正}
\end{figure}

\begin{figure}[h]
  \centering
  \includegraphics[width=\linewidth]{fig/mask.png}\label{mask}
  \caption{修正マスク (閾値 $\theta$ = 30)}
\end{figure}

これらを重ね、判定スコアの閾値を0.02とすることで、図\ref{bounding_tags}のような結果となり、
eyes, mouth, nose, faceのタグが得られる。
\begin{figure}[h]
  \centering
  \includegraphics[scale=0.5]{fig/bounding_tags.png}\label{bounding_tags}
  \caption{得られたタグ (judgeは判定スコア[\ref{judge_score}]、scoreは物体検出の信頼度数値、ratioは修正画素の密度[\ref{ink_ratio}])}
\end{figure}


\newpage

\subsection{修正部位に関する評価データ}
人手により作成した正解データ（Ground Truth）と、システムによる推定結果を比較することで精度評価を行った。
評価対象は前述の 51 サンプルとし、各サンプルに付与される部位タグ（\texttt{face}, \texttt{eyes}, \texttt{mouth}, \texttt{arm}, \texttt{nose}, \texttt{head}, \texttt{leg}, \texttt{person}）を対象としたマルチラベル分類問題として扱う。

なお、本評価における正解ラベルは「画像内に特定の修正指示部位が存在するか否か」を定義した集合である。
そのため、自動推定において同一のラベルが複数のバウンディングボックスとして検出された場合であっても、
評価に際してはサンプル内における重複を除いた集合（ユニークなラベルセット）として扱い、正解集合との一致度を算出した。

\subsection{評価指標}
各サンプルに対し、正解ラベル（部位）の集合を $G$、推定されたラベルの集合を $P$ とする。
このとき、True Positive（TP）、False Positive（FP）、False Negative（FN）を以下のように定義する。
$$\mathrm{TP}=|G\cap P|,\quad
\mathrm{FP}=|P\setminus G|,\quad
\mathrm{FN}=|G\setminus P|$$

これらの値に基づき、適合率（Precision）、再現率（Recall）、およびF1スコア（F1-score）、Micro平均（Micro-average）
Macro F1（Macro-average F1）、完全一致率（Exact Match Ratio）、平均Jaccard係数（Average Jaccard Index）を算出する。

\subsection{評価結果}
表\ref{tab:overall_eval}に、提案手法による全体指標を示す。
全体的な評価指標を示す。
全 51 サンプルを対象とした実験において、Micro F1 スコアは 0.850 を記録した。
Micro Precision（0.853）と Micro Recall（0.847）が同水準であることから、
本手法は誤検出と検出漏れが均衡した、極めて安定的な検出性能を有していることが確認できる。
\begin{table}[h]\centering
  \caption{全体の評価結果（51件）}
  \label{tab:overall_eval}
  \begin{tabular}{l r}\hline
    指標 & 値 \\ \hline
    件数 $N$ & 51 \\
    TP / FP / FN & 221 / 38 / 40 \\
    Micro Precision & 0.853 \\ 
    Micro Recall & 0.847 \\
    Micro F1 & 0.850 \\ 
    Macro F1 & 0.773 \\
    Exact match & 0.250 \\ 
    平均Jaccard & 0.693 \\ \hline
  \end{tabular}
\end{table}

表 \ref{tab:per_label_eval} に、部位ラベル別の評価結果を示す。
部位別の分析では、\texttt{eyes} の Recall が 1.000、\texttt{mouth} の Recall が 
0.964 を記録した。これは、正解として定義された顔パーツの修正箇所のほぼ全てを、
本システムが網羅的に検出できていることを示している。
また、\texttt{nose}（F1: 0.906）や \texttt{face}（F1: 0.872）も高い水準にあり、
顔周辺の修正箇所特定において非常に高い信頼性を有していると言える。

\begin{table}[h] 
  \centering 
  \caption{ラベル別の評価結果（Precision / Recall / F1 / support）} 
  \label{tab:per_label_eval} 
  \begin{tabular}{l c c c c } \hline 
    ラベル & Precision & Recall & F1 & support \\ \hline 
    nose & 0.906 & 0.906 & 0.906 & 32 \\ 
    eyes & 0.816 & 1.000 & 0.899 & 31 \\ 
    mouth & 0.818 & 0.964 & 0.885 & 28 \\ 
    face & 0.872 & 0.872 & 0.872 & 39 \\ 
    arm & 0.806 & 0.926 & 0.862 & 27 \\ 
    head & 0.865 & 0.762 & 0.810 & 42 \\ 
    person & 0.971 & 0.647 & 0.776 & 51 \\ 
    leg & 0.667 & 0.909 & 0.769 & 11 \\ \hline 
  \end{tabular} 
\end{table}

\subsection{考察}
データから得られた本手法の特性について、以下の通り考察する。

まず、顔パーツ（目・口・鼻）の検出漏れが極めて少ない点が挙げられる。これは第3章で述べた「芝居（表情）」
に関わる修正を自動収集する上で大きな利点となる。特に「目」のRecallが1.0であることは、
視線の向きや瞬きのニュアンスなど、アニメーションにおける感情表現の核心となる修正箇所の自動タグ付けが、
本手法によって確実に実行可能であることを実証している。

さらに、ラベルによって「過剰検出（FP）」と「検出漏れ（FN）」の性質が異なることがわかる。 
\begin{itemize} 
  \item 過剰検出（FP）の傾向: \texttt{leg} は Recall（0.909）に対し Precision（0.667）が低く、背景の線画や他の身体部位を「脚」と誤認しやすい。
  \item 検出漏れ（FN）の傾向: \texttt{person} は Precision（0.971）に対し Recall（0.647）が低い。これは\texttt{person}のボックス面積に対する修正画素数の比率の小ささによるものと考えられる。
\end{itemize}

このような過剰検出、検出漏れについては、しきい値の調整(例:θjudge の引き上げ)や，部位ごとの個別しきい値設定， あるいは人物領域(person)との空間関係を用いたフィルタリング等により改善できる可能性がある。

総じて、本手法は顔周辺を中心とした特定の部位において高い精度を達成しており、
「修正の自動タグ付け」を実現するための強力な基盤となることが確認された。

\section{おわりに}
本章では、前章で提案した Qwen3 VLおよび MM Grounding DINO を組み合わせた自動タグ付け手法について、NIITrigger LWA データセットを用いた精度評価を行った 。

VLM による彩色画像の属性抽出においては、構図や姿勢といったマクロな情報の把握において実用的な精度が確認された一方、
アニメ特有の表情表現やカメラアングルの判別には、汎用モデル特有の「正面バイアス」などの課題が明らかとなった。
また、MM Grounding DINO による部位抽出では、特に顔周辺のパーツにおいて極めて高い網羅性（再現率）を示し、
アニメ制作における「芝居」の修正を管理するための強力な基盤となることが実証された 。

一方で、全身（\texttt{person}）の検出漏れや、\texttt{leg}の過剰検出といった課題も浮き彫りとなった 。
これらの知見は、今後のアニメ制作支援システムにおけるアノテーション設計や、
モデルの Fine-tuning における重要な指針となるものである。
以上の評価結果を踏まえ、次章では本研究全体の総括と、今後の展望について述べる。



\chapter{結論}
\section{本論文のまとめ}
本論文では、日本のアニメーション制作支援を目的とし、利活用を見据えた「修正の自動タグ付けシステム」を提案した。

2章では、アニメーション制作過程における中間生成物の蓄積・活用の現状を整理し、
特に修正素材に対する蓄積手法が未確立であることを指摘した。
また、アニメーション画像の整理に効果が期待できる画像認識技術について紹介した。

3章では、アニメーション制作会社へ赴き、制作現場における修正素材の活用事例と
実態について調査した。その結果、修正素材はスケジュール管理や作画の参考資料として活用されていることを確認した。
さらに、修正内容や箇所は担当者ごとに固有の特性を持つことを明らかにした。

4章では、調査結果に従って、頻出修正の分析による発生抑制、適材適所なタスク割り当ての支援、修正内容に依拠した精緻な作業速度の計測
という修正の活用方法を見出し、それに基づいた修正のタグを設計した。
さらに、視覚言語モデル（VLM）と物体検出モデルを組み合わせ、タグを自動で取得する
手法を提案した。

5章では、提案手法を用いた評価実験を行い、
自動付与されたタグがどの程度の精度になるか調査した。
VLM による彩色画像のタグ抽出においては、構図や姿勢といった情報の把握において、一定の精度が確認された一方、
表情やカメラアングルのタグの精度は芳しくない結果となった。
物体検出の部位検出は比較的高い精度が確認されたが、部位ごとの判定閾値の
調整といった改善点が見受けられた。

以上の結果から、本研究で提案した修正の自動タグ付け手法は、修正に適した設計になっており、
アニメーション制作の支援となりうるものであることを示した。

\section{今後の課題}
本システムは、渕上らのシステムを拡張する設計となっているが、
実システムへの組み込みは未達成である。
また、本手法は物体検出のプロンプトで直接的に部位を指定し、修正指示の書き込みとの重なりを判定しているが、
より細かい修正部位の情報を得るためには、プロンプトに直接入力しずらい輪郭や肩などの検出手法を考える必要がある。
加えて、現在の自動タグ付け手法は修正箇所の推論に依拠しており、
取得可能な情報は表層的な内容に偏っている。
「修正の発生要因」を推定する手法を考案できれば、修正のより本質的な分析が可能となることが期待できる。


\appendix
\chapter{リテイクに関与しない部分のアニメ会社調査結果}
必要に応じて、付録を載せる。

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%





\backmatter
\chapter{謝辞}
本論文の執筆にあたり、議論して頂いた関係者に感謝する。

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\bibliographystyle{jplain}
\bibliography{references}
%\begin{thebibliography}{99}
%  \bibitem{tokodai-xyz2015} 科学大太郎. 良い論文の書き方. \textit{Journal of XYZ}, Vol.~3, No.~4, pp. 15--34, 2015.
%\end{thebibliography}

\end{document}
