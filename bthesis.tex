\documentclass[11pt,oneside,openany,report]{jsbook}

\usepackage[a4paper,truedimen,margin=25truemm]{geometry}
\usepackage{cscover}
\usepackage[dvipdfmx]{graphicx}
\usepackage[nobreak]{cite}
\usepackage[a4paper,dvipdfmx,pdfdisplaydoctitle=true,%
    bookmarks=true,bookmarksnumbered=true,bookmarkstype=toc,bookmarksopen=true,%
    pdftitle={学位論文の体裁に関する研究},%
    pdfauthor={科学大太郎}%
    ]{hyperref}
\usepackage{pxjahyper}

\renewcommand{\bibname}{参考文献}
\setcounter{tocdepth}{2}
\pagestyle{plain}

\newcommand{\TODO}[1]{\textbf{[TODO: #1]}}
%\renewcommand{\TODO}[1]{}

\thesistype{学士特定課題研究論文}
\title{日本のアニメーション制作における\\リテイクの調査及び蓄積と活用}
\author{新穂 壮真}
\studentid{22B30610}
\affiliation{東京科学大学\\情報理工学院\\情報工学系} 
\date{2026年1月}

\supervisorname{指導教員}
\supervisor{齋藤 豪}
%\dsupervisorname{副指導教員}
%\dsupervisor{工学 次郎}

\begin{document}

\frontmatter
\maketitle

\chapter{概要}
ここに概要を書きます。

\tableofcontents
\listoffigures
\listoftables

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\mainmatter
\chapter{序論}
\section{本論文の背景と目的}

近年、アニメーション制作のデジタル化が進み、作画や撮影、編集
といった各工程においてコンピュータ上での作業が一般的になってきている。
それに伴い制作過程で扱うデジタルデータの量も増加している。
%これに伴い、制作過程で生成されるレイアウト、原画、動画、仕上げ画像など、
%さまざまなデータをどのように蓄積し利活用するかが重要な課題となっている。
とくに日本のアニメーション制作では、セルアニメーション由来の分業制やカット単位の工程管理が
現在も広く採用されており、各工程で多数の中間生成物や指示書類が発生し、
作品制作の過程で複雑に行き交っている。
その一方で、これらのデータが制作後に体系的に整理・蓄積されることは少なく、
制作ノウハウや現場での判断の多くが個人の経験や属人的な管理に依存しているのが現状である。

こうした状況を受けて、これまでにアニメーション制作におけるデータ管理や
中間生成物の蓄積を目的とした研究・システム開発がいくつか行われてきた。
しかし、それらはいずれも修正という行為そのもの、
すなわち演出や作画監督による修正指示や、その結果として更新された原画・動画といった情報を、
データ活用の観点から蓄積することには十分な焦点を当てていない。
新潟大学アニメ中間素材データベース AIMDB\cite{aimdb} はアニメ制作過程におけるデータの蓄積を目的としたデータベースであり、
リテイクをはじめとした様々な素材の蓄積に対応しているが、データ活用を意識した蓄積構造が設計されているとは言い難い。
渕上ら\cite{fucci}の研究では、データ活用を見据えた中間生成物の蓄積を行っているが、
修正に関する蓄積には対応していない。
修正は、作品のクオリティや作業者ごとの傾向を端的に反映する情報でありながら、
多くの場合は各カットの中に埋もれた形で扱われ、体系的に蓄積・分析されてこなかったと言える。

そこで本論文では、実際のアニメーション制作現場で役立つ視点から、
修正の蓄積とその活用方法を提案することを目的とする。
%その蓄積と利活用を主な対象とする。具体的には、原画や動画に対する演出修正・
%作画監督修正などの作画上の修正情報を、従来のカットや中間生成物の管理とは
%独立した形で収集・構造化し、それらを分析することで制作進行を円滑にするための
%システムを提案することを目的とする。
この目的を達成するため、アニメーション制作現場における修正の運用実態を調査し、
どのような単位・粒度で修正を蓄積すべきかを整理する。その上で
修正とともに蓄積すべきタグについて設計する。
次に、その結果に基づき、修正の内容や発生箇所、担当者、工程などの情報を体系的に
蓄積するためのデータ構造を設計し、修正データを分析することで
制作進行の計画立案や作業者配置の検討を支援する分析システムを実装する。
%最後に、提案システムを用いて修正データの傾向分析や可視化を行い、
%その結果から制作進行の計画立案や人員配置の最適化といった場面における有用性を検証する。





\section{本論文の構成}
本論文は6章から構成されている。各章の内容は以下の通りである。

\vspace{\baselineskip}

\noindent
\textbf{1章 序論}

本章では、本研究の背景と目的について述べる。

\vspace{\baselineskip}

\noindent
\textbf{2章 関連研究}

本章では、関連研究としてアニメーション制作に使用されるツールやアニメーション制作の
現状、及び画像認識技術やLLMについて述べる。

\vspace{\baselineskip}

\noindent
\textbf{3章 アニメ会社への調査}

本章では、アニメーション会社に対して行った調査の方法と結果について述べる。

\vspace{\baselineskip}

\noindent
\textbf{4章 提案手法}

本章では、アニメーション会社への調査結果を踏まえて、
本研究で提案するシステムの設計と実装について述べる。

\vspace{\baselineskip}

\noindent
\textbf{5章 評価}

本章では、本研究で提案するシステムの実際の使用事例とフィードバック、
アニメーション会社の方からの意見によりシステムの有用性について述べる。


\vspace{\baselineskip}

\noindent
\textbf{6章 結論}

本章では、本論文のまとめ及び今後の課題について述べる。


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\chapter{関連研究}
\section{はじめに}
本章では、本研究に関連する従来研究として、日本のアニメーション制作においてデータ管理を目的とした
ツールや中間生成物の蓄積に関する研究について述べる。最後に、本研究を実現するための
既存技術である画像認識技術やLLMについて述べる。

\section{アニメーション制作のデータ蓄積と活用方法の現状}
本節では、日本のアニメーション制作のデータ蓄積の現状と検討されている活用方法について述べる。

\subsection{アニメーションアーカイブの現状2017\cite{yamakawa}}
山川氏は、株式会社プロダクション・アイジーにおいてアーカイブグループのリーダを務め、
業務中に発生したアニメーション制作資料の収集・整理・選別・保管と、その利活用への対応を主な業務としている。
記事では、2017 年時点のアニメーションアーカイブの現状として、
社内スタッフからの問い合わせが月最大 200 件にも達し、
その内容が新作や続編制作のための設定画・色指定データの取り出し、
アニメータや演出家に仕事を発注する際の作風確認、新人教育用の原画貸出、商品化や映像配信、展示企画のための資料提供など多岐にわたることが紹介されている。
このような事例から、過去の原画や設定資料などの中間生成物 が、
制作・教育・商品開発などさまざまな用途において日常的に参照されており、
その活用意義が非常に大きいことがわかる。

中間生成物は、映像を作成する過程で発生した素材のことを指す。
その種類としては、企画書、脚本、絵コンテ、設定、カット袋 (レイアウト・原画・動画・タイムシート・
3D用素材etc) 、カラーモデル、3Dモデル、3Dシーン、色指定・仕上げ、背景、撮影、編集、
音響、アフレコ台本、納品前映像、ロケハン資料、版権画、セル画、宣伝資料、
納品映像(HD-CAM、フィルム) など多様なものが挙げられる。

このように、
多様な媒体・形式の資料が大量に発生するため、その全体像や関係性を把握できる人材は限られており、
評価選別や保管には大きなコストを要する。
その結果、多くの制作会社では原画を映像納品後に産業廃棄物として処分してしまうなど、
資料の大部分が十分な整理を経ずに失われている現状がある。
山川氏は、制作現場で長年培われてきた番号付けや書類管理のルールを基盤としつつ、
アーカイブズ学の知見を取り入れて「アーカイブや利活用時に困らない管理方法」を整備し、
会社や業界を超えた連携によってアニメーション資料の収集・選別・提供を継続的に行える枠組み
を構築することの重要性を述べている。この議論は、アニメーション制作過程で生じる中間生成物
や修正に関する情報についても、将来の制作や教育に資する形で蓄積・整理しておくための視点
が求められていることを示唆している。


\subsection{アイデアソンによるアニメーション中間生成物の活用可能性の検討\cite{matsushita}}
松下らは、日本のアニメーション制作が限られた人員で多数の作品を制作しているため、
制作過程で生まれる中間生成物の整理が十分に行われておらず、多くが廃棄されてしまう現状を指摘している。
一方で、こうした中間生成物はアニメーションの文化資本としての価値を持つにもかかわらず、
具体的な利用用途が見えにくいがゆえに、「コストをかけてでもアーカイブする」という動機づけ
が生じにくいことを問題としている。そこで松下らは、中間生成物の利用用途と活用可能性を検討するため、
2022 年にアイデアソンを実施している。

このアイデアソンでは、国立情報学研究所が公開しているリトルウィッチアカデミアの制作素材
（トリガーデータセット\cite{trigger}）を対象とし、計 27 名の学生が 7 チームに分かれて議論を行った。複数日
にわたるグループディスカッションと成果発表を通じて、モブキャラ作成システム、新人アニメータの
自主練習支援システム、原画データベースシステムなど、さまざまな活用案が提案されている。
これらの案は最終的に、中間生成物の横断的検索の必要性、機械学習用リソースとしての活用、
新たな表現メディア創出の手がかり、という三つの観点に整理され、中間生成物が制作・教育・研究・
ビジネスの各側面から広い応用可能性を持つことが示されている。

このように松下らの研究は、中間生成物そのものに潜在的な活用ニーズが存在し、
それがアーカイブの動機づけになりうることを示している。一方で、中間生成物をどのような
形で蓄積・管理するかという、活用の前段階にあたる大きな問題は依然として残されている。
特に、中間生成物の具体的な種類（例えば修正指示や修正後の原画・動画など）ごとに、
どのような単位で蓄積し、どのような指標やタグと組み合わせて活用すべきかについては、
十分に検討されていない。後述する本論文の検討は、このような課題意識のもとで、
修正に関わる中間生成物に焦点を当て、その蓄積と活用のあり方を考える試みとして位置づけられる。



\section{アニメーション制作におけるデータ管理用ツール}
この節では、日本のアニメーション制作で用いられているデータ管理用ツールについて
述べる。

\subsection{flow production tracking(旧shot grid)\cite{shotgrid}}
flow production tracking は、Autodesk 社が提供するクラウド型のプロダクション管理ツールであり、
映像・CG・アニメーション制作やゲーム開発などの分野で用いられている。
プロジェクト内の作業単位をタスクとして管理し、ショットやアセット
（キャラクタ、プロップ、背景環境などの制作要素）と関連付けることで、
制作工程全体の進捗を可視化することができる。スケジュール管理の面では、図\ref{shotGridSchedule} のように
ガントチャートによるタスクの開始日・終了日・期間の表示や、担当者・ステータスを含めたタスク一覧
ビューが提供されており、プロジェクト全体の進行状況を把握しやすい設計となっている。

\begin{figure}[h]
    \centering
    \includegraphics[width=\linewidth]{fig/shotGridSchedule.png}
    \caption{flow production tracking のスケジュール管理機能}\label{shotGridSchedule}
\end{figure}

また、図\ref{shotGridReview}のようにアップロードされた動画や静止画に対してコメントや描き込みを行うレビュー機能や、
バージョン違いのメディアを切り替えながら確認できるインタフェースも備えており、
オンライン上でのレビュー・承認ワークフローを支援している。

\begin{figure}[h]
    \centering
    \includegraphics[width=\linewidth]{fig/shotGridReview.png}
    \caption{flow production tracking のレビュー機能}\label{shotGridReview}
\end{figure}


さらに、図\ref{shotGridAsset}のようにアセット管理の機能として、
キャラクタや背景などのアセットに対して
任意のフィールドやステータスを追加し、担当者や進捗状態といった情報を一元的に管理できる。
ユーザごとにアクセス権限を設定する仕組みも用意されており、権限に応じて閲覧・編集可能な情報
を制御しながら、スタジオ内で共通の制作基盤として利用できるようになっている。
このように、flow production tracking は ショット・アセット・タスク を中心とした汎用的な
パイプライン管理ツールとして設計されており、スケジュール管理・レビュー・アセット追跡を統合的
に扱える点に特徴がある。


\begin{figure}[h]
    \centering
    \includegraphics[width=\linewidth]{fig/shotGridAsset.png}
    \caption{flow production tracking のアセット追跡機能}\label{shotGridAsset}
\end{figure}


一方で、flow production tracking については、多機能であるがゆえに初心者には扱いづらく、
直感的でない複雑なツールになっているという指摘もなされている。
また、導入コストが高いことや、日本のアニメーション制作で使用されるタイムシートなどへの対応ができないこと、
リテイク処理に対応できずリテイク用の別名カットを新たに作成する必要があるため、本来の意図と異なる使い方を
強いられる場合があることなど、日本のアニメーション制作現場での利用においてはいくつかの課題が残るとされている。
flow production tracking の想定するワークフローは、主に VFX や 3DCG 制作を中心とした国際的なパイプラインを対象としており、
日本のセルアニメーション由来の制作手法をそのまま適用できるとは限らないと考えられる。
特に、日本のアニメーション制作で一般的なカット袋やタイムシートを前提とした工程管理や、
原画・動画レベルでの細かな修正履歴を粒度良く記録・参照する運用は、
flow production tracking の標準的なエンティティ構造（ショット・アセット・タスク）に直接対応づけることが難しい場合がある。
そのため、flow production tracking はタスクやアセット単位の進捗管理やレビューの基盤としては有用である一方で、
原画や動画に対する修正指示や修正後素材といった修正にまつわる中間生成物を、
データ活用の観点から体系的に蓄積するための仕組みとしては十分とはいえない。


\subsection{save point\cite{savepoint}}
save point は株式会社 MUGENUP のプロジェクト管理ツールであり、イラストや 3DCG、映像、
広告アセット、アニメーションなど様々なクリエイティブ制作に対応している。制作スケジュール
や進捗、コミュニケーション、レビューをツール内で管理することで、情報共有を簡単に行える自由度
の高いツールとなっている。図\ref{savePointSchedule} のように、制作スケジュールや各工程の進捗を
ガントチャート形式で一覧できるスケジュール管理機能を備えており、プロジェクト全体の工程と期間
を俯瞰して把握することができる。

\begin{figure}[h]
    \centering
    \includegraphics[width=\linewidth]{fig/savePointSchedule.png}
    \caption{savepoint のスケジュール管理機能}\label{savePointSchedule}
\end{figure}


また、図\ref{savePointThread} に示すようなスレッド機能やレビュー
機能を通じて、各カットや素材ごとにファイルのアップロードや修正指示、コメントのやり取りを行える
ため、中間生成物の確認や指示を行う際に活用されている。ツール紹介では「コストを save」
「データを save」「ディレクターを save」の三つの save を掲げており、制作進行担当者や
ディレクターの業務負担の軽減と、データの一元管理による人的ミスの防止を主な目的としている。


\begin{figure}[h]
    \centering
    \includegraphics[width=\linewidth]{fig/savePointThread.png}
    \caption{savepoint のスレッド機能}\label{savePointThread}
\end{figure}


さらに save point を基盤として、アニメの制作進行に特化した「Save Point for アニメ」
も開発されている。Save Point for アニメ は、カット袋が担ってきた素材の受け渡しと作業指示書、
進行管理の機能をクラウド上で統合的に扱うことを目指したツールであり、絵コンテや原画、動画などの
素材の納品から、監修や修正指示に関するやり取り、スケジュールや進捗状況の管理までをブラウザ上
で一元化できるとされている。アニメ特有の進行表やカット表をツール内で再現したインタフェースや、
図\ref{savepointFinger}のように
紙のタイムシートをめくる「指パラ」に相当するフレーム単位の動きの確認機能、ガントチャートによる
工程スケジュールの可視化などを備え、アニメ制作の現場で使い慣れたワークフローとの親和性を意識した
設計になっている。

\begin{figure}
    \centering
    \includegraphics[scale=0.5]{fig/savepointFinger.jpg}
    \caption{save point for アニメの指パラ機能}\label{savepointFinger}
\end{figure}

しかし save point は、プロジェクト管理に重点を置いたツールであり、蓄積した中間生成物を将来的
に分析・再利用するデータ基盤として設計されているわけではない。そのため、中間生成物の蓄積は案件単位
やタスク単位の管理にとどまり、データ活用の観点から十分に構造化されているとは言い難い。実際に、
save point 内の検索機能も欲しい中間生成物があらかじめ明確になっていることを前提としたファイル
や案件の検索が中心であり、タグや属性に基づいて中間生成物同士の関係や傾向を横断的に探索するような
高度な検索や分析には応用しづらい。save point および Save Point for アニメ は進行管理や
コミュニケーションの効率化には有効である一方で、中間生成物を後の分析や教育など運用の観点から
蓄積する仕組みは備えていないと言える。






\subsection{Hiero\cite{hiero}}
Hiero は Foundry 社が提供する Nuke ファミリーのツールであり、マルチショット編集やコンフォーム、
レビューをタイムラインベースで扱うことを目的としたソフトウェアである。Nuke Studio と同様の
編集タイムラインを備えており、複数ショットをまたいだバージョン管理や再生確認、簡易的な編集作業を
一つのプロジェクト内で行うことができる。

レビュー機能としては、タイムライン上のフレームに対して描き込み付きの
アノテーションやコメントを付与でき、主にコンポジターやエディターなど
後工程の担当者に修正内容を伝えるワークフローが想定されている。
一方で、こうしたアノテーションはあくまで各プロジェクト内のレビュー情報として扱われており、
原画や動画に対する修正指示や修正後素材を、作品をまたいで横断的に蓄積・分析するための
構造化データとして管理する枠組みは提供していない。したがって Hiero はショットレビューと
フィードバックの効率化には有効であるが、本論文が対象とする修正の傾向分析や教育・品質管理に
用いるための修正データベースとしては別途の設計が必要である。


\subsection{アニクロ\cite{anikuro}}
アニクロは、メモリーテック株式会社が提供するクラウド型アニメ制作管理システムであり、
「カット袋をデジタル化しませんか？」というコンセプトのもと、カット袋やタイムシートを
オンライン上に再現して制作工程を管理することを目指している。工程ごとに素材ファイルをアップロード
して紐付ける工程管理・素材管理機能や、ブラウザ上で作画ファイルをプレビューし、コメントや手書きの修正指示
を書き込めるチェック機能を備えており、従来紙ベースで行われてきた受け渡しや指示をクラウド上で完結できる点が特徴である。

また、Web 上で共有可能なデジタルタイムシートや、自動更新されるカット表・日報表、複数カットに対する一括リテイク
出しやリテイク一覧表示などの機能により、作品単位での進行管理とリテイク管理を一元的に行うことができる。
このようにアニクロは、日本のセルアニメーション制作で用いられてきたカット袋やタイムシートの運用に対応した
制作管理ツールとして有用である一方で、原画や動画に対する個々の修正指示や修正前後素材を、作品や期間をまたいで
横断的に分析することを前提とした構造化データとして蓄積する枠組みまでは提供していないと考えられる。


\subsection{OLM FM tool\cite{olmfmtool}}
OLM FM Tool は、株式会社 OLM がデジタル作画パイプライン構築の一環として社内開発したファイル管理
ツールであり、リモートワーク環境における素材配布や成果物回収を円滑に行うことを目的としている。
制作データを Google ドライブ上に保存したうえで、作品・話数・カット・工程といった日本のアニメ制作
の単位に沿ってブラウズできる専用インタフェースを提供し、図\ref{OLMFMTool}のように、
ファイルやフォルダの個別・一括ダウンロード
やアップロード、フォルダの作成や削除などの操作を一画面から行うことができる。
これにより、従来のフォルダ構成では把握しづらいディレクトリ階層を現場向けに分かりやすく整理するとともに、
データ紛失を起こすことなく、低速なネット環境でも比較的快適に素材を扱うことができる点が特徴的であり、
リモートワークへの対応力の高さが評価されている。

\begin{figure}[h]
    \centering
    \includegraphics[width=\linewidth]{fig/OLMFMTool.png}
    \caption{OLM FM toolの自由度の高いディレクトリ操作機能}\label{OLMFMTool}
\end{figure}

一方で、OLM FM Tool はあくまでフォルダ階層とファイルパスに基づく素材管理を主眼としたツールであり、
データベース上に中間生成物を蓄積するわけではなく、オンラインストレージ上にファイル
を保存しているにとどまるという限界もある。また、作品ごとにディレクトリ構造を設計・作成する必要があり、
制作管理そのものの手間や時間を大きく短縮できるわけではないという課題も残されている。



\subsection{Redmine\cite{redmine}}
Redmine はオープンソースの Web ベースプロジェクト管理ツールであり、チケットによる課題管理や
ガントチャート・カレンダーによるスケジュール管理、Wiki・フォーラムによる情報共有機能などを備えている。
プロジェクトごとにチケット種別やワークフロー、カスタムフィールドを定義できる汎用的な設計となっており、
ソフトウェア開発以外の業務管理やコンテンツ制作にも広く用いられている。

アニメーション制作においても、図\ref{redmineChiket}のように各カットや工程をチケットとして登録し、
担当者・期限・ステータスを設定することで、進行状況の把握やタスク割り当てに利用することができる。
しかし Redmine はあくまで汎用的な課題管理ツールであり、
日本のアニメーション制作に特有のカット袋やタイムシートの運用を前提としておらず、原画・動画に対する個々の修正指示や
修正後素材を作品やアニメータをまたいで横断的蓄積するデータ構造は備えていない。

\begin{figure}[h]
    \centering
    \includegraphics[scale=0.5]{fig/redmineChiket.png}
    \caption{Redmine のチケット機能}\label{redmineChiket}
\end{figure}

\subsection{株式会社サンジゲンの制作管理ツール\cite{sannjigenn}}
株式会社サンジゲンは 3DCG アニメーション制作を主業務とするスタジオであり、
日本のアニメ制作に適した市販パッケージが少ないことから、自社内で制作管理システム
と制作データベース（制作DB）を構築している。従来 Excel で管理していた工程表ではタイトル数
やカット数の増加に対応しきれなくなったことを受け、発注情報やスタッフの作業状況、日報、チェック結果、
収支などを一元管理できる仕組みを整備している。
制作の進行状況やステータスはもちろん、チャット機能やアップロード通知の機能など、
管理業務を支援するための機能を幅広く備えている。
アップロードされた中間生成物を参照しながらレビューを行うことも可能であり、
日本のアニメーション制作の工程に幅広く対応している

また、アップロードされた映像データは自動エンコードされて Hiero に蓄積され、
社内ツール SanzigenCutManager と連携して最新テイクと過去テイクの比較チェックを行えるなど、
大規模 3DCG 制作におけるレビューと進行管理を効率化する基盤として機能している。一方で、
修正指示の内容や修正後素材を、中長期的な分析や再利用を目的としたデータとして独立に蓄積・分類
しているわけではなく、修正は主としてスケジュール・品質管理上のイベント
として扱われていると考えられる。




\section{アニメーションの中間生成物の蓄積に関する研究}
この節では、日本のアニメーション制作における中間生成物の蓄積に関する研究について述べる。

\subsection{新潟大学アニメ中間素材データベースAIMDB\cite{aimdb}}
新潟大学アニメ中間素材データベース AIMDB は、
アニメーション制作における中間生成物を体系的にアーカイブすることを目的として構築されたデータベースである。
扱っている中間生成物は原画、動画、修正原画、脚本、リテイクなど多岐にわたり、
制作過程で生じるさまざまな資料を対象としている。

AIMDB の研究目的は、中間生成物のアーカイブ化とデータ処理・分析、
セル画の保存ソリューションの開発であり、特に制作時に散逸しがちな中間生成物を蓄積することに焦点を当てている。
蓄積された中間生成物の一部は公開されており、
アーカイブされたデータはそれぞれの属性をもとに検索ができる。
図\ref{AIMDB}に示すように、作品名や制作会社、中間生成物の種類といった項目によって絞り込みを行うことが可能である。

\begin{figure}[h]
    \centering
    \includegraphics[width=\linewidth]{fig/AIMDB_mid.png}
    \caption{AIMDB}\label{AIMDB}
\end{figure}

一方で、このデータベースにはアニメータが制作業務の中で直接利用できるような入力インタフェースは提案されておらず、
中間生成物を蓄積するためには、過去の制作で用いられた資料をスキャンしてデータ化し、
技術者が手作業でデータベースに登録する必要がある。
また、タイムシートの取り扱いは紙媒体のみを対象としており、
デジタル形式（XDTS\cite{xdts}など）には対応していない。
さらに、検索も主として作品名や会社名など既知の属性を前提としており、
修正の内容や中間生成物同士の関係性といった観点から自由度の高い検索を行うには、
蓄積の設計やメタデータの構造が十分であるとは言い難い。

\subsection{実務家に聞くアニメアーカイブデータベースの可能性と課題
新潟大学アニメ中間素材データベース(AIMDB)へのフィードバックから\cite{matsumoto}}
新潟大学アニメ・アーカイブ研究センターでは、過去のアニメーション作品の中間生成物の
アーカイブを進めており、先述した AIMDB\cite{aimdb} として閲覧者を限定して公開している。
松本は、この AIMDB を用いた科研費プロジェクトの一環として、
Production I.G でアニメアーカイブを推進する山川道子氏と、
東映アニメーションでシニアプロデューサーを務める野口光一氏に
AIMDB を試用してもらい、アニメ制作の実務家としての所感をヒアリングしている。

山川氏と野口氏からは、例えば、
ニーズに応じて解像度の異なるデータを用意してはどうかという指摘や、
タグ付けや香盤表の情報だけでは十分ではなく、
目的に応じて資料を読み解き適切に案内できる
リファレンス能力を持ったアーキビストの育成が不可欠であることなどが挙げられている。
また、現場に共有されないまま早い段階で破棄されてしまう資料の存在を前提に、
絵コンテからのキーワード抽出によって香盤表的な情報を補完するなど、
失われがちな文脈情報を補う仕組みの必要性も指摘されている。

これらの意見からは、単に中間生成物そのものをスキャンして保存するだけでなく、
検索や利活用の起点となるメタデータや文脈情報をあわせて蓄積する重要性が示唆される。
さらに、専門的なアーキビストに全面的に依存するだけでは十分な体制整備が難しいことから、
アニメータを含む制作現場のスタッフ自身が、制作フローの中で中間生成物を登録・整理できる
インタフェース設計が求められていると考えられる。

\subsection{長尾らのデータベース\cite{nagao}}
セルアニメーション由来の手描きを含む制作手法を用いる日本のアニメーション制作では分業制が採用されており、
1 カットに対して携わる人数が多い。さらに、制作現場ごとに制作プロセスが異なるため、
業界内での画一的な中間生成物の管理は困難であり、スタジオごとにそれぞれ独自の手法で中間生成物を管理している。
しかし、共通の形式でデータを蓄積できなければ、中間生成物の活用を見込むことは難しく、貴重とされる中間生成物
が十分に生かされないまま終わってしまう。

これらの事実を受けて、長尾らはアニメーション制作完了後に残された中間生成物を調査し、
画一的な管理手法としてリレーショナルデータベースを提案した。具体的には、2014 年に株式会社スタジオ
コロリドと株式会社ロボットが共同制作を行ったマルコメ株式会社の「料亭の味」の CM アニメーション
\cite{marukome} のうち、「単身赴任編」と「夜食編」の 2 つのエピソードを対象に調査を行っている。
中間生成物を含むディレクトリ構造を分析した結果、以下の 5 点の課題を挙げている。

\begin{enumerate}
    \item ディレクトリの構成や命名規則がはっきりしておらず、必要となるファイルの在処を把握するのが困難
    \item 同一内容のファイルが複数のディレクトリに点在
    \item 工程の進捗状況を知るためには、複雑なデータ構造の確認が必要
    \item チェックの意図がファイル構造やファイル名からは判別しづらい
    \item 一部のファイルについてはデータ自体が残されていない
\end{enumerate}

これら 5 点に対して、長尾らは課題に適した設計指針を示している。設計指針としては、カット単位でデータ
を扱うこと、データの種類をタイムシートに関わるものとそうでない場合を分別できること、 
タイムシートの情報ではフレームとレイヤの情報を持てること、修正前後を含む全てのデータが確認できること
が挙げられている。カット単位で中間生成物を管理することは、カット袋での管理が基本である日本のアニメーション
業界において標準的であり、同一ファイルが複数箇所に点在するようことを防ぐメリットがある。また、
工程ごとにデータを管理することによって、必要となるファイルの在処を明確にし、進捗状況を把握しやすくすることができる。

これらの設計指針を基準に作成したデータベースが以下の図 \ref{Nagao} の 22 のテーブルからなる
リレーショナル・データベースである。カット、ファイル、作業の 3 つのテーブル群をフレームやレイヤなど
のテーブルで結びつけ、カットやファイル、作業を関連付けている。また、登録日時と更新日時を蓄積することで、
作業履歴を追跡可能な構造となっている。

\begin{figure}[h]
    \centering
    \includegraphics[width=\linewidth]{fig/NagaoDatabase.jpg}
    \caption{長尾らのデータベース}\label{Nagao}
\end{figure}

長尾らのデータベースは日本のアニメーション特有の制作手法に特化した構造となっており、
従来では管理が難しかった日本のアニメーション中間生成物を統一的な形式で扱うことを可能にした点に特徴がある。

\subsection{夏らのシステム\cite{yiyi}}
夏らは先述した長尾らのデータベース \cite{nagao} に対して、
原画と動画の中間生成物を蓄積できる WEB システムを提案している。
このシステムはアニメータ自身がアニメーション制作中に中間生成物を蓄積できる設計になっており、
制作後にまとめてアップロードするという手間を省くことができる。

中間生成物を蓄積する具体的な方法は、WEB インタフェース上の作業ページからのアップロードである。
アップロードの形式はレイヤ別の絵とタイムシートを含めたディレクトリ構造を zip 形式に圧縮
したものであり、作画ツールとして主流である CLIP Studio Paint \cite{clipstudio} で
描いた絵やタイムシートを容易にその形式にできることから、ツールとの連携も容易である。アップロード
により蓄積した中間生成物は図 \ref{XiaWorkpage} に示す作業画面にて確認をすることができる。

\begin{figure}[h]
    \centering
    \includegraphics[width=\linewidth]{fig/XiaWorkpage.png}
    \caption{夏らのシステム : 作業画面}\label{XiaWorkpage}
\end{figure}

作業ページのインタフェースはカット袋やタイムシートなど、
日本のアニメーション制作で使用される管理手法と似た表形式を意識して設計されており、
アニメータが違和感なく利用できるように配慮されている。
また、単に中間生成物をアップロードするだけでなく、下記のような制作支援機能を提供することで、ア
ニメータが制作途中に中間生成物を蓄積するモチベーションを高めている。

\begin{enumerate}
    \item タイムシートの編集 \\
    アップロードされたタイムシートはインタフェース上で編集を行うことができる。
    タイムシートのセル値の入力や削除、セル値の移動、undo、redo、コピー、ペーストなどができ、ユーザが容易に編集可能である。
    タイムシートの編集ができるツールは東映デジタルタイムシート \cite{toei} など限られていることから、本機能は貴重である。
    \item 映像作成 \\
    インタフェース上のタイムシートとアップロードされた原画や動画を使用して、
    現状の映像を作成することができる仕組みとなっている。
    映像作成は線画に対応しており、レイヤの重ね合わせはもちろん、
    特定のレイヤのみを用いた映像を作成することも可能である。
    \item 版による履歴管理 \\
    アニメータは自身の作業の中で、絵を描き換えやタイムシートを編集などの変更を加える。
    夏らのシステムではこの変更の際に、素材を上書きせず、過去の版の内容を復元可能な形で蓄積する。
    具体的には、映像作成時や再アップロード時に自動で過去の版を登録する。
    この蓄積方法により、過去の版の中間生成物を復元することが可能となり、
    インタフェース上で確認できる。版の保存は映像確認を行った際に、ユーザ自身の要望に応じて行うことができる。
    \item 版を用いた映像比較 \\
    過去の素材を版として蓄積しているため、各版時点での映像をインタフェース上で作成できる。
    また、過去の版を複数選択すれば、図 \ref{XiaVideopage} に示すインタフェースで、
    最大 4 つの版の映像を同時再生により比較できる。この映像比較機能によって、
    アニメータがより良い素材を選択できるだけでなく、
    試行錯誤の過程とその結果をデータベースに蓄積することができる。
    正解例のみならず失敗例も蓄積することで、試行錯誤の意図の理解に資する可能性がある。
\end{enumerate}


\begin{figure}[htbp]
    \begin{center}
        \includegraphics[scale=0.5]{fig/XiaVideopage.png}
    \end{center}
    \caption{夏らのシステム : 映像比較}\label{XiaVideopage}
\end{figure}

このような制作支援を通して、多忙なアニメーション業界での使用可能性を高めている。
蓄積するタイミングが制作途中であるために、最終版の中間生成物のみでなく、途中経過の中間生成物を蓄積
できることも大きな強みである。また、本システムは WEB システムであるので、アニメータが使用する環境
を構築するのが容易であり、導入難易度が比較的低い点も利点として挙げられる。

\newpage
\subsection{渕上らのシステム\cite{fucci}}
渕上らは、先述した夏らのシステムに対して、
カット間の関係接続を導入した中間生成物蓄積システムを提案した。
関係接続の手がかりとなる中間生成物とそれに関連するアニメータの行動、
および中間生成物の活用方法を明らかにするため、アニメーション制作会社
に対する調査を実施した。調査対象は株式会社スタジオエイトカラーズ、株式会社 OLM、
有限会社神風動画、Kaikai Kiki Animation Studio PONCOTAN であり、
制作現場での定点観察、対面インタビュー、意見交換、アンケートなどの手法を用いて
情報収集を行った。
調査の結果、中間生成物の主な活用方法として、以下の 4 点が挙げられている。

\begin{enumerate}
    \item 教育のための検索 \\ベテランアニメータがアニメーション制作を学んできた過程を調査したところ、原画本や修正指示の様子、類似カットなどの素材を閲覧することで学んできたという回答が多かった。そのため、新人アニメータが参照すべき中間生成物を手元から検索・閲覧できるようにすることは、教育の促進に有効であると考えられる。特に、修正指示や修正過程を併せて閲覧でき、新人の視点を補うような情報が付随していることが望ましい。
    \item 修正指示のための検索\\アニメ制作における修正指示の出し方には、原画シートへの書き込みや補助資料の送付など複数の方法が存在する。動きの説明などのために補助資料を用いる場合も多いが、中間生成物が十分に整理されていない現状では、適切な資料を探すのに多くの時間を要する。修正指示に用いる素材を検索によって素早く取得できれば、指示内容の簡潔化やリテイク数の減少に寄与すると考えられる。この用途の検索は動きなどに特化したものである必要があり、アニメーション制作向けのアノテーションやタグ付けが求められる。
    \item 作画の参考資料としての検索\\アニメータは、慣れないカットを描く場合や再現しにくい動きを捉える場合に、似た素材を検索して作画の参考にする。こうした素材を中間生成物から検索・参照できれば、作画作業を直接支援する機能として有用である。
    \item 素材の使い回し\\3DCG 素材や背景素材などは、作品内で再利用されることがある。しかし、中間生成物が十分に整理されていないと、再利用可能な素材を即座に取り出すことは難しい。使い回し可能な素材を検索によって取得できれば、作業効率を大きく向上させることができる。
\end{enumerate}

また、関係接続の手がかりとなる、中間生成物と関連するアニメータの行動として、
設定資料の閲覧、演出からの指示、タイムシートの更新履歴などが挙げられている。
渕上らは、これらの中から特にアニメータの行動履歴に着目し、カットごとの関係接続
を行うことで、活用を意識した中間生成物の構造的な蓄積を可能にしている。

さらに渕上らは、夏らのシステムと同様に、アニメ会社が本システムを利用するモチベーションを高めるため、アニメーションのクオリティ向上や作業時間短縮につながる付加価値機能を実装している。主な機能としては、以下の点が挙げられる。

\begin{enumerate}
\item デジタルタイムシートへの対応とインタフェース改善\\
デジタルタイムシート形式である TDTS の読み込みに対応し、工程に応じて原画欄と動画欄を切り替えて利用できるようにしている。また、セル幅を削減することで十分なセル数を画面上に表示可能とし、紙のタイムシートに近いレイアウトを実現している。さらに、タイムシート上のセルにマウスオーバーした際に対応する絵を表示する機能を設けることで、映像を生成せずともカットの完成度を簡易的に確認できるようにしている。
\item 色付き素材を考慮した映像作成\\
仕上げ工程を想定し、レイヤ合成時にアルファ値を考慮した映像作成機能を実装している。これにより、線画のみを対象とした夏らのシステムと異なり、色付きのセルを用いた映像確認が可能となっている。
\item 各工程ツールとの連携と作業ファイルのダウンロード\\
原画・動画・ペイントといった各工程で主に用いられる CLIP STUDIO PAINT との連携を考慮し、XDTS や TDTS 形式のデジタルタイムシートと各セルの絵を含むディレクトリ構造を zip 形式でダウンロードできるようにしている。過去の版や最新の版を選択して中間生成物一式を取得できるため、現場の作業フローに組み込みやすい構成となっている。
\end{enumerate}

これらの機能に加え、図 \ref{fucciInforFlow} に示すように、
アニメータが Web システム上で情報伝達を行う中で各工程の中間生成物が自動的に蓄積されるよう設計
されている。システム上で情報伝達と制作管理を一体的に行えるようにすることで、制作進行担当者の業務
負担を軽減するとともに、アニメータがシステムを利用するだけで中間生成物とその版の履歴が蓄積
されていく点が、渕上らのシステムの特徴である。

\begin{figure}[htbp]
    \begin{center}
        \includegraphics[scale = 0.7]{fig/fucciInfoflow.png}
    \end{center}
    \caption{渕上らのシステム : 全体設計}\label{fucciInforFlow}
\end{figure}


\section{既存アニメ関連ツールの比較}

\subsection{比較指標}

\subsection{比較結果}



\section{タグ付けのための物体検出}
本研究では、アニメーション制作過程の修正を活用しやすい形で蓄積するため、
修正が入ったカット、特に彩色後のフレーム画像から自動的にタグを付与することを目的とする。
その基盤技術として、画像中の対象（人物、顔、手、衣装、小物など）を領域（バウンディングボックス）
とともに抽出できる物体検出は有用である。一方で、アニメ画像に対して十分な教師データ
（バウンディングボックス付きデータセット）を用意することは困難であるため
、本研究が物体検出器に求める要件は次の通りとする。

\begin{enumerate}
    \item 学習データを用意せずに適用できる ゼロショット検出 が可能であること
    \item 速度は重視しない（オフライン処理を想定）こと
    \item アニメ画像に対して相対的に高い精度を示す手法を採用すること
\end{enumerate}

以上を踏まえ、クローズドセット検出器（YOLO, DETR, DINO）と、
言語条件により語彙を拡張できるオープンボキャブラリ検出器（GLIP, Grounding DINO）を取り上げ、
特に要件(1)(3)を満たす候補として後者を中心に整理する。



\subsection{YOLO\cite{yolo}}
YOLO は物体検出を代表する手法の一つであり、特に「画像を一度だけネットワークに通して検出を完結させる」
単段（one-stage）検出器の流れを決定づけたモデルとして位置付けられる。YOLO（You Only Look Once）
は Redmon らにより提案された CNN ベースの検出器で、入力画像から特徴を抽出するバックボーン CNN と、
検出ヘッドを一体化して持つ点に特徴がある。図\ref{fig:yolo_arch} に示すように、
畳み込み層とプーリング層を中心に段階的に特徴マップを得たのち、最終段でバウンディングボックスの位置・
サイズとクラス確率を同時に推定する。二段方式（候補領域生成して分類する方式）と比べて処理が単純であるため、
推論が高速になりやすく、リアルタイム物体検出の文脈で広く普及した。

\begin{figure}[h]
  \centering
  \includegraphics[width=\linewidth]{fig/yoloArchitecture.png}
  \caption{YOLOv1 のネットワーク構造の例}
  \label{fig:yolo_arch}
\end{figure}

初期の YOLOv1 は速度面で大きな成功を収めた一方、小物体の見逃しや精度面に課題が指摘されていた。
その後の改良として、YOLOv2 / YOLO9000 ではバッチ正規化、アンカーボックス、高解像度入力といった工夫により精度と再現率
が大きく改善され、YOLOv3 ではより深いバックボーン設計とマルチスケール検出によって速度と精度のバランスがさらに洗練された。
以降も YOLOv4 以降の派生や、Ultralytics 社による v5〜v12 など多くのバリエーションが提案されており、
物体検出の実用モデルとして多様な応用で利用されている。

本研究の修正が入ったカットのタグ付けという文脈に照らすと、
YOLO 系の利点は「多数フレームに対して候補領域を一括抽出する処理を比較的軽量に実行できる」点にある。
制作現場の素材はフレーム数が膨大になり得るため、処理時間を抑えやすいこと自体は魅力である。
ただし、本研究ではオフラインでの一括処理も想定でき、リアルタイム性は必須要件ではないため、高速性は採用判断を左右
する決定要因というより、実装・運用上の余裕をもたらす副次的な利点として位置付けるのが自然である。

一方で、YOLO 系を自動タグ付けの中核として用いる際には、構造上の制約が生じる。多くの YOLO 系モデルは COCO 
など自然画像データセットに基づくクローズドセット検出器として設計され、検出クラスはあらかじめ定義されたカテゴリ集合に限定される。
このため、アニメ制作で検索や分析に有用な「上半身」「顔」「目」といった部位概念や、
作品・工程ごとに柔軟に増やしたいタグ語彙を、学習データなしでそのままゼロショットに扱うことは原理的に難しい。
加えて、アニメ画像（線画や彩色済み画像）は自然画像と統計的性質が異なるにもかかわらず、
アニメ領域ではバウンディングボックス付きの大規模データセットが十分に整備されていない。
その結果、YOLO をアニメ画像に対して安定して高精度に動作させるには追加学習やファインチューニングが必要になりやすいが、
そのための教師データ準備コストが大きく、本研究が前提とする「学習データを用意しにくい状況でのタグ付け」という要件とは整合しにくい。

以上より、YOLO 系は「定義済みの少数クラスに対して高速に候補領域を抽出し、フレーム内の大まかな配置を把握する」
といった用途では有効であり、物体検出手法の代表例として整理する価値がある。
一方で、本研究が重視するゼロショット性とタグ語彙の柔軟性、そしてアニメ画像への相対的な精度という観点では、
クローズドセット検出器である YOLO を主たる手法として採用することは難しい。したがって本章では、
YOLO を物体検出の基礎的枠組みを示す参照（ベースライン）として位置付けつつ、後続で扱うオープンボキャブラリ検出器
へと議論を接続する。

\subsection{DETR\cite{detr}}
\begin{figure}[h]
    \centering
    \includegraphics[width=\linewidth]{fig/Detr_arch.png}
    \caption{DETR の全体構成}\label{fig:detr_arch}
\end{figure}

DETR（DEtection TRansformer）は Carion らによって 2020 年に提案された物体検出モデルであり、
従来主流であった「候補領域の生成→分類・回帰」という段階的パイプラインを、
Transformer を中核とする単一のネットワークに統合した点に特徴がある。物体検出の研究史の中では、
CNN を中心に発展してきた検出器設計に対して、Transformer を用いた 集合予測（set prediction） 
の枠組みを導入し、後続の多くの Transformer 系検出器（改良 DETR 群や DINO 系、さらには言語条件付き検出へ）
につながる重要な転換点となったモデルとして位置付けられる。図\ref{fig:detr_arch} に DETR の全体構成を示す。

DETR の処理は大きくバックボーン、Transformer エンコーダ、Transformer デコーダ
の三段に整理できる。まず入力画像は CNN バックボーンにより特徴マップへ変換され、
空間方向に並べ替えられたうえで位置エンコーディングが付与される。これが Transformer エンコーダへ入力され、
自己アテンションによって画像全体の文脈を踏まえた特徴量が得られる。次に Transformer デコーダには固定個数の 
オブジェクトクエリ が入力される。オブジェクトクエリは学習可能なベクトル集合であり、
画像中の各物体を「どのスロットが担当するか」を決めるための枠組みとして機能する
。デコーダはクエリとエンコーダ出力の間でクロスアテンションを行うことで、画像中の重要領域をクエリごとに参照し、
最終的に各クエリに対応する出力を prediction head に入力してクラスラベルとバウンディングボックスを推定する。
従来の Anchor Base や非最大抑制 (NMS) に依存せず、ネットワーク全体を end-to-end に学習できるため、
検出器の構造を比較的簡潔に記述できる点が利点として挙げられる。また、エンコーダの自己アテンションにより画像全体
の関係性を扱えることから、物体同士の重なりや離れた領域間の関係が重要になる場面で有利に働く可能性がある。

一方で、元の DETR には実用面での課題も報告されている。代表的には、学習の収束が遅く、
COCO のような一般的データセットでも十分な精度に到達するまでに多くの学習エポックを要する点が挙げられる。
また、高解像度画像における小物体の検出性能が十分でないことが指摘されており、
アニメ制作の文脈で頻出する小さな顔パーツや小物、アクセサリ類の検出では不利になり得る。
さらに Transformer を中核とする性質上、軽量な CNN ベースの検出器と比べて推論時間やメモリ使用量
が大きくなりやすく、計算資源の観点で工夫が必要となる場合がある。ただし本研究では速度を重視しない運用
が想定されるため、計算コストそのものは致命的な制約というより、
候補モデル選択におけるトレードオフ要因として整理するのが適切である。

本研究との関係で整理すると、DETR は物体検出を Transformer による end-to-end な枠組みとして定式化した点で重要であり、
後続の改良手法（DINO など）や、言語条件を導入した検出器（Grounding DINO など）を理解するための基礎として有用である。
一方で、DETR 自体は基本的にクローズドセット検出であり、アニメ画像に対する教師データが十分に用意できない状況で
学習なしにタグ語彙を柔軟に増やしながら検出するという本研究の要件であるゼロショット性を満たしていない。
したがって本章では、DETR を Transformer 系検出器の代表例・歴史的起点として位置付けつつ、
収束性や小物体検出といった課題がどのように改善され、さらにゼロショット検出へ発展していくかという流れの中
で次節以降の手法へ接続する。


\subsection{DINO\cite{dino}}
DINO は Zhang らによって提案された Transformer ベースの物体検出モデルであり、
DETR 系列の課題であった学習収束の遅さと小物体検出性能の不足を改善することを目的としている。
図\ref{fig:dino_arch} に DINO の全体構成を示す。

\begin{figure}[h]
  \centering
  \includegraphics[width=\linewidth]{fig/DINO_arch.png}
  \caption{DINO の全体構成図}
  \label{fig:dino_arch}
\end{figure}


まず、入力画像からは CNN バックボーンによりマルチスケールの特徴マップが抽出され、
それぞれに位置エンコーディングを加えた上でフラット化し、
Transformer エンコーダに入力する。
エンコーダは複数スケールの特徴を統合しつつ自己アテンションにより文脈情報を取り込んだ
画像特徴を生成する。

DETR ではオブジェクトクエリがランダム初期化された学習パラメータとして与えられていたのに対して、
DINO ではエンコーダ出力から「クエリ選択（Query Selection）」を行い、
物体らしさの高い位置を初期アンカーとして抽出する。
これらのアンカー情報をもとに内容ベクトル（Content Query）を生成し、
Transformer デコーダに入力することで、
各クエリが画像中の有望な領域に対応しやすいように設計されている。
デコーダの出力は DETR 同様にクラスラベルとバウンディングボックスを予測する
ネットワークに入力され、最終的な検出結果として解釈される。

また DINO では、学習の安定化と性能向上のために
「Contrastive DeNoising（CDN）」と呼ばれる学習戦略を導入している。
これは、正解ボックスにノイズを加えた擬似ターゲットと、
全く関係のないネガティブなボックスを同時にデコーダへ入力し、
どの出力が真の物体に対応するかを学習させる手法である。
このノイズ付きターゲット学習により、
モデルはローカライゼーション誤差や外れ値に対して頑健になり、
少ないエポックでも高い性能に到達しやすくなると報告されている。

このように DINO は、DETR のエンコーダ・デコーダ構造を継承しつつ、
クエリ選択による初期アンカー生成とノイズ付き学習戦略を組み合わせることで、
収束の高速化と小物体を含む高精度な検出を実現したモデルである。
一方で、Transformer を中核とする点は DETR と同様であり、
YOLO 系の軽量な CNN ベース検出器と比較すると推論時の計算コストは依然として大きい。
またゼロショット性を備えていないため、アニメ制作で欲しい「顔」「手」「上半身」といった部位概念や、
作品・工程依存で増やしたいタグ語彙を学習なしで柔軟に扱う主手法としては限界がある。



\subsection{GLIP\cite{glip}}

GLIP は Li らによって 2022 年に提案された物体検出モデルであり、画像と言語を統合的に扱う点に特徴がある。
従来の物体検出では、画像と、それに対応するバウンディングボックスとクラスラベルの組からなる検出データのみ
を用いて学習するのが一般的であったのに対して、GLIP ではこれに加えて、文章中のフレーズと画像内の領域を対応
付けたグラウンディング用データや、画像とキャプションのペアからなる画像テキストデータを併用して事前学習を行う。
具体的には、物体検出データセット上では従来と同様に「ボックス＋クラス名」の組を学習しつつ、
グラウンディングデータセット上では「文章中のフレーズ」と「それに対応する画像領域」の対応関係を学習し、
さらに画像全体とキャプション文のペアからは、画像特徴とテキスト特徴が意味的に対応するように事前学習を行っている。
このように複数形式の画像テキストデータを統合的に用いることで、GLIP は言語に敏感な物体表現を獲得し、
ゼロショット設定においても高い検出性能を示すことが報告されている。

図\ref{fig:glip_arch}に GLIP の全体構成を示す。上段では
「person」「bicycle」「hairdryer」などのカテゴリ名や
簡単なフレーズからなるプロンプトをテキストエンコーダで処理し、
単語ごとの特徴量を得ている。下段では画像から領域ごとの特徴量を
抽出し、テキスト側の特徴と融合させることで、各領域がどの単語に
対応するかのスコア行列を計算している。このように、単語と画像領域の
対応関係を直接学習する構成になっていることが、GLIP の特徴である。

\begin{figure}[h]
  \centering
  \includegraphics[width=\linewidth]{fig/glip.png}
  \caption{GLIP の全体アーキテクチャ\cite{glip}}
  \label{fig:glip_arch}
\end{figure}


GLIP の大きな利点は、オープンボキャブラリ検出が可能である点にある。
検出時には、従来のようにあらかじめ固定されたクラス集合をモデル内部に持たせるのではなく、
「girl」「smiling woman」のようなカテゴリ名や簡潔なフレーズをテキストとして入力し、
そのテキストと画像中の領域の対応に基づいてバウンディングボックスとスコアを出力する枠組みとなっている。
このため、クラス集合を事前に厳密に固定しておく必要がなく、タグ集合を後から追加したり、
「女の子」「赤い服」など比較的柔軟な概念をタグとして扱える点は、タグ設計の自由度という観点から有用である。
また、学習には物体検出データだけでなくキャプション付き画像も用いられているため、
従来の検出器では学習データ数が少なく性能が出にくいカテゴリに対しても、ゼロショットもしくは少数ショット
で一定の性能が得られやすいとされている。

一方で、GLIP を実際のシステムに組み込む際の課題も存在する。GLIP は大規模な Transformer を中核とするモデルであり、
YOLO 系の軽量な検出器と比較すると、推論時間やメモリ使用量は大きい。
また、GLIP は主として実写画像を用いたデータセットで事前学習されているため、
線画や彩色済みセル画といったアニメーション画像とは分布が異なる。デフォルメされたキャラクタやアニメ特有の表現に対しては
検出精度の低下が避けられないと考えられるが、アニメ領域ではバウンディングボックス付きの大規模教師データを新たに構築
することは現実的ではない。そのため、本研究のような設定では、GLIP をアニメ画像に完全に適応させるための追加学習
を前提とするのではなく、ゼロショットを前提としたある程度の誤差を許容した候補領域抽出
として位置付ける必要がある。加えて、検出対象はテキストで指定するため、プロンプトとして与える語彙や表現の仕方
によって検出結果が変動しやすく、アニメ制作におけるタグ設計に合わせて、どのような表現
を用いるかといったプロンプト設計も重要な検討事項となる。

以上より、GLIP は、事前に固定されたクラス集合に依存しないオープンボキャブラリ物体検出を可能にする点で
、アニメーションの修正カットに対して柔軟なタグ付けを行うための有力な候補である一方で、
実写ベースの事前学習による精度低下やプロンプト依存性といった課題を抱えている。
本研究においては、YOLO のようなクローズドセット検出器と比べてタグ語彙の自由度が高いことを重視しつつも、
アニメ画像に対する検出精度や計算コストとのバランスを踏まえた上で、修正カットのタグ付けにおける適用可能性を検討する。






\subsection{Grounding Dino\cite{groundingdino}}
Grounding DINO は Liu らによって提案されたオープンボキャブラリ物体検出モデルであり、
DINO 系の高性能な Transformer ベース検出器と、GLIP のようなテキスト条件付きグラウンディング
の枠組みを統合している\cite{groundingdino}。すなわち、DINO が示した高精度な Transformer 
検出アーキテクチャを土台としつつ、GLIP のようにテキストと画像の対応関係を明示的に学習することで、
任意のテキストフレーズに対するゼロショット検出を実現したモデルと言える。図\ref{fig:grounding_dino_arch}に 
Grounding DINO の全体構成を示す。

\begin{figure}[h]
\centering
\includegraphics[width=\linewidth]{fig/GroundingDino.png}
\caption{Grounding DINO の全体アーキテクチャ\cite{groundingdino}}
\label{fig:grounding_dino_arch}
\end{figure}

図の左下に示すように、入力テキストはテキストバックボーンを通して「cat」「person」「mouse」
などのトークン列として埋め込みベクトルに変換される。一方で、入力画像は DINO と同様の画像バックボーンと 
FPN によってマルチスケールな画像特徴として表現される。これらの「素の」テキスト特徴と画像特徴は 
Feature Enhancer で統合され、テキストから画像へ、画像からテキストへという双方向のクロスアテンションを通じて、
互いの情報を参照しながら更新された特徴表現へと変換される。

その上で、Language-guide Query Selection によってテキスト特徴から言語ガイド付きのクエリが生成される。
これは DINO における学習済みオブジェクトクエリに相当するが、Grounding DINO ではテキスト側の情報を利用して
「どのクエリがどのテキストトークンに対応するか」を明示的に制御する点が異なる。生成されたクエリは 
Cross-Modality Decoder に入力され、画像特徴に対するクロスアテンションとテキスト特徴に対するクロスアテンション
を通して更新される。最終的なデコーダの出力に対しては、テキストと画像領域の整合性を測るコントラスト損失と、
バウンディングボックスの位置精度を評価するローカライゼーション損失が同時に適用され、
テキストフレーズと画像中の領域が一貫した形で対応付けられるように学習される。

GLIP との比較という観点では、両者とも「テキストを入力として任意の語彙の物体検出を行う」という点で共通しているものの、
GLIP が比較的シンプルな検出ヘッドの上にテキストとのクロスアテンションを載せた構成であるのに対し、
Grounding DINO は DINO 系の強力な Transformer 検出アーキテクチャをそのまま活かしつつ、Feature Enhancer 
と Cross-Modality Decoder という二段構成で画像特徴とテキスト特徴を深く融合している点が大きな違いである。
また、DINO と比較すると、DINO はあくまでクラス数が固定されたクローズドセット検出器であり、クラス埋め込みは
モデル内部に固定されているのに対し、Grounding DINO はクラス名やフレーズをテキストとして与えることで、
クラス集合を外から自由に指定できるオープンボキャブラリ検出器となっている。

利点としては、DINO 由来の高い検出精度と学習安定性を維持したまま、GLIP のように自然言語でカテゴリを指定できる
柔軟なゼロショット検出を実現している点が挙げられる。特に高解像度画像に対する検出性能や、長いテキストプロンプト
を扱うスケーラビリティに配慮した設計となっており、公開実装や事前学習済みモデルも整備されていることから、
テキスト条件付き物体検出の実用的な選択肢として広く利用されている。

一方で、Grounding DINO は大規模な Transformer モデルを中核とするため、YOLO 系のような軽量な CNN ベース検出器
に比べると推論時間やメモリ使用量が大きい。
また、事前学習に用いられているデータセットの多くは実写画像であり、線画や彩色済みセル画といったアニメーション画像
とは分布が異なる。そのため、本研究のようにアニメの修正カットに適用する場合には、デフォルメされたキャラクタやアニメ特有
の背景表現に対する検出精度の低下をある程度許容した上で、ゼロショットな候補領域抽出やタグ候補生成のためのツール
として位置付ける必要がある。さらに、GLIP と同様に、検出対象はテキストプロンプトで指定するため、
「どの表現でタグを与えるか」によって検出結果が変動しやすく、アニメ制作で用いるタグ語彙や修正指示の書き方
に合わせたプロンプト設計も重要な検討事項となる。

このように Grounding DINO は、DINO の高精度 Transformer 検出器と GLIP 系の言語条件付きグラウンディング
を統合したモデルとして位置付けられ、クラス集合を固定しない柔軟なタグ付けを可能にする一方で、
計算コストやドメインギャップ、プロンプト依存性といった課題を抱えている。本研究では、YOLO や DINO のような
クローズドセット検出器と比較してタグ設計の自由度が高いという点を重視しつつ、アニメ画像に対する精度や処理コスト
とのバランスを踏まえて、修正カットのタグ付けにおける適用可能性を検討する。





\section{タグ付けのためのポーズ推定}

\subsection{mmpose}

\section{タグ付けのためのVLM}

\subsection{Qwen2.5}

\section{既存画像認識技術の比較}

\subsection{比較指標}

\subsection{比較結果}



\section{おわりに}

結論は、網羅的にかつ簡潔に。

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{アニメ会社への調査}
\section{はじめに}
\section{調査目的/調査方法}
\section{アニメーション制作工程でのワークフロー}
\section{各工程で発生するリテイク}
\subsection{原画}
\subsection{動画}
\subsection{彩色}
\subsection{ラッシュ}
\section{リテイクに関する考察}
\subsection{リテイクの発生原因}
\subsection{リテイクの活用可能性}
\section{おわりに}

\chapter{提案手法}
\section{はじめに}
\section{リテイクを活かしたシステムの提案}
\subsection{リテイクのタグ分類}
\subsection{制作進行を円滑にするための
アニメータのタグ別リテイク率計算システム}
\subsection{修正指示の補助資料としての修正前後の素材検索システム}
\section{リテイクのデータベース設計}
\section{実装方針}
\section{その他実装}
\section{おわりに}


\chapter{評価}
\section{はじめに}
\section{タグ付け精度の評価と考察}
\subsection{実験内容}
\subsection{実験結果}
\section{データベースの評価}
\subsection{制作進行からの意見}
\subsection{アニメータからの意見}
\section{検索システムの評価}
\subsection{制作進行からの意見}
\subsection{アニメータからの意見}
\section{おわりに}

\chapter{結論}
\section{本論文のまとめ}
\section{今後の課題}


\appendix
\chapter{リテイクに関与しない部分のアニメ会社調査結果}
必要に応じて、付録を載せる。

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%





\backmatter
\chapter{謝辞}
本論文の執筆にあたり、議論して頂いた関係者に感謝する。

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\bibliographystyle{jplain}
\bibliography{references}
%\begin{thebibliography}{99}
%  \bibitem{tokodai-xyz2015} 科学大太郎. 良い論文の書き方. \textit{Journal of XYZ}, Vol.~3, No.~4, pp. 15--34, 2015.
%\end{thebibliography}

\end{document}
